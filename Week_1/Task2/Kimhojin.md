# 인공지능 1주차-2

추가 일시: 2024년 7월 8일 오전 4:52
강의: AI-summer
숫자: 2

### CNN 이론

### 완전 연결 계층 (Fully Connected Layer)

### 완전 연결 계층이란?

완전 연결 계층(Fully Connected Layer, FC)은 인공신경망(Artificial Neural Network)에서 가장 기본적인 형태의 계층입니다. 각 뉴런이 이전 계층의 모든 뉴런과 연결되어 있는 구조입니다. 즉, 각 뉴런은 모든 입력 값을 받아 가중치를 적용한 후 하나의 출력을 생성합니다.

### 문제점

- **연산 비용**: 입력 차원이 커질수록 가중치의 수가 기하급수적으로 증가하여 계산 비용이 매우 높아집니다.
- **과적합**: 많은 수의 가중치는 학습 데이터에 대한 과적합(overfitting) 위험을 증가시킵니다.
- **공간적 정보 손실**: 입력 이미지의 공간적 구조를 무시하고 일차원 벡터로 처리하므로, 이미지의 공간적 정보를 활용하지 못합니다.

[Convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network)

### 합성곱 (Convolution)

### 합성곱이란?

합성곱(Convolution)은 이미지 처리에서 자주 사용되는 연산으로, 필터(또는 커널)를 이용해 입력 이미지의 특정 패턴을 추출합니다. 필터는 작은 크기의 행렬로, 입력 이미지의 모든 위치에 대해 점진적으로 적용됩니다. 각 적용 위치에서 필터와 입력 이미지의 대응 요소끼리 곱한 값을 더한 결과가 출력 이미지의 한 픽셀 값을 구성합니다.

### 완전 연결 계층의 문제점 해결

- **연산 비용 감소**: 필터를 사용하여 데이터의 크기가 작아지므로, 필요한 가중치의 수가 크게 줄어듭니다.
- **공간적 정보 유지**: 이미지의 공간적 구조를 유지하면서 특징을 추출할 수 있습니다.

### Padding

### Padding 이란?

패딩(Padding)은 합성곱 연산 시 입력 이미지의 가장자리 정보를 보존하기 위해 입력 이미지의 주변을 특정 값으로 채우는 방법입니다.

### Padding 종류

- **Valid Padding**
    
    입력 사이즈보다 출력 사이즈가 작게 하는 방법 패딩을 하지 않았을 때나 패딩을 하였으나 크기가 작아진 경우
    
- **Same Padding**
    
    입력사이즈와 출력사이즈의 크기가 동일한 방법 합성곱 연산 전후의 크기가 같아진다.
    

### Pooling

### 사용 이유

풀링(Pooling)은 입력 특성 맵의 차원을 줄이고 계산량을 줄이기 위해 사용됩니다. 

### 특징 및 장단점

- **특징**: 데이터의 영역을 나눈뒤 그 영역에서 있는 값들을 연산하여 데이터의 크기를 줄이는 특징이 있다. 이때 연산을 영역내 최대값으로 하면 max pooling 평균 값으로 하면 average pooling이라고 합니다.
- **장점**: 계산 비용 감소, 과적합 방지, 중요한 특징 강조
- **단점**: 정보 손실 가능, 풀링 크기와 stride 선택에 따른 성능 변동

### Conv(n)d [ n = 1, 2 ]

### 입력 데이터의 차원, Kernel

- **Conv1D**: 1차원 합성곱으로, 주로 시계열 데이터나 텍스트 데이터에 사용됩니다. 입력 데이터와 필터 모두 1차원입니다.
- **Conv2D**: 2차원 합성곱으로, 이미지 데이터에 사용됩니다. 입력 데이터와 필터 모두 2차원입니다.

요약하자면 

Conv(n)d는 n차원 데이터를 n차원 필터를 통해 합성곱을 시행하는것이다.

[🧶 Understanding 1D, 2D and 3D Convolution Network](https://www.kaggle.com/code/mersico/understanding-1d-2d-and-3d-convolution-network)

### PyTorch에서 MLP 구현하는 법 (이론)

Multi-Layer Perceptron (MLP)은 여러 개의 완전 연결 계층을 가진 인공신경망입니다. PyTorch에서는 `torch.nn` 모듈을 사용해 MLP를 구현할 수 있습니다.

1. **모델 정의**: `torch.nn.Module`을 상속받아 MLP 클래스를 정의합니다.
2. **계층 구성**: `torch.nn.Linear` 클래스를 사용해 완전 연결 계층을 구성합니다.
3. **활성화 함수**: `torch.nn.ReLU`나 `torch.nn.Sigmoid`와 같은 활성화 함수를 사용합니다.
4. **순전파 정의**: `forward` 메서드를 정의해 입력 데이터가 계층을 거쳐 출력되는 과정을 구현합니다.
5. **역전파 호출**: `backward`함수를 사용하여 역전파시 나온 기울기를 얻습니다.
6. **옵티마이저 호출**: `optimizer.step`등을 사용하여 파라미터를 변화시켜줍니다.