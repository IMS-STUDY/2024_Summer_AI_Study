{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39193,
     "status": "ok",
     "timestamp": 1721015326963,
     "user": {
      "displayName": "Hojin Kim",
      "userId": "14078983730331144087"
     },
     "user_tz": -540
    },
    "id": "CGpRdbn5wvjL",
    "outputId": "9d96680d-114f-409e-a87e-14ab2c6a7954"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimHojin\\anaconda3\\envs\\py310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 지정된 프로시저를 찾을 수 없습니다'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import winsound as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 79331,
     "status": "ok",
     "timestamp": 1721015409070,
     "user": {
      "displayName": "Hojin Kim",
      "userId": "14078983730331144087"
     },
     "user_tz": -540
    },
    "id": "t0XCGIpBweua"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimHojin\\AppData\\Local\\Temp\\ipykernel_25520\\2429053110.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\b\\abs_8f7uhuge1i\\croot\\pytorch-select_1717607507421\\work\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  image =torch.FloatTensor([image])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "dataset=[]\n",
    "#train_dataset=[]\n",
    "#test_dataset=[]\n",
    "for n in range(1,141):\n",
    "  try:\n",
    "    image = Image.open('Dataset/o_{}.png'.format(n)).convert('L')\n",
    "  except:\n",
    "    image = Image.open('Dataset/o_{}.jpg'.format(n)).convert('L')\n",
    "  image = np.array(image)\n",
    "  image =torch.FloatTensor([image])\n",
    "  #data=image,torch.FloatTensor([[0,1]])\n",
    "  data=image,0\n",
    "  dataset.append(data)\n",
    "  try:\n",
    "    image = Image.open('Dataset/x_{}.png'.format(n)).convert('L')\n",
    "  except:\n",
    "    image = Image.open('Dataset/x_{}.jpg'.format(n)).convert('L')\n",
    "  image = np.array(image)\n",
    "  image=torch.FloatTensor([image])\n",
    "  #data=image,torch.FloatTensor([[1,0]])\n",
    "  data=image,1\n",
    "  dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181348,
     "status": "ok",
     "timestamp": 1721016607926,
     "user": {
      "displayName": "Hojin Kim",
      "userId": "14078983730331144087"
     },
     "user_tz": -540
    },
    "id": "-tkNpcV_wfKB",
    "outputId": "302900c1-abc9-4111-b6aa-a8f74cd3eb2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 18.396\n",
      "Loss after mini-batch    20: 10.598\n",
      "Loss after mini-batch    30: 6.991\n",
      "Loss after mini-batch    40: 6.418\n",
      "Loss after mini-batch    50: 6.803\n",
      "Loss after mini-batch    60: 5.048\n",
      "Loss after mini-batch    70: 4.240\n",
      "Loss after mini-batch    80: 3.627\n",
      "Loss after mini-batch    90: 31.336\n",
      "Loss after mini-batch   100: 7.244\n",
      "Loss after mini-batch   110: 6.989\n",
      "Loss after mini-batch   120: 6.960\n",
      "Loss after mini-batch   130: 7.111\n",
      "Loss after mini-batch   140: 7.148\n",
      "Loss after mini-batch   150: 6.927\n",
      "Loss after mini-batch   160: 7.278\n",
      "Loss after mini-batch   170: 6.614\n",
      "Loss after mini-batch   180: 6.516\n",
      "Loss after mini-batch   190: 5.816\n",
      "Loss after mini-batch   200: 6.386\n",
      "Loss after mini-batch   210: 7.020\n",
      "Loss after mini-batch   220: 6.103\n",
      "Loss after mini-batch   230: 8.422\n",
      "Loss after mini-batch   240: 5.230\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 4.963\n",
      "Loss after mini-batch    20: 6.453\n",
      "Loss after mini-batch    30: 3.371\n",
      "Loss after mini-batch    40: 7.902\n",
      "Loss after mini-batch    50: 5.939\n",
      "Loss after mini-batch    60: 4.829\n",
      "Loss after mini-batch    70: 4.458\n",
      "Loss after mini-batch    80: 5.759\n",
      "Loss after mini-batch    90: 4.028\n",
      "Loss after mini-batch   100: 2.711\n",
      "Loss after mini-batch   110: 1.524\n",
      "Loss after mini-batch   120: 5.399\n",
      "Loss after mini-batch   130: 2.849\n",
      "Loss after mini-batch   140: 3.910\n",
      "Loss after mini-batch   150: 3.656\n",
      "Loss after mini-batch   160: 2.037\n",
      "Loss after mini-batch   170: 0.944\n",
      "Loss after mini-batch   180: 2.168\n",
      "Loss after mini-batch   190: 0.468\n",
      "Loss after mini-batch   200: 9.062\n",
      "Loss after mini-batch   210: 3.485\n",
      "Loss after mini-batch   220: 6.033\n",
      "Loss after mini-batch   230: 4.068\n",
      "Loss after mini-batch   240: 3.455\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.773\n",
      "Loss after mini-batch    20: 0.848\n",
      "Loss after mini-batch    30: 1.331\n",
      "Loss after mini-batch    40: 2.752\n",
      "Loss after mini-batch    50: 4.190\n",
      "Loss after mini-batch    60: 2.045\n",
      "Loss after mini-batch    70: 2.151\n",
      "Loss after mini-batch    80: 1.975\n",
      "Loss after mini-batch    90: 2.679\n",
      "Loss after mini-batch   100: 2.155\n",
      "Loss after mini-batch   110: 2.758\n",
      "Loss after mini-batch   120: 3.289\n",
      "Loss after mini-batch   130: 0.841\n",
      "Loss after mini-batch   140: 0.463\n",
      "Loss after mini-batch   150: 1.274\n",
      "Loss after mini-batch   160: 2.360\n",
      "Loss after mini-batch   170: 7.380\n",
      "Loss after mini-batch   180: 3.094\n",
      "Loss after mini-batch   190: 0.826\n",
      "Loss after mini-batch   200: 1.833\n",
      "Loss after mini-batch   210: 1.048\n",
      "Loss after mini-batch   220: 0.591\n",
      "Loss after mini-batch   230: 1.885\n",
      "Loss after mini-batch   240: 0.713\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 0.080\n",
      "Loss after mini-batch    20: 1.535\n",
      "Loss after mini-batch    30: 0.079\n",
      "Loss after mini-batch    40: 0.031\n",
      "Loss after mini-batch    50: 0.487\n",
      "Loss after mini-batch    60: 1.570\n",
      "Loss after mini-batch    70: 1.373\n",
      "Loss after mini-batch    80: 0.417\n",
      "Loss after mini-batch    90: 0.112\n",
      "Loss after mini-batch   100: 3.680\n",
      "Loss after mini-batch   110: 0.070\n",
      "Loss after mini-batch   120: 0.933\n",
      "Loss after mini-batch   130: 0.051\n",
      "Loss after mini-batch   140: 1.647\n",
      "Loss after mini-batch   150: 0.082\n",
      "Loss after mini-batch   160: 0.295\n",
      "Loss after mini-batch   170: 3.511\n",
      "Loss after mini-batch   180: 0.272\n",
      "Loss after mini-batch   190: 2.146\n",
      "Loss after mini-batch   200: 3.452\n",
      "Loss after mini-batch   210: 0.179\n",
      "Loss after mini-batch   220: 2.459\n",
      "Loss after mini-batch   230: 1.612\n",
      "Loss after mini-batch   240: 0.583\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.458\n",
      "Loss after mini-batch    20: 0.053\n",
      "Loss after mini-batch    30: 0.707\n",
      "Loss after mini-batch    40: 0.386\n",
      "Loss after mini-batch    50: 0.462\n",
      "Loss after mini-batch    60: 0.353\n",
      "Loss after mini-batch    70: 0.101\n",
      "Loss after mini-batch    80: 1.766\n",
      "Loss after mini-batch    90: 1.126\n",
      "Loss after mini-batch   100: 0.718\n",
      "Loss after mini-batch   110: 0.018\n",
      "Loss after mini-batch   120: 0.782\n",
      "Loss after mini-batch   130: 0.068\n",
      "Loss after mini-batch   140: 0.224\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.072\n",
      "Loss after mini-batch   170: 0.112\n",
      "Loss after mini-batch   180: 0.815\n",
      "Loss after mini-batch   190: 0.038\n",
      "Loss after mini-batch   200: 0.033\n",
      "Loss after mini-batch   210: 0.011\n",
      "Loss after mini-batch   220: 1.394\n",
      "Loss after mini-batch   230: 0.213\n",
      "Loss after mini-batch   240: 0.128\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    30: 0.217\n",
      "Loss after mini-batch    40: 0.003\n",
      "Loss after mini-batch    50: 0.027\n",
      "Loss after mini-batch    60: 0.028\n",
      "Loss after mini-batch    70: 0.003\n",
      "Loss after mini-batch    80: 0.397\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.060\n",
      "Loss after mini-batch   110: 0.020\n",
      "Loss after mini-batch   120: 0.371\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.003\n",
      "Loss after mini-batch   150: 0.005\n",
      "Loss after mini-batch   160: 0.014\n",
      "Loss after mini-batch   170: 0.060\n",
      "Loss after mini-batch   180: 0.003\n",
      "Loss after mini-batch   190: 0.052\n",
      "Loss after mini-batch   200: 0.007\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.002\n",
      "Loss after mini-batch   230: 0.692\n",
      "Loss after mini-batch   240: 0.131\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.201\n",
      "Loss after mini-batch    50: 0.063\n",
      "Loss after mini-batch    60: 0.004\n",
      "Loss after mini-batch    70: 0.005\n",
      "Loss after mini-batch    80: 0.002\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.024\n",
      "Loss after mini-batch   110: 1.770\n",
      "Loss after mini-batch   120: 0.007\n",
      "Loss after mini-batch   130: 0.091\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.017\n",
      "Loss after mini-batch   160: 0.128\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.002\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.020\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.001\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.005\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.002\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.005\n",
      "Loss after mini-batch    60: 0.003\n",
      "Loss after mini-batch    70: 0.002\n",
      "Loss after mini-batch    80: 0.016\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.023\n",
      "Loss after mini-batch   110: 0.123\n",
      "Loss after mini-batch   120: 0.118\n",
      "Loss after mini-batch   130: 0.807\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.013\n",
      "Loss after mini-batch   170: 0.007\n",
      "Loss after mini-batch   180: 0.003\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.007\n",
      "Loss after mini-batch   210: 0.003\n",
      "Loss after mini-batch   220: 0.038\n",
      "Loss after mini-batch   230: 0.641\n",
      "Loss after mini-batch   240: 0.180\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.091\n",
      "Loss after mini-batch    20: 0.028\n",
      "Loss after mini-batch    30: 0.005\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.076\n",
      "Loss after mini-batch    60: 0.060\n",
      "Loss after mini-batch    70: 0.018\n",
      "Loss after mini-batch    80: 4.955\n",
      "Loss after mini-batch    90: 0.036\n",
      "Loss after mini-batch   100: 7.923\n",
      "Loss after mini-batch   110: 11.799\n",
      "Loss after mini-batch   120: 1.687\n",
      "Loss after mini-batch   130: 0.071\n",
      "Loss after mini-batch   140: 0.005\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.023\n",
      "Loss after mini-batch   170: 0.053\n",
      "Loss after mini-batch   180: 0.021\n",
      "Loss after mini-batch   190: 0.792\n",
      "Loss after mini-batch   200: 0.591\n",
      "Loss after mini-batch   210: 0.007\n",
      "Loss after mini-batch   220: 0.009\n",
      "Loss after mini-batch   230: 0.371\n",
      "Loss after mini-batch   240: 0.424\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    20: 0.038\n",
      "Loss after mini-batch    30: 0.994\n",
      "Loss after mini-batch    40: 0.139\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.256\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.059\n",
      "Loss after mini-batch   100: 0.019\n",
      "Loss after mini-batch   110: 0.082\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.281\n",
      "Loss after mini-batch   140: 0.009\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.013\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.134\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.002\n",
      "Loss after mini-batch   230: 0.008\n",
      "Loss after mini-batch   240: 0.305\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 82 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 22.045\n",
      "Loss after mini-batch    20: 9.897\n",
      "Loss after mini-batch    30: 5.782\n",
      "Loss after mini-batch    40: 5.839\n",
      "Loss after mini-batch    50: 6.225\n",
      "Loss after mini-batch    60: 3.371\n",
      "Loss after mini-batch    70: 7.949\n",
      "Loss after mini-batch    80: 7.009\n",
      "Loss after mini-batch    90: 6.235\n",
      "Loss after mini-batch   100: 2.321\n",
      "Loss after mini-batch   110: 5.106\n",
      "Loss after mini-batch   120: 9.426\n",
      "Loss after mini-batch   130: 3.771\n",
      "Loss after mini-batch   140: 4.967\n",
      "Loss after mini-batch   150: 3.793\n",
      "Loss after mini-batch   160: 2.830\n",
      "Loss after mini-batch   170: 2.290\n",
      "Loss after mini-batch   180: 2.294\n",
      "Loss after mini-batch   190: 7.044\n",
      "Loss after mini-batch   200: 11.791\n",
      "Loss after mini-batch   210: 7.154\n",
      "Loss after mini-batch   220: 3.682\n",
      "Loss after mini-batch   230: 3.188\n",
      "Loss after mini-batch   240: 2.150\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 1.599\n",
      "Loss after mini-batch    20: 0.491\n",
      "Loss after mini-batch    30: 5.571\n",
      "Loss after mini-batch    40: 0.583\n",
      "Loss after mini-batch    50: 0.293\n",
      "Loss after mini-batch    60: 2.467\n",
      "Loss after mini-batch    70: 3.290\n",
      "Loss after mini-batch    80: 4.425\n",
      "Loss after mini-batch    90: 2.193\n",
      "Loss after mini-batch   100: 1.498\n",
      "Loss after mini-batch   110: 4.778\n",
      "Loss after mini-batch   120: 0.381\n",
      "Loss after mini-batch   130: 1.390\n",
      "Loss after mini-batch   140: 3.112\n",
      "Loss after mini-batch   150: 1.685\n",
      "Loss after mini-batch   160: 1.092\n",
      "Loss after mini-batch   170: 1.025\n",
      "Loss after mini-batch   180: 3.712\n",
      "Loss after mini-batch   190: 6.537\n",
      "Loss after mini-batch   200: 2.890\n",
      "Loss after mini-batch   210: 1.343\n",
      "Loss after mini-batch   220: 0.493\n",
      "Loss after mini-batch   230: 3.277\n",
      "Loss after mini-batch   240: 0.138\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.780\n",
      "Loss after mini-batch    20: 1.069\n",
      "Loss after mini-batch    30: 2.238\n",
      "Loss after mini-batch    40: 3.111\n",
      "Loss after mini-batch    50: 0.227\n",
      "Loss after mini-batch    60: 0.783\n",
      "Loss after mini-batch    70: 3.426\n",
      "Loss after mini-batch    80: 0.155\n",
      "Loss after mini-batch    90: 0.090\n",
      "Loss after mini-batch   100: 2.598\n",
      "Loss after mini-batch   110: 1.772\n",
      "Loss after mini-batch   120: 9.332\n",
      "Loss after mini-batch   130: 1.296\n",
      "Loss after mini-batch   140: 0.300\n",
      "Loss after mini-batch   150: 0.388\n",
      "Loss after mini-batch   160: 0.188\n",
      "Loss after mini-batch   170: 3.040\n",
      "Loss after mini-batch   180: 1.904\n",
      "Loss after mini-batch   190: 0.494\n",
      "Loss after mini-batch   200: 1.560\n",
      "Loss after mini-batch   210: 1.117\n",
      "Loss after mini-batch   220: 1.982\n",
      "Loss after mini-batch   230: 0.178\n",
      "Loss after mini-batch   240: 0.668\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 0.315\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    30: 0.178\n",
      "Loss after mini-batch    40: 0.763\n",
      "Loss after mini-batch    50: 0.103\n",
      "Loss after mini-batch    60: 0.063\n",
      "Loss after mini-batch    70: 0.040\n",
      "Loss after mini-batch    80: 0.085\n",
      "Loss after mini-batch    90: 0.431\n",
      "Loss after mini-batch   100: 0.030\n",
      "Loss after mini-batch   110: 0.008\n",
      "Loss after mini-batch   120: 0.412\n",
      "Loss after mini-batch   130: 1.343\n",
      "Loss after mini-batch   140: 0.005\n",
      "Loss after mini-batch   150: 5.364\n",
      "Loss after mini-batch   160: 0.607\n",
      "Loss after mini-batch   170: 0.010\n",
      "Loss after mini-batch   180: 0.140\n",
      "Loss after mini-batch   190: 0.804\n",
      "Loss after mini-batch   200: 0.408\n",
      "Loss after mini-batch   210: 0.175\n",
      "Loss after mini-batch   220: 0.133\n",
      "Loss after mini-batch   230: 0.001\n",
      "Loss after mini-batch   240: 0.150\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    30: 0.006\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.164\n",
      "Loss after mini-batch    60: 0.028\n",
      "Loss after mini-batch    70: 0.072\n",
      "Loss after mini-batch    80: 0.225\n",
      "Loss after mini-batch    90: 0.028\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.003\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.714\n",
      "Loss after mini-batch   140: 0.011\n",
      "Loss after mini-batch   150: 0.055\n",
      "Loss after mini-batch   160: 0.627\n",
      "Loss after mini-batch   170: 0.008\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.007\n",
      "Loss after mini-batch   200: 0.078\n",
      "Loss after mini-batch   210: 0.185\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.010\n",
      "Loss after mini-batch   240: 0.102\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.011\n",
      "Loss after mini-batch    30: 0.101\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.238\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.027\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.063\n",
      "Loss after mini-batch   160: 0.017\n",
      "Loss after mini-batch   170: 0.709\n",
      "Loss after mini-batch   180: 0.063\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.068\n",
      "Loss after mini-batch   230: 0.036\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.212\n",
      "Loss after mini-batch    30: 0.506\n",
      "Loss after mini-batch    40: 0.005\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.003\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.004\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.313\n",
      "Loss after mini-batch   180: 0.024\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.022\n",
      "Loss after mini-batch   210: 0.046\n",
      "Loss after mini-batch   220: 0.010\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.004\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.043\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.095\n",
      "Loss after mini-batch   110: 0.109\n",
      "Loss after mini-batch   120: 0.004\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.109\n",
      "Loss after mini-batch   150: 0.055\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.003\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.017\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.009\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.249\n",
      "Loss after mini-batch   110: 4.918\n",
      "Loss after mini-batch   120: 4.332\n",
      "Loss after mini-batch   130: 16.926\n",
      "Loss after mini-batch   140: 1.747\n",
      "Loss after mini-batch   150: 4.719\n",
      "Loss after mini-batch   160: 0.603\n",
      "Loss after mini-batch   170: 1.818\n",
      "Loss after mini-batch   180: 3.948\n",
      "Loss after mini-batch   190: 0.385\n",
      "Loss after mini-batch   200: 0.259\n",
      "Loss after mini-batch   210: 0.053\n",
      "Loss after mini-batch   220: 2.161\n",
      "Loss after mini-batch   230: 12.207\n",
      "Loss after mini-batch   240: 2.417\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 3.281\n",
      "Loss after mini-batch    20: 0.408\n",
      "Loss after mini-batch    30: 0.057\n",
      "Loss after mini-batch    40: 0.174\n",
      "Loss after mini-batch    50: 0.322\n",
      "Loss after mini-batch    60: 0.213\n",
      "Loss after mini-batch    70: 0.164\n",
      "Loss after mini-batch    80: 0.004\n",
      "Loss after mini-batch    90: 0.220\n",
      "Loss after mini-batch   100: 0.008\n",
      "Loss after mini-batch   110: 0.848\n",
      "Loss after mini-batch   120: 0.888\n",
      "Loss after mini-batch   130: 0.028\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.068\n",
      "Loss after mini-batch   160: 0.063\n",
      "Loss after mini-batch   170: 18.820\n",
      "Loss after mini-batch   180: 1.875\n",
      "Loss after mini-batch   190: 0.028\n",
      "Loss after mini-batch   200: 0.054\n",
      "Loss after mini-batch   210: 0.032\n",
      "Loss after mini-batch   220: 0.053\n",
      "Loss after mini-batch   230: 1.070\n",
      "Loss after mini-batch   240: 0.129\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 82 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 12.641\n",
      "Loss after mini-batch    20: 9.036\n",
      "Loss after mini-batch    30: 7.546\n",
      "Loss after mini-batch    40: 8.715\n",
      "Loss after mini-batch    50: 9.212\n",
      "Loss after mini-batch    60: 6.477\n",
      "Loss after mini-batch    70: 7.206\n",
      "Loss after mini-batch    80: 6.926\n",
      "Loss after mini-batch    90: 6.800\n",
      "Loss after mini-batch   100: 5.357\n",
      "Loss after mini-batch   110: 7.706\n",
      "Loss after mini-batch   120: 5.240\n",
      "Loss after mini-batch   130: 6.866\n",
      "Loss after mini-batch   140: 5.500\n",
      "Loss after mini-batch   150: 2.335\n",
      "Loss after mini-batch   160: 15.083\n",
      "Loss after mini-batch   170: 12.380\n",
      "Loss after mini-batch   180: 4.076\n",
      "Loss after mini-batch   190: 8.930\n",
      "Loss after mini-batch   200: 4.878\n",
      "Loss after mini-batch   210: 5.587\n",
      "Loss after mini-batch   220: 3.045\n",
      "Loss after mini-batch   230: 5.038\n",
      "Loss after mini-batch   240: 1.685\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 2.236\n",
      "Loss after mini-batch    20: 5.424\n",
      "Loss after mini-batch    30: 9.481\n",
      "Loss after mini-batch    40: 2.291\n",
      "Loss after mini-batch    50: 3.797\n",
      "Loss after mini-batch    60: 4.137\n",
      "Loss after mini-batch    70: 2.583\n",
      "Loss after mini-batch    80: 3.968\n",
      "Loss after mini-batch    90: 2.853\n",
      "Loss after mini-batch   100: 2.931\n",
      "Loss after mini-batch   110: 4.254\n",
      "Loss after mini-batch   120: 5.032\n",
      "Loss after mini-batch   130: 4.310\n",
      "Loss after mini-batch   140: 3.322\n",
      "Loss after mini-batch   150: 2.027\n",
      "Loss after mini-batch   160: 4.700\n",
      "Loss after mini-batch   170: 1.976\n",
      "Loss after mini-batch   180: 2.626\n",
      "Loss after mini-batch   190: 1.785\n",
      "Loss after mini-batch   200: 3.696\n",
      "Loss after mini-batch   210: 2.215\n",
      "Loss after mini-batch   220: 4.549\n",
      "Loss after mini-batch   230: 1.161\n",
      "Loss after mini-batch   240: 2.629\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.871\n",
      "Loss after mini-batch    20: 1.236\n",
      "Loss after mini-batch    30: 1.398\n",
      "Loss after mini-batch    40: 2.504\n",
      "Loss after mini-batch    50: 0.816\n",
      "Loss after mini-batch    60: 0.185\n",
      "Loss after mini-batch    70: 0.535\n",
      "Loss after mini-batch    80: 3.463\n",
      "Loss after mini-batch    90: 1.733\n",
      "Loss after mini-batch   100: 0.802\n",
      "Loss after mini-batch   110: 2.032\n",
      "Loss after mini-batch   120: 0.073\n",
      "Loss after mini-batch   130: 8.790\n",
      "Loss after mini-batch   140: 1.381\n",
      "Loss after mini-batch   150: 3.409\n",
      "Loss after mini-batch   160: 0.637\n",
      "Loss after mini-batch   170: 0.120\n",
      "Loss after mini-batch   180: 3.683\n",
      "Loss after mini-batch   190: 0.791\n",
      "Loss after mini-batch   200: 0.805\n",
      "Loss after mini-batch   210: 1.905\n",
      "Loss after mini-batch   220: 0.819\n",
      "Loss after mini-batch   230: 1.622\n",
      "Loss after mini-batch   240: 0.740\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 3.462\n",
      "Loss after mini-batch    20: 0.595\n",
      "Loss after mini-batch    30: 0.045\n",
      "Loss after mini-batch    40: 1.226\n",
      "Loss after mini-batch    50: 4.802\n",
      "Loss after mini-batch    60: 4.689\n",
      "Loss after mini-batch    70: 1.711\n",
      "Loss after mini-batch    80: 0.163\n",
      "Loss after mini-batch    90: 1.773\n",
      "Loss after mini-batch   100: 0.191\n",
      "Loss after mini-batch   110: 0.796\n",
      "Loss after mini-batch   120: 0.625\n",
      "Loss after mini-batch   130: 1.397\n",
      "Loss after mini-batch   140: 0.297\n",
      "Loss after mini-batch   150: 0.108\n",
      "Loss after mini-batch   160: 0.292\n",
      "Loss after mini-batch   170: 0.328\n",
      "Loss after mini-batch   180: 0.017\n",
      "Loss after mini-batch   190: 0.082\n",
      "Loss after mini-batch   200: 0.065\n",
      "Loss after mini-batch   210: 3.321\n",
      "Loss after mini-batch   220: 0.843\n",
      "Loss after mini-batch   230: 0.363\n",
      "Loss after mini-batch   240: 1.337\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.984\n",
      "Loss after mini-batch    20: 0.108\n",
      "Loss after mini-batch    30: 0.101\n",
      "Loss after mini-batch    40: 0.093\n",
      "Loss after mini-batch    50: 0.196\n",
      "Loss after mini-batch    60: 0.047\n",
      "Loss after mini-batch    70: 0.168\n",
      "Loss after mini-batch    80: 0.026\n",
      "Loss after mini-batch    90: 0.012\n",
      "Loss after mini-batch   100: 0.299\n",
      "Loss after mini-batch   110: 0.178\n",
      "Loss after mini-batch   120: 1.199\n",
      "Loss after mini-batch   130: 0.083\n",
      "Loss after mini-batch   140: 0.180\n",
      "Loss after mini-batch   150: 0.116\n",
      "Loss after mini-batch   160: 0.070\n",
      "Loss after mini-batch   170: 0.486\n",
      "Loss after mini-batch   180: 0.026\n",
      "Loss after mini-batch   190: 0.777\n",
      "Loss after mini-batch   200: 0.003\n",
      "Loss after mini-batch   210: 0.014\n",
      "Loss after mini-batch   220: 0.553\n",
      "Loss after mini-batch   230: 0.038\n",
      "Loss after mini-batch   240: 0.048\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.467\n",
      "Loss after mini-batch    20: 4.502\n",
      "Loss after mini-batch    30: 0.051\n",
      "Loss after mini-batch    40: 5.543\n",
      "Loss after mini-batch    50: 0.070\n",
      "Loss after mini-batch    60: 0.281\n",
      "Loss after mini-batch    70: 1.167\n",
      "Loss after mini-batch    80: 0.224\n",
      "Loss after mini-batch    90: 0.042\n",
      "Loss after mini-batch   100: 0.061\n",
      "Loss after mini-batch   110: 0.053\n",
      "Loss after mini-batch   120: 0.161\n",
      "Loss after mini-batch   130: 0.037\n",
      "Loss after mini-batch   140: 2.840\n",
      "Loss after mini-batch   150: 0.044\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 1.367\n",
      "Loss after mini-batch   180: 0.021\n",
      "Loss after mini-batch   190: 0.006\n",
      "Loss after mini-batch   200: 0.006\n",
      "Loss after mini-batch   210: 0.137\n",
      "Loss after mini-batch   220: 2.346\n",
      "Loss after mini-batch   230: 2.301\n",
      "Loss after mini-batch   240: 0.334\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 7.157\n",
      "Loss after mini-batch    20: 0.016\n",
      "Loss after mini-batch    30: 2.133\n",
      "Loss after mini-batch    40: 0.110\n",
      "Loss after mini-batch    50: 0.084\n",
      "Loss after mini-batch    60: 0.592\n",
      "Loss after mini-batch    70: 0.111\n",
      "Loss after mini-batch    80: 0.564\n",
      "Loss after mini-batch    90: 0.289\n",
      "Loss after mini-batch   100: 0.582\n",
      "Loss after mini-batch   110: 0.006\n",
      "Loss after mini-batch   120: 0.136\n",
      "Loss after mini-batch   130: 0.024\n",
      "Loss after mini-batch   140: 0.290\n",
      "Loss after mini-batch   150: 2.488\n",
      "Loss after mini-batch   160: 0.142\n",
      "Loss after mini-batch   170: 0.179\n",
      "Loss after mini-batch   180: 0.071\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.020\n",
      "Loss after mini-batch   210: 0.078\n",
      "Loss after mini-batch   220: 0.380\n",
      "Loss after mini-batch   230: 0.004\n",
      "Loss after mini-batch   240: 0.016\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.084\n",
      "Loss after mini-batch    40: 0.019\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.008\n",
      "Loss after mini-batch    70: 0.011\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.003\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.055\n",
      "Loss after mini-batch   140: 0.070\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.012\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.009\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.025\n",
      "Loss after mini-batch   210: 0.009\n",
      "Loss after mini-batch   220: 0.029\n",
      "Loss after mini-batch   230: 0.739\n",
      "Loss after mini-batch   240: 0.028\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.094\n",
      "Loss after mini-batch    50: 0.002\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.015\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.002\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.009\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.016\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.023\n",
      "Loss after mini-batch   200: 0.003\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.001\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.047\n",
      "Loss after mini-batch    50: 0.006\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.012\n",
      "Loss after mini-batch   100: 0.003\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.002\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.057\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.004\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.023\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.001\n",
      "Loss after mini-batch   240: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 92 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 12.410\n",
      "Loss after mini-batch    20: 8.208\n",
      "Loss after mini-batch    30: 8.818\n",
      "Loss after mini-batch    40: 4.928\n",
      "Loss after mini-batch    50: 7.109\n",
      "Loss after mini-batch    60: 5.801\n",
      "Loss after mini-batch    70: 5.743\n",
      "Loss after mini-batch    80: 4.410\n",
      "Loss after mini-batch    90: 4.856\n",
      "Loss after mini-batch   100: 2.299\n",
      "Loss after mini-batch   110: 6.845\n",
      "Loss after mini-batch   120: 5.160\n",
      "Loss after mini-batch   130: 4.858\n",
      "Loss after mini-batch   140: 5.561\n",
      "Loss after mini-batch   150: 5.057\n",
      "Loss after mini-batch   160: 6.988\n",
      "Loss after mini-batch   170: 4.089\n",
      "Loss after mini-batch   180: 7.489\n",
      "Loss after mini-batch   190: 5.458\n",
      "Loss after mini-batch   200: 2.489\n",
      "Loss after mini-batch   210: 4.437\n",
      "Loss after mini-batch   220: 4.103\n",
      "Loss after mini-batch   230: 5.002\n",
      "Loss after mini-batch   240: 3.689\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 3.429\n",
      "Loss after mini-batch    20: 2.754\n",
      "Loss after mini-batch    30: 2.029\n",
      "Loss after mini-batch    40: 1.571\n",
      "Loss after mini-batch    50: 6.452\n",
      "Loss after mini-batch    60: 2.205\n",
      "Loss after mini-batch    70: 2.458\n",
      "Loss after mini-batch    80: 1.803\n",
      "Loss after mini-batch    90: 3.220\n",
      "Loss after mini-batch   100: 0.675\n",
      "Loss after mini-batch   110: 3.183\n",
      "Loss after mini-batch   120: 2.535\n",
      "Loss after mini-batch   130: 4.472\n",
      "Loss after mini-batch   140: 1.536\n",
      "Loss after mini-batch   150: 0.327\n",
      "Loss after mini-batch   160: 1.156\n",
      "Loss after mini-batch   170: 1.379\n",
      "Loss after mini-batch   180: 6.378\n",
      "Loss after mini-batch   190: 3.293\n",
      "Loss after mini-batch   200: 2.007\n",
      "Loss after mini-batch   210: 3.524\n",
      "Loss after mini-batch   220: 4.582\n",
      "Loss after mini-batch   230: 0.397\n",
      "Loss after mini-batch   240: 2.337\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.427\n",
      "Loss after mini-batch    20: 1.631\n",
      "Loss after mini-batch    30: 1.446\n",
      "Loss after mini-batch    40: 2.570\n",
      "Loss after mini-batch    50: 2.448\n",
      "Loss after mini-batch    60: 1.023\n",
      "Loss after mini-batch    70: 2.532\n",
      "Loss after mini-batch    80: 2.298\n",
      "Loss after mini-batch    90: 2.291\n",
      "Loss after mini-batch   100: 0.767\n",
      "Loss after mini-batch   110: 0.341\n",
      "Loss after mini-batch   120: 1.065\n",
      "Loss after mini-batch   130: 0.657\n",
      "Loss after mini-batch   140: 0.228\n",
      "Loss after mini-batch   150: 0.161\n",
      "Loss after mini-batch   160: 0.861\n",
      "Loss after mini-batch   170: 1.164\n",
      "Loss after mini-batch   180: 1.413\n",
      "Loss after mini-batch   190: 0.205\n",
      "Loss after mini-batch   200: 0.568\n",
      "Loss after mini-batch   210: 0.501\n",
      "Loss after mini-batch   220: 0.020\n",
      "Loss after mini-batch   230: 0.215\n",
      "Loss after mini-batch   240: 0.862\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 0.043\n",
      "Loss after mini-batch    20: 0.119\n",
      "Loss after mini-batch    30: 0.207\n",
      "Loss after mini-batch    40: 0.028\n",
      "Loss after mini-batch    50: 4.576\n",
      "Loss after mini-batch    60: 1.814\n",
      "Loss after mini-batch    70: 2.503\n",
      "Loss after mini-batch    80: 0.088\n",
      "Loss after mini-batch    90: 0.661\n",
      "Loss after mini-batch   100: 0.758\n",
      "Loss after mini-batch   110: 0.677\n",
      "Loss after mini-batch   120: 0.292\n",
      "Loss after mini-batch   130: 1.264\n",
      "Loss after mini-batch   140: 0.224\n",
      "Loss after mini-batch   150: 0.598\n",
      "Loss after mini-batch   160: 0.609\n",
      "Loss after mini-batch   170: 0.818\n",
      "Loss after mini-batch   180: 0.015\n",
      "Loss after mini-batch   190: 0.913\n",
      "Loss after mini-batch   200: 0.193\n",
      "Loss after mini-batch   210: 0.809\n",
      "Loss after mini-batch   220: 1.238\n",
      "Loss after mini-batch   230: 0.806\n",
      "Loss after mini-batch   240: 0.009\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.088\n",
      "Loss after mini-batch    20: 0.087\n",
      "Loss after mini-batch    30: 0.579\n",
      "Loss after mini-batch    40: 0.029\n",
      "Loss after mini-batch    50: 0.120\n",
      "Loss after mini-batch    60: 0.362\n",
      "Loss after mini-batch    70: 0.036\n",
      "Loss after mini-batch    80: 0.188\n",
      "Loss after mini-batch    90: 0.157\n",
      "Loss after mini-batch   100: 0.406\n",
      "Loss after mini-batch   110: 0.188\n",
      "Loss after mini-batch   120: 0.010\n",
      "Loss after mini-batch   130: 0.908\n",
      "Loss after mini-batch   140: 0.034\n",
      "Loss after mini-batch   150: 0.027\n",
      "Loss after mini-batch   160: 0.005\n",
      "Loss after mini-batch   170: 0.103\n",
      "Loss after mini-batch   180: 0.034\n",
      "Loss after mini-batch   190: 0.030\n",
      "Loss after mini-batch   200: 0.003\n",
      "Loss after mini-batch   210: 0.103\n",
      "Loss after mini-batch   220: 0.001\n",
      "Loss after mini-batch   230: 0.001\n",
      "Loss after mini-batch   240: 0.068\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.017\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.004\n",
      "Loss after mini-batch    60: 0.007\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.006\n",
      "Loss after mini-batch    90: 0.268\n",
      "Loss after mini-batch   100: 0.162\n",
      "Loss after mini-batch   110: 0.008\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.019\n",
      "Loss after mini-batch   150: 0.008\n",
      "Loss after mini-batch   160: 0.042\n",
      "Loss after mini-batch   170: 0.553\n",
      "Loss after mini-batch   180: 0.027\n",
      "Loss after mini-batch   190: 0.010\n",
      "Loss after mini-batch   200: 0.365\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.006\n",
      "Loss after mini-batch   230: 0.003\n",
      "Loss after mini-batch   240: 0.041\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    30: 0.008\n",
      "Loss after mini-batch    40: 0.015\n",
      "Loss after mini-batch    50: 0.274\n",
      "Loss after mini-batch    60: 0.153\n",
      "Loss after mini-batch    70: 0.019\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.004\n",
      "Loss after mini-batch   110: 0.006\n",
      "Loss after mini-batch   120: 0.003\n",
      "Loss after mini-batch   130: 0.003\n",
      "Loss after mini-batch   140: 0.003\n",
      "Loss after mini-batch   150: 0.003\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.101\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 5.128\n",
      "Loss after mini-batch   220: 9.442\n",
      "Loss after mini-batch   230: 0.027\n",
      "Loss after mini-batch   240: 2.940\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.694\n",
      "Loss after mini-batch    20: 0.015\n",
      "Loss after mini-batch    30: 0.772\n",
      "Loss after mini-batch    40: 0.027\n",
      "Loss after mini-batch    50: 2.977\n",
      "Loss after mini-batch    60: 1.803\n",
      "Loss after mini-batch    70: 0.543\n",
      "Loss after mini-batch    80: 10.107\n",
      "Loss after mini-batch    90: 0.126\n",
      "Loss after mini-batch   100: 0.855\n",
      "Loss after mini-batch   110: 0.041\n",
      "Loss after mini-batch   120: 0.423\n",
      "Loss after mini-batch   130: 3.973\n",
      "Loss after mini-batch   140: 6.349\n",
      "Loss after mini-batch   150: 1.109\n",
      "Loss after mini-batch   160: 4.474\n",
      "Loss after mini-batch   170: 0.030\n",
      "Loss after mini-batch   180: 0.205\n",
      "Loss after mini-batch   190: 2.797\n",
      "Loss after mini-batch   200: 0.204\n",
      "Loss after mini-batch   210: 0.510\n",
      "Loss after mini-batch   220: 0.373\n",
      "Loss after mini-batch   230: 0.124\n",
      "Loss after mini-batch   240: 0.117\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.032\n",
      "Loss after mini-batch    20: 0.105\n",
      "Loss after mini-batch    30: 0.498\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 0.229\n",
      "Loss after mini-batch    60: 0.228\n",
      "Loss after mini-batch    70: 0.051\n",
      "Loss after mini-batch    80: 0.059\n",
      "Loss after mini-batch    90: 0.170\n",
      "Loss after mini-batch   100: 1.599\n",
      "Loss after mini-batch   110: 0.007\n",
      "Loss after mini-batch   120: 6.647\n",
      "Loss after mini-batch   130: 0.096\n",
      "Loss after mini-batch   140: 0.294\n",
      "Loss after mini-batch   150: 0.454\n",
      "Loss after mini-batch   160: 1.036\n",
      "Loss after mini-batch   170: 0.196\n",
      "Loss after mini-batch   180: 0.565\n",
      "Loss after mini-batch   190: 0.017\n",
      "Loss after mini-batch   200: 0.336\n",
      "Loss after mini-batch   210: 0.004\n",
      "Loss after mini-batch   220: 0.008\n",
      "Loss after mini-batch   230: 0.047\n",
      "Loss after mini-batch   240: 0.002\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.086\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.167\n",
      "Loss after mini-batch    40: 0.093\n",
      "Loss after mini-batch    50: 0.482\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.127\n",
      "Loss after mini-batch    80: 0.006\n",
      "Loss after mini-batch    90: 0.016\n",
      "Loss after mini-batch   100: 0.008\n",
      "Loss after mini-batch   110: 0.058\n",
      "Loss after mini-batch   120: 0.405\n",
      "Loss after mini-batch   130: 0.028\n",
      "Loss after mini-batch   140: 0.221\n",
      "Loss after mini-batch   150: 1.148\n",
      "Loss after mini-batch   160: 0.060\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.652\n",
      "Loss after mini-batch   190: 0.006\n",
      "Loss after mini-batch   200: 0.025\n",
      "Loss after mini-batch   210: 0.409\n",
      "Loss after mini-batch   220: 0.004\n",
      "Loss after mini-batch   230: 0.003\n",
      "Loss after mini-batch   240: 0.344\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 97 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 21.623\n",
      "Loss after mini-batch    20: 16.728\n",
      "Loss after mini-batch    30: 7.331\n",
      "Loss after mini-batch    40: 6.944\n",
      "Loss after mini-batch    50: 6.579\n",
      "Loss after mini-batch    60: 7.206\n",
      "Loss after mini-batch    70: 6.278\n",
      "Loss after mini-batch    80: 5.065\n",
      "Loss after mini-batch    90: 5.751\n",
      "Loss after mini-batch   100: 2.600\n",
      "Loss after mini-batch   110: 7.951\n",
      "Loss after mini-batch   120: 1.243\n",
      "Loss after mini-batch   130: 4.061\n",
      "Loss after mini-batch   140: 9.133\n",
      "Loss after mini-batch   150: 6.724\n",
      "Loss after mini-batch   160: 1.233\n",
      "Loss after mini-batch   170: 5.002\n",
      "Loss after mini-batch   180: 9.447\n",
      "Loss after mini-batch   190: 2.313\n",
      "Loss after mini-batch   200: 3.903\n",
      "Loss after mini-batch   210: 8.203\n",
      "Loss after mini-batch   220: 2.840\n",
      "Loss after mini-batch   230: 3.587\n",
      "Loss after mini-batch   240: 5.131\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 1.543\n",
      "Loss after mini-batch    20: 3.188\n",
      "Loss after mini-batch    30: 2.487\n",
      "Loss after mini-batch    40: 3.548\n",
      "Loss after mini-batch    50: 1.896\n",
      "Loss after mini-batch    60: 5.614\n",
      "Loss after mini-batch    70: 4.135\n",
      "Loss after mini-batch    80: 3.394\n",
      "Loss after mini-batch    90: 3.067\n",
      "Loss after mini-batch   100: 7.452\n",
      "Loss after mini-batch   110: 2.984\n",
      "Loss after mini-batch   120: 3.354\n",
      "Loss after mini-batch   130: 1.110\n",
      "Loss after mini-batch   140: 2.892\n",
      "Loss after mini-batch   150: 4.668\n",
      "Loss after mini-batch   160: 0.744\n",
      "Loss after mini-batch   170: 2.279\n",
      "Loss after mini-batch   180: 0.504\n",
      "Loss after mini-batch   190: 3.666\n",
      "Loss after mini-batch   200: 0.605\n",
      "Loss after mini-batch   210: 1.322\n",
      "Loss after mini-batch   220: 1.267\n",
      "Loss after mini-batch   230: 5.197\n",
      "Loss after mini-batch   240: 1.658\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.101\n",
      "Loss after mini-batch    20: 1.456\n",
      "Loss after mini-batch    30: 3.060\n",
      "Loss after mini-batch    40: 2.264\n",
      "Loss after mini-batch    50: 3.287\n",
      "Loss after mini-batch    60: 0.147\n",
      "Loss after mini-batch    70: 0.877\n",
      "Loss after mini-batch    80: 0.566\n",
      "Loss after mini-batch    90: 0.119\n",
      "Loss after mini-batch   100: 0.460\n",
      "Loss after mini-batch   110: 0.064\n",
      "Loss after mini-batch   120: 0.242\n",
      "Loss after mini-batch   130: 4.188\n",
      "Loss after mini-batch   140: 0.711\n",
      "Loss after mini-batch   150: 0.135\n",
      "Loss after mini-batch   160: 0.189\n",
      "Loss after mini-batch   170: 0.041\n",
      "Loss after mini-batch   180: 0.022\n",
      "Loss after mini-batch   190: 0.807\n",
      "Loss after mini-batch   200: 4.611\n",
      "Loss after mini-batch   210: 2.050\n",
      "Loss after mini-batch   220: 0.972\n",
      "Loss after mini-batch   230: 0.620\n",
      "Loss after mini-batch   240: 1.401\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 0.424\n",
      "Loss after mini-batch    20: 0.043\n",
      "Loss after mini-batch    30: 0.023\n",
      "Loss after mini-batch    40: 0.240\n",
      "Loss after mini-batch    50: 0.238\n",
      "Loss after mini-batch    60: 1.550\n",
      "Loss after mini-batch    70: 0.154\n",
      "Loss after mini-batch    80: 0.253\n",
      "Loss after mini-batch    90: 0.419\n",
      "Loss after mini-batch   100: 0.049\n",
      "Loss after mini-batch   110: 0.475\n",
      "Loss after mini-batch   120: 0.415\n",
      "Loss after mini-batch   130: 0.030\n",
      "Loss after mini-batch   140: 0.029\n",
      "Loss after mini-batch   150: 0.048\n",
      "Loss after mini-batch   160: 0.083\n",
      "Loss after mini-batch   170: 0.071\n",
      "Loss after mini-batch   180: 0.010\n",
      "Loss after mini-batch   190: 0.018\n",
      "Loss after mini-batch   200: 0.013\n",
      "Loss after mini-batch   210: 0.014\n",
      "Loss after mini-batch   220: 0.762\n",
      "Loss after mini-batch   230: 0.763\n",
      "Loss after mini-batch   240: 0.033\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.022\n",
      "Loss after mini-batch    20: 0.082\n",
      "Loss after mini-batch    30: 0.007\n",
      "Loss after mini-batch    40: 0.078\n",
      "Loss after mini-batch    50: 0.008\n",
      "Loss after mini-batch    60: 0.028\n",
      "Loss after mini-batch    70: 0.003\n",
      "Loss after mini-batch    80: 0.017\n",
      "Loss after mini-batch    90: 0.002\n",
      "Loss after mini-batch   100: 0.015\n",
      "Loss after mini-batch   110: 0.004\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.037\n",
      "Loss after mini-batch   140: 0.018\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.005\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.389\n",
      "Loss after mini-batch   190: 0.051\n",
      "Loss after mini-batch   200: 0.024\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.147\n",
      "Loss after mini-batch   230: 0.186\n",
      "Loss after mini-batch   240: 0.003\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.004\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.037\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.008\n",
      "Loss after mini-batch    80: 0.003\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.008\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.003\n",
      "Loss after mini-batch   150: 0.007\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.009\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.076\n",
      "Loss after mini-batch   230: 0.044\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.031\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.002\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.006\n",
      "Loss after mini-batch   130: 0.011\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.009\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.004\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.016\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.003\n",
      "Loss after mini-batch   230: 0.009\n",
      "Loss after mini-batch   240: 0.006\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.002\n",
      "Loss after mini-batch    80: 0.001\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.007\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.002\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.002\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.001\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.003\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.001\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.002\n",
      "Loss after mini-batch   240: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 82 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 27.347\n",
      "Loss after mini-batch    20: 7.836\n",
      "Loss after mini-batch    30: 7.036\n",
      "Loss after mini-batch    40: 6.194\n",
      "Loss after mini-batch    50: 5.256\n",
      "Loss after mini-batch    60: 5.353\n",
      "Loss after mini-batch    70: 4.131\n",
      "Loss after mini-batch    80: 1.961\n",
      "Loss after mini-batch    90: 6.036\n",
      "Loss after mini-batch   100: 2.796\n",
      "Loss after mini-batch   110: 3.648\n",
      "Loss after mini-batch   120: 17.438\n",
      "Loss after mini-batch   130: 7.654\n",
      "Loss after mini-batch   140: 5.884\n",
      "Loss after mini-batch   150: 3.492\n",
      "Loss after mini-batch   160: 4.971\n",
      "Loss after mini-batch   170: 1.376\n",
      "Loss after mini-batch   180: 4.730\n",
      "Loss after mini-batch   190: 3.491\n",
      "Loss after mini-batch   200: 6.697\n",
      "Loss after mini-batch   210: 4.460\n",
      "Loss after mini-batch   220: 5.542\n",
      "Loss after mini-batch   230: 9.750\n",
      "Loss after mini-batch   240: 5.028\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 2.861\n",
      "Loss after mini-batch    20: 3.434\n",
      "Loss after mini-batch    30: 1.132\n",
      "Loss after mini-batch    40: 6.295\n",
      "Loss after mini-batch    50: 5.940\n",
      "Loss after mini-batch    60: 5.759\n",
      "Loss after mini-batch    70: 4.639\n",
      "Loss after mini-batch    80: 3.192\n",
      "Loss after mini-batch    90: 1.647\n",
      "Loss after mini-batch   100: 2.390\n",
      "Loss after mini-batch   110: 2.092\n",
      "Loss after mini-batch   120: 0.186\n",
      "Loss after mini-batch   130: 2.815\n",
      "Loss after mini-batch   140: 1.521\n",
      "Loss after mini-batch   150: 0.402\n",
      "Loss after mini-batch   160: 3.076\n",
      "Loss after mini-batch   170: 2.844\n",
      "Loss after mini-batch   180: 1.669\n",
      "Loss after mini-batch   190: 0.830\n",
      "Loss after mini-batch   200: 0.345\n",
      "Loss after mini-batch   210: 2.251\n",
      "Loss after mini-batch   220: 1.890\n",
      "Loss after mini-batch   230: 4.537\n",
      "Loss after mini-batch   240: 1.558\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.992\n",
      "Loss after mini-batch    20: 0.936\n",
      "Loss after mini-batch    30: 1.279\n",
      "Loss after mini-batch    40: 0.260\n",
      "Loss after mini-batch    50: 0.441\n",
      "Loss after mini-batch    60: 0.221\n",
      "Loss after mini-batch    70: 0.269\n",
      "Loss after mini-batch    80: 0.145\n",
      "Loss after mini-batch    90: 0.099\n",
      "Loss after mini-batch   100: 0.064\n",
      "Loss after mini-batch   110: 3.047\n",
      "Loss after mini-batch   120: 0.038\n",
      "Loss after mini-batch   130: 1.675\n",
      "Loss after mini-batch   140: 0.730\n",
      "Loss after mini-batch   150: 3.841\n",
      "Loss after mini-batch   160: 0.222\n",
      "Loss after mini-batch   170: 0.386\n",
      "Loss after mini-batch   180: 0.147\n",
      "Loss after mini-batch   190: 2.447\n",
      "Loss after mini-batch   200: 0.385\n",
      "Loss after mini-batch   210: 2.084\n",
      "Loss after mini-batch   220: 3.187\n",
      "Loss after mini-batch   230: 1.000\n",
      "Loss after mini-batch   240: 2.470\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 1.221\n",
      "Loss after mini-batch    20: 0.407\n",
      "Loss after mini-batch    30: 0.006\n",
      "Loss after mini-batch    40: 8.417\n",
      "Loss after mini-batch    50: 1.924\n",
      "Loss after mini-batch    60: 5.569\n",
      "Loss after mini-batch    70: 1.205\n",
      "Loss after mini-batch    80: 0.927\n",
      "Loss after mini-batch    90: 0.519\n",
      "Loss after mini-batch   100: 0.781\n",
      "Loss after mini-batch   110: 0.978\n",
      "Loss after mini-batch   120: 0.447\n",
      "Loss after mini-batch   130: 0.532\n",
      "Loss after mini-batch   140: 0.046\n",
      "Loss after mini-batch   150: 0.395\n",
      "Loss after mini-batch   160: 0.258\n",
      "Loss after mini-batch   170: 1.290\n",
      "Loss after mini-batch   180: 0.158\n",
      "Loss after mini-batch   190: 4.080\n",
      "Loss after mini-batch   200: 0.147\n",
      "Loss after mini-batch   210: 0.655\n",
      "Loss after mini-batch   220: 0.495\n",
      "Loss after mini-batch   230: 1.873\n",
      "Loss after mini-batch   240: 1.057\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.259\n",
      "Loss after mini-batch    20: 0.248\n",
      "Loss after mini-batch    30: 0.082\n",
      "Loss after mini-batch    40: 0.033\n",
      "Loss after mini-batch    50: 0.163\n",
      "Loss after mini-batch    60: 0.030\n",
      "Loss after mini-batch    70: 0.019\n",
      "Loss after mini-batch    80: 0.052\n",
      "Loss after mini-batch    90: 5.277\n",
      "Loss after mini-batch   100: 0.092\n",
      "Loss after mini-batch   110: 0.003\n",
      "Loss after mini-batch   120: 0.303\n",
      "Loss after mini-batch   130: 1.266\n",
      "Loss after mini-batch   140: 0.641\n",
      "Loss after mini-batch   150: 0.346\n",
      "Loss after mini-batch   160: 0.039\n",
      "Loss after mini-batch   170: 0.112\n",
      "Loss after mini-batch   180: 0.054\n",
      "Loss after mini-batch   190: 0.015\n",
      "Loss after mini-batch   200: 0.016\n",
      "Loss after mini-batch   210: 0.034\n",
      "Loss after mini-batch   220: 0.158\n",
      "Loss after mini-batch   230: 0.030\n",
      "Loss after mini-batch   240: 0.006\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.095\n",
      "Loss after mini-batch    20: 1.141\n",
      "Loss after mini-batch    30: 0.204\n",
      "Loss after mini-batch    40: 0.418\n",
      "Loss after mini-batch    50: 0.091\n",
      "Loss after mini-batch    60: 0.277\n",
      "Loss after mini-batch    70: 1.151\n",
      "Loss after mini-batch    80: 0.288\n",
      "Loss after mini-batch    90: 0.846\n",
      "Loss after mini-batch   100: 0.801\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.027\n",
      "Loss after mini-batch   130: 0.488\n",
      "Loss after mini-batch   140: 0.186\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.062\n",
      "Loss after mini-batch   170: 0.005\n",
      "Loss after mini-batch   180: 0.002\n",
      "Loss after mini-batch   190: 0.026\n",
      "Loss after mini-batch   200: 0.100\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.333\n",
      "Loss after mini-batch   230: 0.005\n",
      "Loss after mini-batch   240: 0.029\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.029\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.038\n",
      "Loss after mini-batch    50: 0.002\n",
      "Loss after mini-batch    60: 0.032\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.015\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.015\n",
      "Loss after mini-batch   120: 0.002\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.147\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.005\n",
      "Loss after mini-batch   180: 0.006\n",
      "Loss after mini-batch   190: 0.035\n",
      "Loss after mini-batch   200: 0.828\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.004\n",
      "Loss after mini-batch   230: 0.000\n",
      "Loss after mini-batch   240: 0.001\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.094\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.002\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.003\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.359\n",
      "Loss after mini-batch   130: 0.015\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.003\n",
      "Loss after mini-batch   160: 0.070\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.232\n",
      "Loss after mini-batch   210: 5.759\n",
      "Loss after mini-batch   220: 0.089\n",
      "Loss after mini-batch   230: 3.744\n",
      "Loss after mini-batch   240: 1.427\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.673\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.052\n",
      "Loss after mini-batch    40: 0.025\n",
      "Loss after mini-batch    50: 0.009\n",
      "Loss after mini-batch    60: 3.455\n",
      "Loss after mini-batch    70: 1.115\n",
      "Loss after mini-batch    80: 0.314\n",
      "Loss after mini-batch    90: 0.066\n",
      "Loss after mini-batch   100: 0.740\n",
      "Loss after mini-batch   110: 0.004\n",
      "Loss after mini-batch   120: 0.021\n",
      "Loss after mini-batch   130: 0.009\n",
      "Loss after mini-batch   140: 0.337\n",
      "Loss after mini-batch   150: 0.009\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.004\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.042\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.012\n",
      "Loss after mini-batch   220: 0.184\n",
      "Loss after mini-batch   230: 0.031\n",
      "Loss after mini-batch   240: 0.003\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.297\n",
      "Loss after mini-batch   100: 0.006\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.005\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.035\n",
      "Loss after mini-batch   150: 0.080\n",
      "Loss after mini-batch   160: 0.004\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.298\n",
      "Loss after mini-batch   220: 0.000\n",
      "Loss after mini-batch   230: 0.001\n",
      "Loss after mini-batch   240: 0.002\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 5: 87 %\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=65536, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch    10: 46.033\n",
      "Loss after mini-batch    20: 8.415\n",
      "Loss after mini-batch    30: 6.361\n",
      "Loss after mini-batch    40: 3.270\n",
      "Loss after mini-batch    50: 10.367\n",
      "Loss after mini-batch    60: 7.136\n",
      "Loss after mini-batch    70: 7.057\n",
      "Loss after mini-batch    80: 6.216\n",
      "Loss after mini-batch    90: 5.524\n",
      "Loss after mini-batch   100: 5.238\n",
      "Loss after mini-batch   110: 7.413\n",
      "Loss after mini-batch   120: 5.663\n",
      "Loss after mini-batch   130: 6.122\n",
      "Loss after mini-batch   140: 7.538\n",
      "Loss after mini-batch   150: 6.728\n",
      "Loss after mini-batch   160: 2.401\n",
      "Loss after mini-batch   170: 3.439\n",
      "Loss after mini-batch   180: 11.014\n",
      "Loss after mini-batch   190: 3.069\n",
      "Loss after mini-batch   200: 5.295\n",
      "Loss after mini-batch   210: 3.804\n",
      "Loss after mini-batch   220: 2.808\n",
      "Loss after mini-batch   230: 2.124\n",
      "Loss after mini-batch   240: 6.675\n",
      "Starting epoch 2\n",
      "Loss after mini-batch    10: 0.747\n",
      "Loss after mini-batch    20: 3.733\n",
      "Loss after mini-batch    30: 1.394\n",
      "Loss after mini-batch    40: 6.621\n",
      "Loss after mini-batch    50: 4.227\n",
      "Loss after mini-batch    60: 4.306\n",
      "Loss after mini-batch    70: 3.596\n",
      "Loss after mini-batch    80: 1.854\n",
      "Loss after mini-batch    90: 2.953\n",
      "Loss after mini-batch   100: 5.733\n",
      "Loss after mini-batch   110: 3.485\n",
      "Loss after mini-batch   120: 0.660\n",
      "Loss after mini-batch   130: 4.675\n",
      "Loss after mini-batch   140: 3.175\n",
      "Loss after mini-batch   150: 1.741\n",
      "Loss after mini-batch   160: 4.786\n",
      "Loss after mini-batch   170: 4.965\n",
      "Loss after mini-batch   180: 1.576\n",
      "Loss after mini-batch   190: 0.621\n",
      "Loss after mini-batch   200: 3.766\n",
      "Loss after mini-batch   210: 4.292\n",
      "Loss after mini-batch   220: 6.364\n",
      "Loss after mini-batch   230: 2.790\n",
      "Loss after mini-batch   240: 1.932\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.634\n",
      "Loss after mini-batch    20: 0.749\n",
      "Loss after mini-batch    30: 0.191\n",
      "Loss after mini-batch    40: 0.759\n",
      "Loss after mini-batch    50: 1.802\n",
      "Loss after mini-batch    60: 0.852\n",
      "Loss after mini-batch    70: 0.139\n",
      "Loss after mini-batch    80: 4.685\n",
      "Loss after mini-batch    90: 0.946\n",
      "Loss after mini-batch   100: 0.106\n",
      "Loss after mini-batch   110: 0.261\n",
      "Loss after mini-batch   120: 0.187\n",
      "Loss after mini-batch   130: 1.678\n",
      "Loss after mini-batch   140: 3.672\n",
      "Loss after mini-batch   150: 1.032\n",
      "Loss after mini-batch   160: 2.439\n",
      "Loss after mini-batch   170: 2.713\n",
      "Loss after mini-batch   180: 0.787\n",
      "Loss after mini-batch   190: 2.476\n",
      "Loss after mini-batch   200: 0.967\n",
      "Loss after mini-batch   210: 2.733\n",
      "Loss after mini-batch   220: 1.476\n",
      "Loss after mini-batch   230: 0.190\n",
      "Loss after mini-batch   240: 0.097\n",
      "Starting epoch 4\n",
      "Loss after mini-batch    10: 0.354\n",
      "Loss after mini-batch    20: 1.455\n",
      "Loss after mini-batch    30: 0.665\n",
      "Loss after mini-batch    40: 0.013\n",
      "Loss after mini-batch    50: 0.313\n",
      "Loss after mini-batch    60: 0.396\n",
      "Loss after mini-batch    70: 0.005\n",
      "Loss after mini-batch    80: 0.414\n",
      "Loss after mini-batch    90: 0.052\n",
      "Loss after mini-batch   100: 0.279\n",
      "Loss after mini-batch   110: 0.985\n",
      "Loss after mini-batch   120: 0.541\n",
      "Loss after mini-batch   130: 0.267\n",
      "Loss after mini-batch   140: 0.111\n",
      "Loss after mini-batch   150: 0.251\n",
      "Loss after mini-batch   160: 0.055\n",
      "Loss after mini-batch   170: 0.597\n",
      "Loss after mini-batch   180: 0.007\n",
      "Loss after mini-batch   190: 0.798\n",
      "Loss after mini-batch   200: 1.421\n",
      "Loss after mini-batch   210: 0.700\n",
      "Loss after mini-batch   220: 1.339\n",
      "Loss after mini-batch   230: 0.011\n",
      "Loss after mini-batch   240: 0.078\n",
      "Starting epoch 5\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    30: 0.057\n",
      "Loss after mini-batch    40: 0.003\n",
      "Loss after mini-batch    50: 0.938\n",
      "Loss after mini-batch    60: 0.088\n",
      "Loss after mini-batch    70: 0.338\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.417\n",
      "Loss after mini-batch   110: 0.016\n",
      "Loss after mini-batch   120: 0.766\n",
      "Loss after mini-batch   130: 1.356\n",
      "Loss after mini-batch   140: 0.002\n",
      "Loss after mini-batch   150: 0.067\n",
      "Loss after mini-batch   160: 0.006\n",
      "Loss after mini-batch   170: 0.072\n",
      "Loss after mini-batch   180: 0.007\n",
      "Loss after mini-batch   190: 0.102\n",
      "Loss after mini-batch   200: 0.021\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 1.291\n",
      "Loss after mini-batch   230: 0.032\n",
      "Loss after mini-batch   240: 0.026\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    30: 0.015\n",
      "Loss after mini-batch    40: 0.003\n",
      "Loss after mini-batch    50: 0.057\n",
      "Loss after mini-batch    60: 0.005\n",
      "Loss after mini-batch    70: 0.054\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.146\n",
      "Loss after mini-batch   100: 0.020\n",
      "Loss after mini-batch   110: 0.013\n",
      "Loss after mini-batch   120: 1.434\n",
      "Loss after mini-batch   130: 6.320\n",
      "Loss after mini-batch   140: 0.153\n",
      "Loss after mini-batch   150: 13.495\n",
      "Loss after mini-batch   160: 2.117\n",
      "Loss after mini-batch   170: 1.168\n",
      "Loss after mini-batch   180: 0.151\n",
      "Loss after mini-batch   190: 1.195\n",
      "Loss after mini-batch   200: 1.259\n",
      "Loss after mini-batch   210: 0.014\n",
      "Loss after mini-batch   220: 1.035\n",
      "Loss after mini-batch   230: 0.173\n",
      "Loss after mini-batch   240: 1.008\n",
      "Starting epoch 7\n",
      "Loss after mini-batch    10: 0.235\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    30: 0.013\n",
      "Loss after mini-batch    40: 0.051\n",
      "Loss after mini-batch    50: 0.047\n",
      "Loss after mini-batch    60: 0.016\n",
      "Loss after mini-batch    70: 0.501\n",
      "Loss after mini-batch    80: 0.004\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.029\n",
      "Loss after mini-batch   120: 0.006\n",
      "Loss after mini-batch   130: 0.035\n",
      "Loss after mini-batch   140: 0.066\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.024\n",
      "Loss after mini-batch   170: 0.216\n",
      "Loss after mini-batch   180: 0.023\n",
      "Loss after mini-batch   190: 1.390\n",
      "Loss after mini-batch   200: 0.009\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.641\n",
      "Loss after mini-batch   230: 0.030\n",
      "Loss after mini-batch   240: 0.192\n",
      "Starting epoch 8\n",
      "Loss after mini-batch    10: 0.661\n",
      "Loss after mini-batch    20: 0.183\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.017\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.016\n",
      "Loss after mini-batch    80: 0.085\n",
      "Loss after mini-batch    90: 0.021\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.130\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.013\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.004\n",
      "Loss after mini-batch   170: 0.906\n",
      "Loss after mini-batch   180: 0.021\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 13.794\n",
      "Loss after mini-batch   210: 0.195\n",
      "Loss after mini-batch   220: 0.009\n",
      "Loss after mini-batch   230: 0.084\n",
      "Loss after mini-batch   240: 0.687\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.346\n",
      "Loss after mini-batch    20: 0.084\n",
      "Loss after mini-batch    30: 0.082\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.019\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.526\n",
      "Loss after mini-batch    80: 0.001\n",
      "Loss after mini-batch    90: 0.024\n",
      "Loss after mini-batch   100: 0.156\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.131\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 1.869\n",
      "Loss after mini-batch   150: 5.477\n",
      "Loss after mini-batch   160: 0.247\n",
      "Loss after mini-batch   170: 1.955\n",
      "Loss after mini-batch   180: 0.026\n",
      "Loss after mini-batch   190: 0.019\n",
      "Loss after mini-batch   200: 0.346\n",
      "Loss after mini-batch   210: 1.710\n",
      "Loss after mini-batch   220: 0.020\n",
      "Loss after mini-batch   230: 0.349\n",
      "Loss after mini-batch   240: 0.147\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.113\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.275\n",
      "Loss after mini-batch    70: 0.003\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.026\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.033\n",
      "Loss after mini-batch   120: 0.099\n",
      "Loss after mini-batch   130: 2.331\n",
      "Loss after mini-batch   140: 0.015\n",
      "Loss after mini-batch   150: 0.161\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.007\n",
      "Loss after mini-batch   180: 0.105\n",
      "Loss after mini-batch   190: 0.007\n",
      "Loss after mini-batch   200: 0.012\n",
      "Loss after mini-batch   210: 0.124\n",
      "Loss after mini-batch   220: 0.220\n",
      "Loss after mini-batch   230: 0.010\n",
      "Loss after mini-batch   240: 0.007\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 6: 92 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 7 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 82.5 %\n",
      "Fold 1: 82.5 %\n",
      "Fold 2: 92.5 %\n",
      "Fold 3: 97.5 %\n",
      "Fold 4: 82.5 %\n",
      "Fold 5: 87.5 %\n",
      "Fold 6: 92.5 %\n",
      "Average: 88.21428571428571 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 32, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(32, 64, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(64, 128, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(128, 256, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 256, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 7\n",
    "  num_epochs = 10\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=train_subsampler)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=test_subsampler)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1721017094986,
     "user": {
      "displayName": "Hojin Kim",
      "userId": "14078983730331144087"
     },
     "user_tz": -540
    },
    "id": "Y1OkgvzYnMHm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.950\n",
      "Loss after mini-batch     2: 0.646\n",
      "Loss after mini-batch     3: 0.635\n",
      "Loss after mini-batch     4: 0.701\n",
      "Loss after mini-batch     5: 0.706\n",
      "Loss after mini-batch     6: 0.583\n",
      "Loss after mini-batch     7: 1.034\n",
      "Loss after mini-batch     8: 0.783\n",
      "Loss after mini-batch     9: 0.540\n",
      "Loss after mini-batch    10: 0.620\n",
      "Loss after mini-batch    11: 0.595\n",
      "Loss after mini-batch    12: 0.602\n",
      "Loss after mini-batch    13: 0.920\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.441\n",
      "Loss after mini-batch     2: 0.458\n",
      "Loss after mini-batch     3: 0.411\n",
      "Loss after mini-batch     4: 0.601\n",
      "Loss after mini-batch     5: 0.725\n",
      "Loss after mini-batch     6: 0.365\n",
      "Loss after mini-batch     7: 0.375\n",
      "Loss after mini-batch     8: 0.445\n",
      "Loss after mini-batch     9: 0.482\n",
      "Loss after mini-batch    10: 0.406\n",
      "Loss after mini-batch    11: 0.533\n",
      "Loss after mini-batch    12: 0.529\n",
      "Loss after mini-batch    13: 0.527\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.312\n",
      "Loss after mini-batch     2: 0.614\n",
      "Loss after mini-batch     3: 0.324\n",
      "Loss after mini-batch     4: 0.388\n",
      "Loss after mini-batch     5: 0.353\n",
      "Loss after mini-batch     6: 0.268\n",
      "Loss after mini-batch     7: 0.393\n",
      "Loss after mini-batch     8: 0.455\n",
      "Loss after mini-batch     9: 0.262\n",
      "Loss after mini-batch    10: 0.353\n",
      "Loss after mini-batch    11: 0.393\n",
      "Loss after mini-batch    12: 0.295\n",
      "Loss after mini-batch    13: 0.261\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.170\n",
      "Loss after mini-batch     2: 0.396\n",
      "Loss after mini-batch     3: 0.360\n",
      "Loss after mini-batch     4: 0.268\n",
      "Loss after mini-batch     5: 0.294\n",
      "Loss after mini-batch     6: 0.337\n",
      "Loss after mini-batch     7: 0.292\n",
      "Loss after mini-batch     8: 0.267\n",
      "Loss after mini-batch     9: 0.248\n",
      "Loss after mini-batch    10: 0.166\n",
      "Loss after mini-batch    11: 0.204\n",
      "Loss after mini-batch    12: 0.406\n",
      "Loss after mini-batch    13: 0.109\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.265\n",
      "Loss after mini-batch     2: 0.298\n",
      "Loss after mini-batch     3: 0.164\n",
      "Loss after mini-batch     4: 0.132\n",
      "Loss after mini-batch     5: 0.172\n",
      "Loss after mini-batch     6: 0.237\n",
      "Loss after mini-batch     7: 0.077\n",
      "Loss after mini-batch     8: 0.146\n",
      "Loss after mini-batch     9: 0.288\n",
      "Loss after mini-batch    10: 0.244\n",
      "Loss after mini-batch    11: 0.179\n",
      "Loss after mini-batch    12: 0.193\n",
      "Loss after mini-batch    13: 0.284\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.144\n",
      "Loss after mini-batch     2: 0.170\n",
      "Loss after mini-batch     3: 0.124\n",
      "Loss after mini-batch     4: 0.210\n",
      "Loss after mini-batch     5: 0.236\n",
      "Loss after mini-batch     6: 0.084\n",
      "Loss after mini-batch     7: 0.195\n",
      "Loss after mini-batch     8: 0.217\n",
      "Loss after mini-batch     9: 0.128\n",
      "Loss after mini-batch    10: 0.169\n",
      "Loss after mini-batch    11: 0.073\n",
      "Loss after mini-batch    12: 0.118\n",
      "Loss after mini-batch    13: 0.128\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.144\n",
      "Loss after mini-batch     2: 0.048\n",
      "Loss after mini-batch     3: 0.137\n",
      "Loss after mini-batch     4: 0.097\n",
      "Loss after mini-batch     5: 0.159\n",
      "Loss after mini-batch     6: 0.181\n",
      "Loss after mini-batch     7: 0.092\n",
      "Loss after mini-batch     8: 0.071\n",
      "Loss after mini-batch     9: 0.080\n",
      "Loss after mini-batch    10: 0.029\n",
      "Loss after mini-batch    11: 0.148\n",
      "Loss after mini-batch    12: 0.158\n",
      "Loss after mini-batch    13: 0.050\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.047\n",
      "Loss after mini-batch     2: 0.065\n",
      "Loss after mini-batch     3: 0.124\n",
      "Loss after mini-batch     4: 0.095\n",
      "Loss after mini-batch     5: 0.057\n",
      "Loss after mini-batch     6: 0.057\n",
      "Loss after mini-batch     7: 0.107\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.072\n",
      "Loss after mini-batch    10: 0.057\n",
      "Loss after mini-batch    11: 0.050\n",
      "Loss after mini-batch    12: 0.098\n",
      "Loss after mini-batch    13: 0.128\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.126\n",
      "Loss after mini-batch     2: 0.024\n",
      "Loss after mini-batch     3: 0.036\n",
      "Loss after mini-batch     4: 0.086\n",
      "Loss after mini-batch     5: 0.054\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.049\n",
      "Loss after mini-batch     9: 0.076\n",
      "Loss after mini-batch    10: 0.044\n",
      "Loss after mini-batch    11: 0.020\n",
      "Loss after mini-batch    12: 0.038\n",
      "Loss after mini-batch    13: 0.033\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.041\n",
      "Loss after mini-batch     2: 0.033\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.033\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.060\n",
      "Loss after mini-batch     8: 0.053\n",
      "Loss after mini-batch     9: 0.026\n",
      "Loss after mini-batch    10: 0.050\n",
      "Loss after mini-batch    11: 0.035\n",
      "Loss after mini-batch    12: 0.041\n",
      "Loss after mini-batch    13: 0.021\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 85 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.978\n",
      "Loss after mini-batch     2: 1.452\n",
      "Loss after mini-batch     3: 1.060\n",
      "Loss after mini-batch     4: 0.649\n",
      "Loss after mini-batch     5: 1.066\n",
      "Loss after mini-batch     6: 0.777\n",
      "Loss after mini-batch     7: 0.795\n",
      "Loss after mini-batch     8: 0.741\n",
      "Loss after mini-batch     9: 0.688\n",
      "Loss after mini-batch    10: 0.704\n",
      "Loss after mini-batch    11: 0.635\n",
      "Loss after mini-batch    12: 0.655\n",
      "Loss after mini-batch    13: 0.634\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.700\n",
      "Loss after mini-batch     2: 0.623\n",
      "Loss after mini-batch     3: 0.605\n",
      "Loss after mini-batch     4: 0.595\n",
      "Loss after mini-batch     5: 0.593\n",
      "Loss after mini-batch     6: 0.585\n",
      "Loss after mini-batch     7: 0.597\n",
      "Loss after mini-batch     8: 0.569\n",
      "Loss after mini-batch     9: 0.553\n",
      "Loss after mini-batch    10: 0.561\n",
      "Loss after mini-batch    11: 0.571\n",
      "Loss after mini-batch    12: 0.507\n",
      "Loss after mini-batch    13: 0.506\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.451\n",
      "Loss after mini-batch     2: 0.507\n",
      "Loss after mini-batch     3: 0.449\n",
      "Loss after mini-batch     4: 0.466\n",
      "Loss after mini-batch     5: 0.379\n",
      "Loss after mini-batch     6: 0.349\n",
      "Loss after mini-batch     7: 0.418\n",
      "Loss after mini-batch     8: 0.462\n",
      "Loss after mini-batch     9: 0.669\n",
      "Loss after mini-batch    10: 0.347\n",
      "Loss after mini-batch    11: 0.419\n",
      "Loss after mini-batch    12: 0.368\n",
      "Loss after mini-batch    13: 0.640\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.574\n",
      "Loss after mini-batch     2: 0.465\n",
      "Loss after mini-batch     3: 0.345\n",
      "Loss after mini-batch     4: 0.468\n",
      "Loss after mini-batch     5: 0.291\n",
      "Loss after mini-batch     6: 0.344\n",
      "Loss after mini-batch     7: 0.300\n",
      "Loss after mini-batch     8: 0.361\n",
      "Loss after mini-batch     9: 0.315\n",
      "Loss after mini-batch    10: 0.313\n",
      "Loss after mini-batch    11: 0.421\n",
      "Loss after mini-batch    12: 0.363\n",
      "Loss after mini-batch    13: 0.409\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.211\n",
      "Loss after mini-batch     2: 0.498\n",
      "Loss after mini-batch     3: 0.405\n",
      "Loss after mini-batch     4: 0.175\n",
      "Loss after mini-batch     5: 0.329\n",
      "Loss after mini-batch     6: 0.330\n",
      "Loss after mini-batch     7: 0.258\n",
      "Loss after mini-batch     8: 0.299\n",
      "Loss after mini-batch     9: 0.464\n",
      "Loss after mini-batch    10: 0.154\n",
      "Loss after mini-batch    11: 0.239\n",
      "Loss after mini-batch    12: 0.330\n",
      "Loss after mini-batch    13: 0.271\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.280\n",
      "Loss after mini-batch     2: 0.142\n",
      "Loss after mini-batch     3: 0.105\n",
      "Loss after mini-batch     4: 0.318\n",
      "Loss after mini-batch     5: 0.272\n",
      "Loss after mini-batch     6: 0.243\n",
      "Loss after mini-batch     7: 0.233\n",
      "Loss after mini-batch     8: 0.321\n",
      "Loss after mini-batch     9: 0.210\n",
      "Loss after mini-batch    10: 0.160\n",
      "Loss after mini-batch    11: 0.304\n",
      "Loss after mini-batch    12: 0.152\n",
      "Loss after mini-batch    13: 0.430\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.265\n",
      "Loss after mini-batch     2: 0.154\n",
      "Loss after mini-batch     3: 0.112\n",
      "Loss after mini-batch     4: 0.236\n",
      "Loss after mini-batch     5: 0.210\n",
      "Loss after mini-batch     6: 0.375\n",
      "Loss after mini-batch     7: 0.223\n",
      "Loss after mini-batch     8: 0.155\n",
      "Loss after mini-batch     9: 0.232\n",
      "Loss after mini-batch    10: 0.132\n",
      "Loss after mini-batch    11: 0.154\n",
      "Loss after mini-batch    12: 0.157\n",
      "Loss after mini-batch    13: 0.123\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.297\n",
      "Loss after mini-batch     2: 0.212\n",
      "Loss after mini-batch     3: 0.111\n",
      "Loss after mini-batch     4: 0.159\n",
      "Loss after mini-batch     5: 0.090\n",
      "Loss after mini-batch     6: 0.176\n",
      "Loss after mini-batch     7: 0.143\n",
      "Loss after mini-batch     8: 0.256\n",
      "Loss after mini-batch     9: 0.084\n",
      "Loss after mini-batch    10: 0.141\n",
      "Loss after mini-batch    11: 0.141\n",
      "Loss after mini-batch    12: 0.149\n",
      "Loss after mini-batch    13: 0.096\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.112\n",
      "Loss after mini-batch     2: 0.129\n",
      "Loss after mini-batch     3: 0.067\n",
      "Loss after mini-batch     4: 0.114\n",
      "Loss after mini-batch     5: 0.203\n",
      "Loss after mini-batch     6: 0.100\n",
      "Loss after mini-batch     7: 0.138\n",
      "Loss after mini-batch     8: 0.114\n",
      "Loss after mini-batch     9: 0.138\n",
      "Loss after mini-batch    10: 0.026\n",
      "Loss after mini-batch    11: 0.353\n",
      "Loss after mini-batch    12: 0.104\n",
      "Loss after mini-batch    13: 0.036\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.219\n",
      "Loss after mini-batch     2: 0.093\n",
      "Loss after mini-batch     3: 0.091\n",
      "Loss after mini-batch     4: 0.104\n",
      "Loss after mini-batch     5: 0.081\n",
      "Loss after mini-batch     6: 0.056\n",
      "Loss after mini-batch     7: 0.175\n",
      "Loss after mini-batch     8: 0.103\n",
      "Loss after mini-batch     9: 0.137\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.189\n",
      "Loss after mini-batch    12: 0.085\n",
      "Loss after mini-batch    13: 0.090\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 92 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.862\n",
      "Loss after mini-batch     2: 0.759\n",
      "Loss after mini-batch     3: 0.724\n",
      "Loss after mini-batch     4: 0.757\n",
      "Loss after mini-batch     5: 0.689\n",
      "Loss after mini-batch     6: 1.239\n",
      "Loss after mini-batch     7: 0.645\n",
      "Loss after mini-batch     8: 0.673\n",
      "Loss after mini-batch     9: 0.744\n",
      "Loss after mini-batch    10: 0.653\n",
      "Loss after mini-batch    11: 0.650\n",
      "Loss after mini-batch    12: 0.676\n",
      "Loss after mini-batch    13: 0.679\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.619\n",
      "Loss after mini-batch     2: 0.632\n",
      "Loss after mini-batch     3: 0.589\n",
      "Loss after mini-batch     4: 0.555\n",
      "Loss after mini-batch     5: 0.717\n",
      "Loss after mini-batch     6: 0.506\n",
      "Loss after mini-batch     7: 0.603\n",
      "Loss after mini-batch     8: 0.519\n",
      "Loss after mini-batch     9: 0.631\n",
      "Loss after mini-batch    10: 0.483\n",
      "Loss after mini-batch    11: 0.669\n",
      "Loss after mini-batch    12: 0.593\n",
      "Loss after mini-batch    13: 0.439\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.527\n",
      "Loss after mini-batch     2: 0.517\n",
      "Loss after mini-batch     3: 0.496\n",
      "Loss after mini-batch     4: 0.438\n",
      "Loss after mini-batch     5: 0.439\n",
      "Loss after mini-batch     6: 0.489\n",
      "Loss after mini-batch     7: 0.503\n",
      "Loss after mini-batch     8: 0.418\n",
      "Loss after mini-batch     9: 0.272\n",
      "Loss after mini-batch    10: 0.696\n",
      "Loss after mini-batch    11: 0.473\n",
      "Loss after mini-batch    12: 0.470\n",
      "Loss after mini-batch    13: 0.318\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.501\n",
      "Loss after mini-batch     2: 0.648\n",
      "Loss after mini-batch     3: 0.326\n",
      "Loss after mini-batch     4: 0.520\n",
      "Loss after mini-batch     5: 0.402\n",
      "Loss after mini-batch     6: 0.265\n",
      "Loss after mini-batch     7: 0.346\n",
      "Loss after mini-batch     8: 0.390\n",
      "Loss after mini-batch     9: 0.276\n",
      "Loss after mini-batch    10: 0.365\n",
      "Loss after mini-batch    11: 0.268\n",
      "Loss after mini-batch    12: 0.252\n",
      "Loss after mini-batch    13: 0.364\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.286\n",
      "Loss after mini-batch     2: 0.436\n",
      "Loss after mini-batch     3: 0.345\n",
      "Loss after mini-batch     4: 0.214\n",
      "Loss after mini-batch     5: 0.326\n",
      "Loss after mini-batch     6: 0.518\n",
      "Loss after mini-batch     7: 0.268\n",
      "Loss after mini-batch     8: 0.224\n",
      "Loss after mini-batch     9: 0.261\n",
      "Loss after mini-batch    10: 0.269\n",
      "Loss after mini-batch    11: 0.271\n",
      "Loss after mini-batch    12: 0.255\n",
      "Loss after mini-batch    13: 0.265\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.274\n",
      "Loss after mini-batch     2: 0.305\n",
      "Loss after mini-batch     3: 0.305\n",
      "Loss after mini-batch     4: 0.117\n",
      "Loss after mini-batch     5: 0.408\n",
      "Loss after mini-batch     6: 0.176\n",
      "Loss after mini-batch     7: 0.170\n",
      "Loss after mini-batch     8: 0.156\n",
      "Loss after mini-batch     9: 0.420\n",
      "Loss after mini-batch    10: 0.316\n",
      "Loss after mini-batch    11: 0.319\n",
      "Loss after mini-batch    12: 0.213\n",
      "Loss after mini-batch    13: 0.100\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.256\n",
      "Loss after mini-batch     2: 0.260\n",
      "Loss after mini-batch     3: 0.207\n",
      "Loss after mini-batch     4: 0.134\n",
      "Loss after mini-batch     5: 0.261\n",
      "Loss after mini-batch     6: 0.243\n",
      "Loss after mini-batch     7: 0.270\n",
      "Loss after mini-batch     8: 0.193\n",
      "Loss after mini-batch     9: 0.262\n",
      "Loss after mini-batch    10: 0.319\n",
      "Loss after mini-batch    11: 0.220\n",
      "Loss after mini-batch    12: 0.290\n",
      "Loss after mini-batch    13: 0.360\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.112\n",
      "Loss after mini-batch     2: 0.183\n",
      "Loss after mini-batch     3: 0.423\n",
      "Loss after mini-batch     4: 0.147\n",
      "Loss after mini-batch     5: 0.218\n",
      "Loss after mini-batch     6: 0.152\n",
      "Loss after mini-batch     7: 0.199\n",
      "Loss after mini-batch     8: 0.224\n",
      "Loss after mini-batch     9: 0.226\n",
      "Loss after mini-batch    10: 0.201\n",
      "Loss after mini-batch    11: 0.128\n",
      "Loss after mini-batch    12: 0.201\n",
      "Loss after mini-batch    13: 0.370\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.110\n",
      "Loss after mini-batch     2: 0.181\n",
      "Loss after mini-batch     3: 0.177\n",
      "Loss after mini-batch     4: 0.161\n",
      "Loss after mini-batch     5: 0.317\n",
      "Loss after mini-batch     6: 0.147\n",
      "Loss after mini-batch     7: 0.176\n",
      "Loss after mini-batch     8: 0.098\n",
      "Loss after mini-batch     9: 0.110\n",
      "Loss after mini-batch    10: 0.079\n",
      "Loss after mini-batch    11: 0.108\n",
      "Loss after mini-batch    12: 0.175\n",
      "Loss after mini-batch    13: 0.070\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.189\n",
      "Loss after mini-batch     2: 0.161\n",
      "Loss after mini-batch     3: 0.100\n",
      "Loss after mini-batch     4: 0.184\n",
      "Loss after mini-batch     5: 0.145\n",
      "Loss after mini-batch     6: 0.133\n",
      "Loss after mini-batch     7: 0.104\n",
      "Loss after mini-batch     8: 0.156\n",
      "Loss after mini-batch     9: 0.017\n",
      "Loss after mini-batch    10: 0.112\n",
      "Loss after mini-batch    11: 0.169\n",
      "Loss after mini-batch    12: 0.091\n",
      "Loss after mini-batch    13: 0.073\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 82 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.521\n",
      "Loss after mini-batch     2: 0.663\n",
      "Loss after mini-batch     3: 1.217\n",
      "Loss after mini-batch     4: 1.220\n",
      "Loss after mini-batch     5: 0.703\n",
      "Loss after mini-batch     6: 0.642\n",
      "Loss after mini-batch     7: 0.799\n",
      "Loss after mini-batch     8: 0.641\n",
      "Loss after mini-batch     9: 0.635\n",
      "Loss after mini-batch    10: 0.640\n",
      "Loss after mini-batch    11: 0.703\n",
      "Loss after mini-batch    12: 0.645\n",
      "Loss after mini-batch    13: 0.554\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.609\n",
      "Loss after mini-batch     2: 0.555\n",
      "Loss after mini-batch     3: 0.567\n",
      "Loss after mini-batch     4: 0.541\n",
      "Loss after mini-batch     5: 0.607\n",
      "Loss after mini-batch     6: 0.543\n",
      "Loss after mini-batch     7: 0.526\n",
      "Loss after mini-batch     8: 0.546\n",
      "Loss after mini-batch     9: 0.614\n",
      "Loss after mini-batch    10: 0.475\n",
      "Loss after mini-batch    11: 0.480\n",
      "Loss after mini-batch    12: 0.464\n",
      "Loss after mini-batch    13: 0.616\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.514\n",
      "Loss after mini-batch     2: 0.362\n",
      "Loss after mini-batch     3: 0.624\n",
      "Loss after mini-batch     4: 0.487\n",
      "Loss after mini-batch     5: 0.333\n",
      "Loss after mini-batch     6: 0.462\n",
      "Loss after mini-batch     7: 0.394\n",
      "Loss after mini-batch     8: 0.408\n",
      "Loss after mini-batch     9: 0.439\n",
      "Loss after mini-batch    10: 0.373\n",
      "Loss after mini-batch    11: 0.397\n",
      "Loss after mini-batch    12: 0.503\n",
      "Loss after mini-batch    13: 0.453\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.562\n",
      "Loss after mini-batch     2: 0.346\n",
      "Loss after mini-batch     3: 0.402\n",
      "Loss after mini-batch     4: 0.353\n",
      "Loss after mini-batch     5: 0.264\n",
      "Loss after mini-batch     6: 0.361\n",
      "Loss after mini-batch     7: 0.513\n",
      "Loss after mini-batch     8: 0.303\n",
      "Loss after mini-batch     9: 0.342\n",
      "Loss after mini-batch    10: 0.201\n",
      "Loss after mini-batch    11: 0.580\n",
      "Loss after mini-batch    12: 0.172\n",
      "Loss after mini-batch    13: 0.230\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.418\n",
      "Loss after mini-batch     2: 0.254\n",
      "Loss after mini-batch     3: 0.243\n",
      "Loss after mini-batch     4: 0.263\n",
      "Loss after mini-batch     5: 0.282\n",
      "Loss after mini-batch     6: 0.190\n",
      "Loss after mini-batch     7: 0.393\n",
      "Loss after mini-batch     8: 0.386\n",
      "Loss after mini-batch     9: 0.285\n",
      "Loss after mini-batch    10: 0.422\n",
      "Loss after mini-batch    11: 0.375\n",
      "Loss after mini-batch    12: 0.198\n",
      "Loss after mini-batch    13: 0.358\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.177\n",
      "Loss after mini-batch     2: 0.241\n",
      "Loss after mini-batch     3: 0.204\n",
      "Loss after mini-batch     4: 0.165\n",
      "Loss after mini-batch     5: 0.305\n",
      "Loss after mini-batch     6: 0.145\n",
      "Loss after mini-batch     7: 0.205\n",
      "Loss after mini-batch     8: 0.266\n",
      "Loss after mini-batch     9: 0.402\n",
      "Loss after mini-batch    10: 0.260\n",
      "Loss after mini-batch    11: 0.249\n",
      "Loss after mini-batch    12: 0.211\n",
      "Loss after mini-batch    13: 0.212\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.194\n",
      "Loss after mini-batch     2: 0.481\n",
      "Loss after mini-batch     3: 0.188\n",
      "Loss after mini-batch     4: 0.229\n",
      "Loss after mini-batch     5: 0.238\n",
      "Loss after mini-batch     6: 0.244\n",
      "Loss after mini-batch     7: 0.137\n",
      "Loss after mini-batch     8: 0.180\n",
      "Loss after mini-batch     9: 0.065\n",
      "Loss after mini-batch    10: 0.189\n",
      "Loss after mini-batch    11: 0.237\n",
      "Loss after mini-batch    12: 0.086\n",
      "Loss after mini-batch    13: 0.160\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.155\n",
      "Loss after mini-batch     2: 0.181\n",
      "Loss after mini-batch     3: 0.138\n",
      "Loss after mini-batch     4: 0.116\n",
      "Loss after mini-batch     5: 0.148\n",
      "Loss after mini-batch     6: 0.093\n",
      "Loss after mini-batch     7: 0.148\n",
      "Loss after mini-batch     8: 0.259\n",
      "Loss after mini-batch     9: 0.202\n",
      "Loss after mini-batch    10: 0.041\n",
      "Loss after mini-batch    11: 0.119\n",
      "Loss after mini-batch    12: 0.108\n",
      "Loss after mini-batch    13: 0.182\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.098\n",
      "Loss after mini-batch     2: 0.117\n",
      "Loss after mini-batch     3: 0.104\n",
      "Loss after mini-batch     4: 0.055\n",
      "Loss after mini-batch     5: 0.106\n",
      "Loss after mini-batch     6: 0.155\n",
      "Loss after mini-batch     7: 0.055\n",
      "Loss after mini-batch     8: 0.054\n",
      "Loss after mini-batch     9: 0.122\n",
      "Loss after mini-batch    10: 0.096\n",
      "Loss after mini-batch    11: 0.116\n",
      "Loss after mini-batch    12: 0.107\n",
      "Loss after mini-batch    13: 0.043\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.105\n",
      "Loss after mini-batch     2: 0.071\n",
      "Loss after mini-batch     3: 0.093\n",
      "Loss after mini-batch     4: 0.103\n",
      "Loss after mini-batch     5: 0.041\n",
      "Loss after mini-batch     6: 0.062\n",
      "Loss after mini-batch     7: 0.082\n",
      "Loss after mini-batch     8: 0.063\n",
      "Loss after mini-batch     9: 0.131\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.104\n",
      "Loss after mini-batch    12: 0.074\n",
      "Loss after mini-batch    13: 0.065\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 85 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.684\n",
      "Loss after mini-batch     2: 0.659\n",
      "Loss after mini-batch     3: 1.668\n",
      "Loss after mini-batch     4: 0.955\n",
      "Loss after mini-batch     5: 0.733\n",
      "Loss after mini-batch     6: 0.678\n",
      "Loss after mini-batch     7: 0.790\n",
      "Loss after mini-batch     8: 0.675\n",
      "Loss after mini-batch     9: 0.690\n",
      "Loss after mini-batch    10: 0.668\n",
      "Loss after mini-batch    11: 0.822\n",
      "Loss after mini-batch    12: 0.682\n",
      "Loss after mini-batch    13: 0.672\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.678\n",
      "Loss after mini-batch     2: 0.616\n",
      "Loss after mini-batch     3: 0.734\n",
      "Loss after mini-batch     4: 0.684\n",
      "Loss after mini-batch     5: 0.646\n",
      "Loss after mini-batch     6: 0.659\n",
      "Loss after mini-batch     7: 0.645\n",
      "Loss after mini-batch     8: 0.671\n",
      "Loss after mini-batch     9: 0.629\n",
      "Loss after mini-batch    10: 0.657\n",
      "Loss after mini-batch    11: 0.585\n",
      "Loss after mini-batch    12: 0.649\n",
      "Loss after mini-batch    13: 0.577\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.604\n",
      "Loss after mini-batch     2: 0.621\n",
      "Loss after mini-batch     3: 0.565\n",
      "Loss after mini-batch     4: 0.571\n",
      "Loss after mini-batch     5: 0.519\n",
      "Loss after mini-batch     6: 0.543\n",
      "Loss after mini-batch     7: 0.704\n",
      "Loss after mini-batch     8: 0.536\n",
      "Loss after mini-batch     9: 0.505\n",
      "Loss after mini-batch    10: 0.498\n",
      "Loss after mini-batch    11: 0.526\n",
      "Loss after mini-batch    12: 0.551\n",
      "Loss after mini-batch    13: 0.472\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.474\n",
      "Loss after mini-batch     2: 0.372\n",
      "Loss after mini-batch     3: 0.448\n",
      "Loss after mini-batch     4: 0.484\n",
      "Loss after mini-batch     5: 0.477\n",
      "Loss after mini-batch     6: 0.475\n",
      "Loss after mini-batch     7: 0.478\n",
      "Loss after mini-batch     8: 0.510\n",
      "Loss after mini-batch     9: 0.386\n",
      "Loss after mini-batch    10: 0.446\n",
      "Loss after mini-batch    11: 0.376\n",
      "Loss after mini-batch    12: 0.480\n",
      "Loss after mini-batch    13: 0.470\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.518\n",
      "Loss after mini-batch     2: 0.242\n",
      "Loss after mini-batch     3: 0.392\n",
      "Loss after mini-batch     4: 0.281\n",
      "Loss after mini-batch     5: 0.410\n",
      "Loss after mini-batch     6: 0.316\n",
      "Loss after mini-batch     7: 0.451\n",
      "Loss after mini-batch     8: 0.251\n",
      "Loss after mini-batch     9: 0.416\n",
      "Loss after mini-batch    10: 0.276\n",
      "Loss after mini-batch    11: 0.355\n",
      "Loss after mini-batch    12: 0.330\n",
      "Loss after mini-batch    13: 0.317\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.260\n",
      "Loss after mini-batch     2: 0.371\n",
      "Loss after mini-batch     3: 0.205\n",
      "Loss after mini-batch     4: 0.429\n",
      "Loss after mini-batch     5: 0.348\n",
      "Loss after mini-batch     6: 0.311\n",
      "Loss after mini-batch     7: 0.323\n",
      "Loss after mini-batch     8: 0.302\n",
      "Loss after mini-batch     9: 0.438\n",
      "Loss after mini-batch    10: 0.108\n",
      "Loss after mini-batch    11: 0.441\n",
      "Loss after mini-batch    12: 0.426\n",
      "Loss after mini-batch    13: 0.141\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.186\n",
      "Loss after mini-batch     2: 0.171\n",
      "Loss after mini-batch     3: 0.206\n",
      "Loss after mini-batch     4: 0.324\n",
      "Loss after mini-batch     5: 0.414\n",
      "Loss after mini-batch     6: 0.238\n",
      "Loss after mini-batch     7: 0.328\n",
      "Loss after mini-batch     8: 0.314\n",
      "Loss after mini-batch     9: 0.166\n",
      "Loss after mini-batch    10: 0.150\n",
      "Loss after mini-batch    11: 0.270\n",
      "Loss after mini-batch    12: 0.319\n",
      "Loss after mini-batch    13: 0.207\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.251\n",
      "Loss after mini-batch     2: 0.369\n",
      "Loss after mini-batch     3: 0.437\n",
      "Loss after mini-batch     4: 0.293\n",
      "Loss after mini-batch     5: 0.312\n",
      "Loss after mini-batch     6: 0.271\n",
      "Loss after mini-batch     7: 0.168\n",
      "Loss after mini-batch     8: 0.159\n",
      "Loss after mini-batch     9: 0.065\n",
      "Loss after mini-batch    10: 0.176\n",
      "Loss after mini-batch    11: 0.251\n",
      "Loss after mini-batch    12: 0.138\n",
      "Loss after mini-batch    13: 0.203\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.203\n",
      "Loss after mini-batch     2: 0.226\n",
      "Loss after mini-batch     3: 0.090\n",
      "Loss after mini-batch     4: 0.120\n",
      "Loss after mini-batch     5: 0.225\n",
      "Loss after mini-batch     6: 0.262\n",
      "Loss after mini-batch     7: 0.126\n",
      "Loss after mini-batch     8: 0.169\n",
      "Loss after mini-batch     9: 0.304\n",
      "Loss after mini-batch    10: 0.144\n",
      "Loss after mini-batch    11: 0.127\n",
      "Loss after mini-batch    12: 0.206\n",
      "Loss after mini-batch    13: 0.199\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.106\n",
      "Loss after mini-batch     2: 0.092\n",
      "Loss after mini-batch     3: 0.083\n",
      "Loss after mini-batch     4: 0.084\n",
      "Loss after mini-batch     5: 0.248\n",
      "Loss after mini-batch     6: 0.163\n",
      "Loss after mini-batch     7: 0.114\n",
      "Loss after mini-batch     8: 0.175\n",
      "Loss after mini-batch     9: 0.213\n",
      "Loss after mini-batch    10: 0.125\n",
      "Loss after mini-batch    11: 0.183\n",
      "Loss after mini-batch    12: 0.154\n",
      "Loss after mini-batch    13: 0.222\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 89 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.740\n",
      "Loss after mini-batch     2: 0.977\n",
      "Loss after mini-batch     3: 0.696\n",
      "Loss after mini-batch     4: 0.720\n",
      "Loss after mini-batch     5: 0.679\n",
      "Loss after mini-batch     6: 0.721\n",
      "Loss after mini-batch     7: 0.691\n",
      "Loss after mini-batch     8: 0.669\n",
      "Loss after mini-batch     9: 0.698\n",
      "Loss after mini-batch    10: 0.689\n",
      "Loss after mini-batch    11: 0.679\n",
      "Loss after mini-batch    12: 0.713\n",
      "Loss after mini-batch    13: 0.657\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.678\n",
      "Loss after mini-batch     2: 0.731\n",
      "Loss after mini-batch     3: 0.699\n",
      "Loss after mini-batch     4: 0.670\n",
      "Loss after mini-batch     5: 0.695\n",
      "Loss after mini-batch     6: 0.657\n",
      "Loss after mini-batch     7: 0.653\n",
      "Loss after mini-batch     8: 0.662\n",
      "Loss after mini-batch     9: 0.649\n",
      "Loss after mini-batch    10: 0.671\n",
      "Loss after mini-batch    11: 0.619\n",
      "Loss after mini-batch    12: 0.627\n",
      "Loss after mini-batch    13: 0.665\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.672\n",
      "Loss after mini-batch     2: 0.611\n",
      "Loss after mini-batch     3: 0.595\n",
      "Loss after mini-batch     4: 0.535\n",
      "Loss after mini-batch     5: 0.604\n",
      "Loss after mini-batch     6: 0.592\n",
      "Loss after mini-batch     7: 0.612\n",
      "Loss after mini-batch     8: 0.580\n",
      "Loss after mini-batch     9: 0.548\n",
      "Loss after mini-batch    10: 0.521\n",
      "Loss after mini-batch    11: 0.480\n",
      "Loss after mini-batch    12: 0.467\n",
      "Loss after mini-batch    13: 0.602\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.591\n",
      "Loss after mini-batch     2: 0.525\n",
      "Loss after mini-batch     3: 0.528\n",
      "Loss after mini-batch     4: 0.416\n",
      "Loss after mini-batch     5: 0.439\n",
      "Loss after mini-batch     6: 0.480\n",
      "Loss after mini-batch     7: 0.464\n",
      "Loss after mini-batch     8: 0.519\n",
      "Loss after mini-batch     9: 0.417\n",
      "Loss after mini-batch    10: 0.400\n",
      "Loss after mini-batch    11: 0.533\n",
      "Loss after mini-batch    12: 0.441\n",
      "Loss after mini-batch    13: 0.337\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.605\n",
      "Loss after mini-batch     2: 0.412\n",
      "Loss after mini-batch     3: 0.385\n",
      "Loss after mini-batch     4: 0.361\n",
      "Loss after mini-batch     5: 0.467\n",
      "Loss after mini-batch     6: 0.367\n",
      "Loss after mini-batch     7: 0.495\n",
      "Loss after mini-batch     8: 0.386\n",
      "Loss after mini-batch     9: 0.307\n",
      "Loss after mini-batch    10: 0.450\n",
      "Loss after mini-batch    11: 0.336\n",
      "Loss after mini-batch    12: 0.306\n",
      "Loss after mini-batch    13: 0.450\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.390\n",
      "Loss after mini-batch     2: 0.296\n",
      "Loss after mini-batch     3: 0.330\n",
      "Loss after mini-batch     4: 0.487\n",
      "Loss after mini-batch     5: 0.394\n",
      "Loss after mini-batch     6: 0.528\n",
      "Loss after mini-batch     7: 0.335\n",
      "Loss after mini-batch     8: 0.413\n",
      "Loss after mini-batch     9: 0.295\n",
      "Loss after mini-batch    10: 0.242\n",
      "Loss after mini-batch    11: 0.463\n",
      "Loss after mini-batch    12: 0.409\n",
      "Loss after mini-batch    13: 0.339\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.386\n",
      "Loss after mini-batch     2: 0.444\n",
      "Loss after mini-batch     3: 0.309\n",
      "Loss after mini-batch     4: 0.564\n",
      "Loss after mini-batch     5: 0.213\n",
      "Loss after mini-batch     6: 0.411\n",
      "Loss after mini-batch     7: 0.342\n",
      "Loss after mini-batch     8: 0.371\n",
      "Loss after mini-batch     9: 0.350\n",
      "Loss after mini-batch    10: 0.197\n",
      "Loss after mini-batch    11: 0.323\n",
      "Loss after mini-batch    12: 0.229\n",
      "Loss after mini-batch    13: 0.132\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.157\n",
      "Loss after mini-batch     2: 0.313\n",
      "Loss after mini-batch     3: 0.205\n",
      "Loss after mini-batch     4: 0.445\n",
      "Loss after mini-batch     5: 0.367\n",
      "Loss after mini-batch     6: 0.381\n",
      "Loss after mini-batch     7: 0.203\n",
      "Loss after mini-batch     8: 0.273\n",
      "Loss after mini-batch     9: 0.245\n",
      "Loss after mini-batch    10: 0.364\n",
      "Loss after mini-batch    11: 0.685\n",
      "Loss after mini-batch    12: 0.182\n",
      "Loss after mini-batch    13: 0.122\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.168\n",
      "Loss after mini-batch     2: 0.229\n",
      "Loss after mini-batch     3: 0.160\n",
      "Loss after mini-batch     4: 0.236\n",
      "Loss after mini-batch     5: 0.443\n",
      "Loss after mini-batch     6: 0.270\n",
      "Loss after mini-batch     7: 0.194\n",
      "Loss after mini-batch     8: 0.203\n",
      "Loss after mini-batch     9: 0.184\n",
      "Loss after mini-batch    10: 0.271\n",
      "Loss after mini-batch    11: 0.260\n",
      "Loss after mini-batch    12: 0.163\n",
      "Loss after mini-batch    13: 0.181\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.162\n",
      "Loss after mini-batch     2: 0.273\n",
      "Loss after mini-batch     3: 0.164\n",
      "Loss after mini-batch     4: 0.105\n",
      "Loss after mini-batch     5: 0.146\n",
      "Loss after mini-batch     6: 0.211\n",
      "Loss after mini-batch     7: 0.172\n",
      "Loss after mini-batch     8: 0.173\n",
      "Loss after mini-batch     9: 0.079\n",
      "Loss after mini-batch    10: 0.229\n",
      "Loss after mini-batch    11: 0.094\n",
      "Loss after mini-batch    12: 0.173\n",
      "Loss after mini-batch    13: 0.127\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 5: 82 %\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.757\n",
      "Loss after mini-batch     2: 0.761\n",
      "Loss after mini-batch     3: 0.723\n",
      "Loss after mini-batch     4: 0.691\n",
      "Loss after mini-batch     5: 0.684\n",
      "Loss after mini-batch     6: 0.681\n",
      "Loss after mini-batch     7: 0.697\n",
      "Loss after mini-batch     8: 0.591\n",
      "Loss after mini-batch     9: 0.748\n",
      "Loss after mini-batch    10: 0.670\n",
      "Loss after mini-batch    11: 0.675\n",
      "Loss after mini-batch    12: 0.604\n",
      "Loss after mini-batch    13: 0.639\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.639\n",
      "Loss after mini-batch     2: 0.630\n",
      "Loss after mini-batch     3: 0.625\n",
      "Loss after mini-batch     4: 0.538\n",
      "Loss after mini-batch     5: 0.572\n",
      "Loss after mini-batch     6: 0.542\n",
      "Loss after mini-batch     7: 0.570\n",
      "Loss after mini-batch     8: 0.511\n",
      "Loss after mini-batch     9: 0.473\n",
      "Loss after mini-batch    10: 0.484\n",
      "Loss after mini-batch    11: 0.476\n",
      "Loss after mini-batch    12: 0.474\n",
      "Loss after mini-batch    13: 0.600\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.463\n",
      "Loss after mini-batch     2: 0.466\n",
      "Loss after mini-batch     3: 0.473\n",
      "Loss after mini-batch     4: 0.515\n",
      "Loss after mini-batch     5: 0.327\n",
      "Loss after mini-batch     6: 0.415\n",
      "Loss after mini-batch     7: 0.359\n",
      "Loss after mini-batch     8: 0.284\n",
      "Loss after mini-batch     9: 0.281\n",
      "Loss after mini-batch    10: 0.402\n",
      "Loss after mini-batch    11: 0.268\n",
      "Loss after mini-batch    12: 0.532\n",
      "Loss after mini-batch    13: 0.421\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.339\n",
      "Loss after mini-batch     2: 0.288\n",
      "Loss after mini-batch     3: 0.542\n",
      "Loss after mini-batch     4: 0.369\n",
      "Loss after mini-batch     5: 0.227\n",
      "Loss after mini-batch     6: 0.320\n",
      "Loss after mini-batch     7: 0.188\n",
      "Loss after mini-batch     8: 0.345\n",
      "Loss after mini-batch     9: 0.310\n",
      "Loss after mini-batch    10: 0.350\n",
      "Loss after mini-batch    11: 0.271\n",
      "Loss after mini-batch    12: 0.215\n",
      "Loss after mini-batch    13: 0.336\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.215\n",
      "Loss after mini-batch     2: 0.384\n",
      "Loss after mini-batch     3: 0.300\n",
      "Loss after mini-batch     4: 0.742\n",
      "Loss after mini-batch     5: 0.228\n",
      "Loss after mini-batch     6: 0.193\n",
      "Loss after mini-batch     7: 0.319\n",
      "Loss after mini-batch     8: 0.499\n",
      "Loss after mini-batch     9: 0.177\n",
      "Loss after mini-batch    10: 0.215\n",
      "Loss after mini-batch    11: 0.184\n",
      "Loss after mini-batch    12: 0.225\n",
      "Loss after mini-batch    13: 0.098\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.388\n",
      "Loss after mini-batch     2: 0.177\n",
      "Loss after mini-batch     3: 0.117\n",
      "Loss after mini-batch     4: 0.154\n",
      "Loss after mini-batch     5: 0.294\n",
      "Loss after mini-batch     6: 0.251\n",
      "Loss after mini-batch     7: 0.131\n",
      "Loss after mini-batch     8: 0.286\n",
      "Loss after mini-batch     9: 0.206\n",
      "Loss after mini-batch    10: 0.517\n",
      "Loss after mini-batch    11: 0.215\n",
      "Loss after mini-batch    12: 0.200\n",
      "Loss after mini-batch    13: 0.092\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.240\n",
      "Loss after mini-batch     2: 0.257\n",
      "Loss after mini-batch     3: 0.389\n",
      "Loss after mini-batch     4: 0.084\n",
      "Loss after mini-batch     5: 0.294\n",
      "Loss after mini-batch     6: 0.197\n",
      "Loss after mini-batch     7: 0.085\n",
      "Loss after mini-batch     8: 0.129\n",
      "Loss after mini-batch     9: 0.199\n",
      "Loss after mini-batch    10: 0.230\n",
      "Loss after mini-batch    11: 0.181\n",
      "Loss after mini-batch    12: 0.175\n",
      "Loss after mini-batch    13: 0.114\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.125\n",
      "Loss after mini-batch     2: 0.080\n",
      "Loss after mini-batch     3: 0.169\n",
      "Loss after mini-batch     4: 0.086\n",
      "Loss after mini-batch     5: 0.164\n",
      "Loss after mini-batch     6: 0.169\n",
      "Loss after mini-batch     7: 0.225\n",
      "Loss after mini-batch     8: 0.179\n",
      "Loss after mini-batch     9: 0.194\n",
      "Loss after mini-batch    10: 0.162\n",
      "Loss after mini-batch    11: 0.186\n",
      "Loss after mini-batch    12: 0.122\n",
      "Loss after mini-batch    13: 0.137\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.191\n",
      "Loss after mini-batch     2: 0.037\n",
      "Loss after mini-batch     3: 0.208\n",
      "Loss after mini-batch     4: 0.045\n",
      "Loss after mini-batch     5: 0.100\n",
      "Loss after mini-batch     6: 0.196\n",
      "Loss after mini-batch     7: 0.098\n",
      "Loss after mini-batch     8: 0.121\n",
      "Loss after mini-batch     9: 0.187\n",
      "Loss after mini-batch    10: 0.114\n",
      "Loss after mini-batch    11: 0.043\n",
      "Loss after mini-batch    12: 0.209\n",
      "Loss after mini-batch    13: 0.157\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.061\n",
      "Loss after mini-batch     2: 0.088\n",
      "Loss after mini-batch     3: 0.089\n",
      "Loss after mini-batch     4: 0.088\n",
      "Loss after mini-batch     5: 0.099\n",
      "Loss after mini-batch     6: 0.092\n",
      "Loss after mini-batch     7: 0.051\n",
      "Loss after mini-batch     8: 0.039\n",
      "Loss after mini-batch     9: 0.079\n",
      "Loss after mini-batch    10: 0.192\n",
      "Loss after mini-batch    11: 0.238\n",
      "Loss after mini-batch    12: 0.092\n",
      "Loss after mini-batch    13: 0.141\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 6: 78 %\n",
      "--------------------------------\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.722\n",
      "Loss after mini-batch     2: 1.509\n",
      "Loss after mini-batch     3: 0.701\n",
      "Loss after mini-batch     4: 1.438\n",
      "Loss after mini-batch     5: 1.020\n",
      "Loss after mini-batch     6: 0.688\n",
      "Loss after mini-batch     7: 0.853\n",
      "Loss after mini-batch     8: 0.845\n",
      "Loss after mini-batch     9: 0.805\n",
      "Loss after mini-batch    10: 0.920\n",
      "Loss after mini-batch    11: 0.661\n",
      "Loss after mini-batch    12: 0.688\n",
      "Loss after mini-batch    13: 0.619\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.789\n",
      "Loss after mini-batch     2: 0.729\n",
      "Loss after mini-batch     3: 0.729\n",
      "Loss after mini-batch     4: 0.692\n",
      "Loss after mini-batch     5: 0.744\n",
      "Loss after mini-batch     6: 0.651\n",
      "Loss after mini-batch     7: 0.598\n",
      "Loss after mini-batch     8: 0.589\n",
      "Loss after mini-batch     9: 0.614\n",
      "Loss after mini-batch    10: 0.581\n",
      "Loss after mini-batch    11: 0.646\n",
      "Loss after mini-batch    12: 0.657\n",
      "Loss after mini-batch    13: 0.630\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.612\n",
      "Loss after mini-batch     2: 0.544\n",
      "Loss after mini-batch     3: 0.603\n",
      "Loss after mini-batch     4: 0.541\n",
      "Loss after mini-batch     5: 0.526\n",
      "Loss after mini-batch     6: 0.535\n",
      "Loss after mini-batch     7: 0.696\n",
      "Loss after mini-batch     8: 0.556\n",
      "Loss after mini-batch     9: 0.506\n",
      "Loss after mini-batch    10: 0.398\n",
      "Loss after mini-batch    11: 0.615\n",
      "Loss after mini-batch    12: 0.574\n",
      "Loss after mini-batch    13: 0.541\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.467\n",
      "Loss after mini-batch     2: 0.392\n",
      "Loss after mini-batch     3: 0.346\n",
      "Loss after mini-batch     4: 0.507\n",
      "Loss after mini-batch     5: 0.434\n",
      "Loss after mini-batch     6: 0.432\n",
      "Loss after mini-batch     7: 0.386\n",
      "Loss after mini-batch     8: 0.623\n",
      "Loss after mini-batch     9: 0.416\n",
      "Loss after mini-batch    10: 0.426\n",
      "Loss after mini-batch    11: 0.362\n",
      "Loss after mini-batch    12: 0.385\n",
      "Loss after mini-batch    13: 0.387\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.362\n",
      "Loss after mini-batch     2: 0.372\n",
      "Loss after mini-batch     3: 0.260\n",
      "Loss after mini-batch     4: 0.254\n",
      "Loss after mini-batch     5: 0.272\n",
      "Loss after mini-batch     6: 0.542\n",
      "Loss after mini-batch     7: 0.449\n",
      "Loss after mini-batch     8: 0.470\n",
      "Loss after mini-batch     9: 0.325\n",
      "Loss after mini-batch    10: 0.285\n",
      "Loss after mini-batch    11: 0.206\n",
      "Loss after mini-batch    12: 0.331\n",
      "Loss after mini-batch    13: 0.328\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.361\n",
      "Loss after mini-batch     2: 0.252\n",
      "Loss after mini-batch     3: 0.246\n",
      "Loss after mini-batch     4: 0.435\n",
      "Loss after mini-batch     5: 0.223\n",
      "Loss after mini-batch     6: 0.392\n",
      "Loss after mini-batch     7: 0.219\n",
      "Loss after mini-batch     8: 0.237\n",
      "Loss after mini-batch     9: 0.126\n",
      "Loss after mini-batch    10: 0.329\n",
      "Loss after mini-batch    11: 0.521\n",
      "Loss after mini-batch    12: 0.300\n",
      "Loss after mini-batch    13: 0.283\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.334\n",
      "Loss after mini-batch     2: 0.294\n",
      "Loss after mini-batch     3: 0.286\n",
      "Loss after mini-batch     4: 0.360\n",
      "Loss after mini-batch     5: 0.294\n",
      "Loss after mini-batch     6: 0.223\n",
      "Loss after mini-batch     7: 0.305\n",
      "Loss after mini-batch     8: 0.129\n",
      "Loss after mini-batch     9: 0.190\n",
      "Loss after mini-batch    10: 0.323\n",
      "Loss after mini-batch    11: 0.164\n",
      "Loss after mini-batch    12: 0.310\n",
      "Loss after mini-batch    13: 0.135\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.138\n",
      "Loss after mini-batch     2: 0.234\n",
      "Loss after mini-batch     3: 0.209\n",
      "Loss after mini-batch     4: 0.117\n",
      "Loss after mini-batch     5: 0.194\n",
      "Loss after mini-batch     6: 0.179\n",
      "Loss after mini-batch     7: 0.249\n",
      "Loss after mini-batch     8: 0.298\n",
      "Loss after mini-batch     9: 0.208\n",
      "Loss after mini-batch    10: 0.122\n",
      "Loss after mini-batch    11: 0.271\n",
      "Loss after mini-batch    12: 0.229\n",
      "Loss after mini-batch    13: 0.260\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.138\n",
      "Loss after mini-batch     2: 0.191\n",
      "Loss after mini-batch     3: 0.249\n",
      "Loss after mini-batch     4: 0.137\n",
      "Loss after mini-batch     5: 0.158\n",
      "Loss after mini-batch     6: 0.156\n",
      "Loss after mini-batch     7: 0.169\n",
      "Loss after mini-batch     8: 0.365\n",
      "Loss after mini-batch     9: 0.045\n",
      "Loss after mini-batch    10: 0.171\n",
      "Loss after mini-batch    11: 0.177\n",
      "Loss after mini-batch    12: 0.113\n",
      "Loss after mini-batch    13: 0.118\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.066\n",
      "Loss after mini-batch     2: 0.169\n",
      "Loss after mini-batch     3: 0.150\n",
      "Loss after mini-batch     4: 0.084\n",
      "Loss after mini-batch     5: 0.116\n",
      "Loss after mini-batch     6: 0.055\n",
      "Loss after mini-batch     7: 0.201\n",
      "Loss after mini-batch     8: 0.159\n",
      "Loss after mini-batch     9: 0.097\n",
      "Loss after mini-batch    10: 0.120\n",
      "Loss after mini-batch    11: 0.212\n",
      "Loss after mini-batch    12: 0.129\n",
      "Loss after mini-batch    13: 0.161\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 7: 78 %\n",
      "--------------------------------\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.825\n",
      "Loss after mini-batch     2: 0.774\n",
      "Loss after mini-batch     3: 0.686\n",
      "Loss after mini-batch     4: 0.657\n",
      "Loss after mini-batch     5: 1.052\n",
      "Loss after mini-batch     6: 0.731\n",
      "Loss after mini-batch     7: 0.664\n",
      "Loss after mini-batch     8: 0.741\n",
      "Loss after mini-batch     9: 0.606\n",
      "Loss after mini-batch    10: 0.661\n",
      "Loss after mini-batch    11: 0.629\n",
      "Loss after mini-batch    12: 0.653\n",
      "Loss after mini-batch    13: 0.575\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.606\n",
      "Loss after mini-batch     2: 0.582\n",
      "Loss after mini-batch     3: 0.581\n",
      "Loss after mini-batch     4: 0.580\n",
      "Loss after mini-batch     5: 0.559\n",
      "Loss after mini-batch     6: 0.543\n",
      "Loss after mini-batch     7: 0.564\n",
      "Loss after mini-batch     8: 0.491\n",
      "Loss after mini-batch     9: 0.551\n",
      "Loss after mini-batch    10: 0.467\n",
      "Loss after mini-batch    11: 0.475\n",
      "Loss after mini-batch    12: 0.494\n",
      "Loss after mini-batch    13: 0.475\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.468\n",
      "Loss after mini-batch     2: 0.371\n",
      "Loss after mini-batch     3: 0.390\n",
      "Loss after mini-batch     4: 0.405\n",
      "Loss after mini-batch     5: 0.289\n",
      "Loss after mini-batch     6: 0.394\n",
      "Loss after mini-batch     7: 0.407\n",
      "Loss after mini-batch     8: 0.409\n",
      "Loss after mini-batch     9: 0.455\n",
      "Loss after mini-batch    10: 0.278\n",
      "Loss after mini-batch    11: 0.364\n",
      "Loss after mini-batch    12: 0.360\n",
      "Loss after mini-batch    13: 0.341\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.229\n",
      "Loss after mini-batch     2: 0.333\n",
      "Loss after mini-batch     3: 0.364\n",
      "Loss after mini-batch     4: 0.394\n",
      "Loss after mini-batch     5: 0.312\n",
      "Loss after mini-batch     6: 0.299\n",
      "Loss after mini-batch     7: 0.215\n",
      "Loss after mini-batch     8: 0.475\n",
      "Loss after mini-batch     9: 0.442\n",
      "Loss after mini-batch    10: 0.260\n",
      "Loss after mini-batch    11: 0.243\n",
      "Loss after mini-batch    12: 0.156\n",
      "Loss after mini-batch    13: 0.374\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.163\n",
      "Loss after mini-batch     2: 0.207\n",
      "Loss after mini-batch     3: 0.308\n",
      "Loss after mini-batch     4: 0.291\n",
      "Loss after mini-batch     5: 0.123\n",
      "Loss after mini-batch     6: 0.406\n",
      "Loss after mini-batch     7: 0.153\n",
      "Loss after mini-batch     8: 0.404\n",
      "Loss after mini-batch     9: 0.264\n",
      "Loss after mini-batch    10: 0.362\n",
      "Loss after mini-batch    11: 0.164\n",
      "Loss after mini-batch    12: 0.182\n",
      "Loss after mini-batch    13: 0.286\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.333\n",
      "Loss after mini-batch     2: 0.128\n",
      "Loss after mini-batch     3: 0.364\n",
      "Loss after mini-batch     4: 0.349\n",
      "Loss after mini-batch     5: 0.080\n",
      "Loss after mini-batch     6: 0.201\n",
      "Loss after mini-batch     7: 0.204\n",
      "Loss after mini-batch     8: 0.121\n",
      "Loss after mini-batch     9: 0.132\n",
      "Loss after mini-batch    10: 0.219\n",
      "Loss after mini-batch    11: 0.128\n",
      "Loss after mini-batch    12: 0.230\n",
      "Loss after mini-batch    13: 0.203\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.102\n",
      "Loss after mini-batch     2: 0.211\n",
      "Loss after mini-batch     3: 0.256\n",
      "Loss after mini-batch     4: 0.100\n",
      "Loss after mini-batch     5: 0.082\n",
      "Loss after mini-batch     6: 0.061\n",
      "Loss after mini-batch     7: 0.118\n",
      "Loss after mini-batch     8: 0.167\n",
      "Loss after mini-batch     9: 0.388\n",
      "Loss after mini-batch    10: 0.166\n",
      "Loss after mini-batch    11: 0.196\n",
      "Loss after mini-batch    12: 0.227\n",
      "Loss after mini-batch    13: 0.150\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.166\n",
      "Loss after mini-batch     2: 0.157\n",
      "Loss after mini-batch     3: 0.174\n",
      "Loss after mini-batch     4: 0.115\n",
      "Loss after mini-batch     5: 0.130\n",
      "Loss after mini-batch     6: 0.108\n",
      "Loss after mini-batch     7: 0.121\n",
      "Loss after mini-batch     8: 0.061\n",
      "Loss after mini-batch     9: 0.084\n",
      "Loss after mini-batch    10: 0.130\n",
      "Loss after mini-batch    11: 0.119\n",
      "Loss after mini-batch    12: 0.080\n",
      "Loss after mini-batch    13: 0.069\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.056\n",
      "Loss after mini-batch     2: 0.173\n",
      "Loss after mini-batch     3: 0.130\n",
      "Loss after mini-batch     4: 0.035\n",
      "Loss after mini-batch     5: 0.067\n",
      "Loss after mini-batch     6: 0.123\n",
      "Loss after mini-batch     7: 0.091\n",
      "Loss after mini-batch     8: 0.109\n",
      "Loss after mini-batch     9: 0.086\n",
      "Loss after mini-batch    10: 0.098\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.084\n",
      "Loss after mini-batch    13: 0.125\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.051\n",
      "Loss after mini-batch     2: 0.083\n",
      "Loss after mini-batch     3: 0.036\n",
      "Loss after mini-batch     4: 0.054\n",
      "Loss after mini-batch     5: 0.069\n",
      "Loss after mini-batch     6: 0.086\n",
      "Loss after mini-batch     7: 0.075\n",
      "Loss after mini-batch     8: 0.077\n",
      "Loss after mini-batch     9: 0.039\n",
      "Loss after mini-batch    10: 0.144\n",
      "Loss after mini-batch    11: 0.144\n",
      "Loss after mini-batch    12: 0.033\n",
      "Loss after mini-batch    13: 0.051\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 8: 71 %\n",
      "--------------------------------\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 1.312\n",
      "Loss after mini-batch     2: 0.791\n",
      "Loss after mini-batch     3: 0.699\n",
      "Loss after mini-batch     4: 0.788\n",
      "Loss after mini-batch     5: 0.653\n",
      "Loss after mini-batch     6: 0.697\n",
      "Loss after mini-batch     7: 0.669\n",
      "Loss after mini-batch     8: 0.669\n",
      "Loss after mini-batch     9: 0.675\n",
      "Loss after mini-batch    10: 0.659\n",
      "Loss after mini-batch    11: 0.648\n",
      "Loss after mini-batch    12: 0.644\n",
      "Loss after mini-batch    13: 0.646\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.612\n",
      "Loss after mini-batch     2: 0.661\n",
      "Loss after mini-batch     3: 0.589\n",
      "Loss after mini-batch     4: 0.632\n",
      "Loss after mini-batch     5: 0.557\n",
      "Loss after mini-batch     6: 0.625\n",
      "Loss after mini-batch     7: 0.586\n",
      "Loss after mini-batch     8: 0.562\n",
      "Loss after mini-batch     9: 0.593\n",
      "Loss after mini-batch    10: 0.540\n",
      "Loss after mini-batch    11: 0.539\n",
      "Loss after mini-batch    12: 0.575\n",
      "Loss after mini-batch    13: 0.422\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.457\n",
      "Loss after mini-batch     2: 0.470\n",
      "Loss after mini-batch     3: 0.458\n",
      "Loss after mini-batch     4: 0.358\n",
      "Loss after mini-batch     5: 0.597\n",
      "Loss after mini-batch     6: 0.342\n",
      "Loss after mini-batch     7: 0.508\n",
      "Loss after mini-batch     8: 0.548\n",
      "Loss after mini-batch     9: 0.443\n",
      "Loss after mini-batch    10: 0.430\n",
      "Loss after mini-batch    11: 0.438\n",
      "Loss after mini-batch    12: 0.345\n",
      "Loss after mini-batch    13: 0.247\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.278\n",
      "Loss after mini-batch     2: 0.369\n",
      "Loss after mini-batch     3: 0.306\n",
      "Loss after mini-batch     4: 0.461\n",
      "Loss after mini-batch     5: 0.205\n",
      "Loss after mini-batch     6: 0.229\n",
      "Loss after mini-batch     7: 0.367\n",
      "Loss after mini-batch     8: 0.314\n",
      "Loss after mini-batch     9: 0.429\n",
      "Loss after mini-batch    10: 0.359\n",
      "Loss after mini-batch    11: 0.674\n",
      "Loss after mini-batch    12: 0.418\n",
      "Loss after mini-batch    13: 0.327\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.485\n",
      "Loss after mini-batch     2: 0.228\n",
      "Loss after mini-batch     3: 0.199\n",
      "Loss after mini-batch     4: 0.529\n",
      "Loss after mini-batch     5: 0.208\n",
      "Loss after mini-batch     6: 0.307\n",
      "Loss after mini-batch     7: 0.388\n",
      "Loss after mini-batch     8: 0.288\n",
      "Loss after mini-batch     9: 0.402\n",
      "Loss after mini-batch    10: 0.315\n",
      "Loss after mini-batch    11: 0.447\n",
      "Loss after mini-batch    12: 0.413\n",
      "Loss after mini-batch    13: 0.468\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.264\n",
      "Loss after mini-batch     2: 0.476\n",
      "Loss after mini-batch     3: 0.379\n",
      "Loss after mini-batch     4: 0.443\n",
      "Loss after mini-batch     5: 0.255\n",
      "Loss after mini-batch     6: 0.287\n",
      "Loss after mini-batch     7: 0.277\n",
      "Loss after mini-batch     8: 0.148\n",
      "Loss after mini-batch     9: 0.204\n",
      "Loss after mini-batch    10: 0.279\n",
      "Loss after mini-batch    11: 0.168\n",
      "Loss after mini-batch    12: 0.231\n",
      "Loss after mini-batch    13: 0.439\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.219\n",
      "Loss after mini-batch     2: 0.259\n",
      "Loss after mini-batch     3: 0.123\n",
      "Loss after mini-batch     4: 0.227\n",
      "Loss after mini-batch     5: 0.162\n",
      "Loss after mini-batch     6: 0.283\n",
      "Loss after mini-batch     7: 0.109\n",
      "Loss after mini-batch     8: 0.401\n",
      "Loss after mini-batch     9: 0.255\n",
      "Loss after mini-batch    10: 0.176\n",
      "Loss after mini-batch    11: 0.150\n",
      "Loss after mini-batch    12: 0.319\n",
      "Loss after mini-batch    13: 0.302\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.367\n",
      "Loss after mini-batch     2: 0.207\n",
      "Loss after mini-batch     3: 0.151\n",
      "Loss after mini-batch     4: 0.122\n",
      "Loss after mini-batch     5: 0.162\n",
      "Loss after mini-batch     6: 0.244\n",
      "Loss after mini-batch     7: 0.206\n",
      "Loss after mini-batch     8: 0.152\n",
      "Loss after mini-batch     9: 0.206\n",
      "Loss after mini-batch    10: 0.194\n",
      "Loss after mini-batch    11: 0.109\n",
      "Loss after mini-batch    12: 0.177\n",
      "Loss after mini-batch    13: 0.138\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.115\n",
      "Loss after mini-batch     2: 0.236\n",
      "Loss after mini-batch     3: 0.306\n",
      "Loss after mini-batch     4: 0.106\n",
      "Loss after mini-batch     5: 0.066\n",
      "Loss after mini-batch     6: 0.173\n",
      "Loss after mini-batch     7: 0.100\n",
      "Loss after mini-batch     8: 0.193\n",
      "Loss after mini-batch     9: 0.091\n",
      "Loss after mini-batch    10: 0.136\n",
      "Loss after mini-batch    11: 0.108\n",
      "Loss after mini-batch    12: 0.047\n",
      "Loss after mini-batch    13: 0.110\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.112\n",
      "Loss after mini-batch     2: 0.045\n",
      "Loss after mini-batch     3: 0.066\n",
      "Loss after mini-batch     4: 0.229\n",
      "Loss after mini-batch     5: 0.121\n",
      "Loss after mini-batch     6: 0.132\n",
      "Loss after mini-batch     7: 0.136\n",
      "Loss after mini-batch     8: 0.091\n",
      "Loss after mini-batch     9: 0.081\n",
      "Loss after mini-batch    10: 0.091\n",
      "Loss after mini-batch    11: 0.103\n",
      "Loss after mini-batch    12: 0.128\n",
      "Loss after mini-batch    13: 0.057\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 9: 85 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 85.71428571428571 %\n",
      "Fold 1: 92.85714285714286 %\n",
      "Fold 2: 82.14285714285714 %\n",
      "Fold 3: 85.71428571428571 %\n",
      "Fold 4: 89.28571428571429 %\n",
      "Fold 5: 82.14285714285714 %\n",
      "Fold 6: 78.57142857142857 %\n",
      "Fold 7: 78.57142857142857 %\n",
      "Fold 8: 71.42857142857143 %\n",
      "Fold 9: 85.71428571428571 %\n",
      "Average: 83.2142857142857 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 10\n",
    "  num_epochs = 10\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvzVZlRNmSap",
    "outputId": "de0ee018-b19a-4d0d-f189-f70736d33ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 1.022\n",
      "Loss after mini-batch     2: 0.679\n",
      "Loss after mini-batch     3: 0.712\n",
      "Loss after mini-batch     4: 0.667\n",
      "Loss after mini-batch     5: 0.662\n",
      "Loss after mini-batch     6: 0.737\n",
      "Loss after mini-batch     7: 0.510\n",
      "Loss after mini-batch     8: 0.552\n",
      "Loss after mini-batch     9: 0.549\n",
      "Loss after mini-batch    10: 0.524\n",
      "Loss after mini-batch    11: 0.504\n",
      "Loss after mini-batch    12: 0.642\n",
      "Loss after mini-batch    13: 0.848\n",
      "Loss after mini-batch    14: 0.503\n",
      "Loss after mini-batch    15: 0.534\n",
      "Loss after mini-batch    16: 0.615\n",
      "Loss after mini-batch    17: 0.585\n",
      "Loss after mini-batch    18: 0.601\n",
      "Loss after mini-batch    19: 0.538\n",
      "Loss after mini-batch    20: 0.400\n",
      "Loss after mini-batch    21: 0.317\n",
      "Loss after mini-batch    22: 0.432\n",
      "Loss after mini-batch    23: 0.439\n",
      "Loss after mini-batch    24: 0.388\n",
      "Loss after mini-batch    25: 0.368\n",
      "Loss after mini-batch    26: 0.747\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.246\n",
      "Loss after mini-batch     2: 0.445\n",
      "Loss after mini-batch     3: 0.376\n",
      "Loss after mini-batch     4: 0.268\n",
      "Loss after mini-batch     5: 0.287\n",
      "Loss after mini-batch     6: 0.343\n",
      "Loss after mini-batch     7: 0.201\n",
      "Loss after mini-batch     8: 0.538\n",
      "Loss after mini-batch     9: 0.236\n",
      "Loss after mini-batch    10: 0.246\n",
      "Loss after mini-batch    11: 0.344\n",
      "Loss after mini-batch    12: 0.346\n",
      "Loss after mini-batch    13: 0.630\n",
      "Loss after mini-batch    14: 0.517\n",
      "Loss after mini-batch    15: 0.414\n",
      "Loss after mini-batch    16: 0.434\n",
      "Loss after mini-batch    17: 0.354\n",
      "Loss after mini-batch    18: 0.447\n",
      "Loss after mini-batch    19: 0.186\n",
      "Loss after mini-batch    20: 0.359\n",
      "Loss after mini-batch    21: 0.378\n",
      "Loss after mini-batch    22: 0.446\n",
      "Loss after mini-batch    23: 0.706\n",
      "Loss after mini-batch    24: 0.260\n",
      "Loss after mini-batch    25: 0.262\n",
      "Loss after mini-batch    26: 0.538\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.449\n",
      "Loss after mini-batch     2: 0.278\n",
      "Loss after mini-batch     3: 0.111\n",
      "Loss after mini-batch     4: 0.211\n",
      "Loss after mini-batch     5: 0.288\n",
      "Loss after mini-batch     6: 0.350\n",
      "Loss after mini-batch     7: 0.266\n",
      "Loss after mini-batch     8: 0.335\n",
      "Loss after mini-batch     9: 0.262\n",
      "Loss after mini-batch    10: 0.158\n",
      "Loss after mini-batch    11: 0.301\n",
      "Loss after mini-batch    12: 0.557\n",
      "Loss after mini-batch    13: 0.345\n",
      "Loss after mini-batch    14: 0.040\n",
      "Loss after mini-batch    15: 0.237\n",
      "Loss after mini-batch    16: 0.342\n",
      "Loss after mini-batch    17: 0.095\n",
      "Loss after mini-batch    18: 0.179\n",
      "Loss after mini-batch    19: 0.300\n",
      "Loss after mini-batch    20: 0.200\n",
      "Loss after mini-batch    21: 0.183\n",
      "Loss after mini-batch    22: 0.325\n",
      "Loss after mini-batch    23: 0.062\n",
      "Loss after mini-batch    24: 0.395\n",
      "Loss after mini-batch    25: 0.267\n",
      "Loss after mini-batch    26: 0.060\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.212\n",
      "Loss after mini-batch     2: 0.271\n",
      "Loss after mini-batch     3: 0.344\n",
      "Loss after mini-batch     4: 0.372\n",
      "Loss after mini-batch     5: 0.335\n",
      "Loss after mini-batch     6: 0.260\n",
      "Loss after mini-batch     7: 0.242\n",
      "Loss after mini-batch     8: 0.185\n",
      "Loss after mini-batch     9: 0.178\n",
      "Loss after mini-batch    10: 0.255\n",
      "Loss after mini-batch    11: 0.451\n",
      "Loss after mini-batch    12: 0.072\n",
      "Loss after mini-batch    13: 0.218\n",
      "Loss after mini-batch    14: 0.042\n",
      "Loss after mini-batch    15: 0.154\n",
      "Loss after mini-batch    16: 0.135\n",
      "Loss after mini-batch    17: 0.091\n",
      "Loss after mini-batch    18: 0.028\n",
      "Loss after mini-batch    19: 0.121\n",
      "Loss after mini-batch    20: 0.168\n",
      "Loss after mini-batch    21: 0.123\n",
      "Loss after mini-batch    22: 0.056\n",
      "Loss after mini-batch    23: 0.151\n",
      "Loss after mini-batch    24: 0.188\n",
      "Loss after mini-batch    25: 0.125\n",
      "Loss after mini-batch    26: 0.008\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.104\n",
      "Loss after mini-batch     2: 0.080\n",
      "Loss after mini-batch     3: 0.175\n",
      "Loss after mini-batch     4: 0.151\n",
      "Loss after mini-batch     5: 0.173\n",
      "Loss after mini-batch     6: 0.154\n",
      "Loss after mini-batch     7: 0.047\n",
      "Loss after mini-batch     8: 0.083\n",
      "Loss after mini-batch     9: 0.064\n",
      "Loss after mini-batch    10: 0.066\n",
      "Loss after mini-batch    11: 0.045\n",
      "Loss after mini-batch    12: 0.152\n",
      "Loss after mini-batch    13: 0.019\n",
      "Loss after mini-batch    14: 0.405\n",
      "Loss after mini-batch    15: 0.258\n",
      "Loss after mini-batch    16: 0.150\n",
      "Loss after mini-batch    17: 0.053\n",
      "Loss after mini-batch    18: 0.092\n",
      "Loss after mini-batch    19: 0.016\n",
      "Loss after mini-batch    20: 0.064\n",
      "Loss after mini-batch    21: 0.147\n",
      "Loss after mini-batch    22: 0.562\n",
      "Loss after mini-batch    23: 0.310\n",
      "Loss after mini-batch    24: 0.246\n",
      "Loss after mini-batch    25: 0.273\n",
      "Loss after mini-batch    26: 0.093\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.087\n",
      "Loss after mini-batch     2: 0.052\n",
      "Loss after mini-batch     3: 0.068\n",
      "Loss after mini-batch     4: 0.114\n",
      "Loss after mini-batch     5: 0.159\n",
      "Loss after mini-batch     6: 0.093\n",
      "Loss after mini-batch     7: 0.063\n",
      "Loss after mini-batch     8: 0.019\n",
      "Loss after mini-batch     9: 0.056\n",
      "Loss after mini-batch    10: 0.189\n",
      "Loss after mini-batch    11: 0.150\n",
      "Loss after mini-batch    12: 0.104\n",
      "Loss after mini-batch    13: 0.029\n",
      "Loss after mini-batch    14: 0.060\n",
      "Loss after mini-batch    15: 0.094\n",
      "Loss after mini-batch    16: 0.055\n",
      "Loss after mini-batch    17: 0.035\n",
      "Loss after mini-batch    18: 0.096\n",
      "Loss after mini-batch    19: 0.145\n",
      "Loss after mini-batch    20: 0.023\n",
      "Loss after mini-batch    21: 0.129\n",
      "Loss after mini-batch    22: 0.165\n",
      "Loss after mini-batch    23: 0.020\n",
      "Loss after mini-batch    24: 0.079\n",
      "Loss after mini-batch    25: 0.023\n",
      "Loss after mini-batch    26: 0.004\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.063\n",
      "Loss after mini-batch     2: 0.021\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.026\n",
      "Loss after mini-batch     5: 0.038\n",
      "Loss after mini-batch     6: 0.080\n",
      "Loss after mini-batch     7: 0.303\n",
      "Loss after mini-batch     8: 0.128\n",
      "Loss after mini-batch     9: 0.066\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.084\n",
      "Loss after mini-batch    12: 0.022\n",
      "Loss after mini-batch    13: 0.081\n",
      "Loss after mini-batch    14: 0.030\n",
      "Loss after mini-batch    15: 0.042\n",
      "Loss after mini-batch    16: 0.070\n",
      "Loss after mini-batch    17: 0.064\n",
      "Loss after mini-batch    18: 0.042\n",
      "Loss after mini-batch    19: 0.003\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.017\n",
      "Loss after mini-batch    22: 0.028\n",
      "Loss after mini-batch    23: 0.004\n",
      "Loss after mini-batch    24: 0.084\n",
      "Loss after mini-batch    25: 0.015\n",
      "Loss after mini-batch    26: 0.001\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.018\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.024\n",
      "Loss after mini-batch     4: 0.095\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.128\n",
      "Loss after mini-batch     9: 0.045\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.017\n",
      "Loss after mini-batch    12: 0.015\n",
      "Loss after mini-batch    13: 0.033\n",
      "Loss after mini-batch    14: 0.024\n",
      "Loss after mini-batch    15: 0.013\n",
      "Loss after mini-batch    16: 0.004\n",
      "Loss after mini-batch    17: 0.004\n",
      "Loss after mini-batch    18: 0.019\n",
      "Loss after mini-batch    19: 0.004\n",
      "Loss after mini-batch    20: 0.009\n",
      "Loss after mini-batch    21: 0.049\n",
      "Loss after mini-batch    22: 0.007\n",
      "Loss after mini-batch    23: 0.056\n",
      "Loss after mini-batch    24: 0.034\n",
      "Loss after mini-batch    25: 0.018\n",
      "Loss after mini-batch    26: 0.011\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.041\n",
      "Loss after mini-batch     3: 0.091\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.020\n",
      "Loss after mini-batch     8: 0.016\n",
      "Loss after mini-batch     9: 0.027\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.041\n",
      "Loss after mini-batch    13: 0.004\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.009\n",
      "Loss after mini-batch    17: 0.011\n",
      "Loss after mini-batch    18: 0.056\n",
      "Loss after mini-batch    19: 0.009\n",
      "Loss after mini-batch    20: 0.010\n",
      "Loss after mini-batch    21: 0.008\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.020\n",
      "Loss after mini-batch    24: 0.008\n",
      "Loss after mini-batch    25: 0.011\n",
      "Loss after mini-batch    26: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.037\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.012\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.011\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.008\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.005\n",
      "Loss after mini-batch    16: 0.006\n",
      "Loss after mini-batch    17: 0.006\n",
      "Loss after mini-batch    18: 0.010\n",
      "Loss after mini-batch    19: 0.026\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.006\n",
      "Loss after mini-batch    22: 0.065\n",
      "Loss after mini-batch    23: 0.037\n",
      "Loss after mini-batch    24: 0.000\n",
      "Loss after mini-batch    25: 0.001\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 75 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.747\n",
      "Loss after mini-batch     2: 0.956\n",
      "Loss after mini-batch     3: 0.844\n",
      "Loss after mini-batch     4: 0.759\n",
      "Loss after mini-batch     5: 0.720\n",
      "Loss after mini-batch     6: 0.764\n",
      "Loss after mini-batch     7: 0.465\n",
      "Loss after mini-batch     8: 0.497\n",
      "Loss after mini-batch     9: 1.575\n",
      "Loss after mini-batch    10: 1.445\n",
      "Loss after mini-batch    11: 1.236\n",
      "Loss after mini-batch    12: 0.809\n",
      "Loss after mini-batch    13: 0.648\n",
      "Loss after mini-batch    14: 0.705\n",
      "Loss after mini-batch    15: 0.812\n",
      "Loss after mini-batch    16: 0.660\n",
      "Loss after mini-batch    17: 0.622\n",
      "Loss after mini-batch    18: 0.769\n",
      "Loss after mini-batch    19: 0.590\n",
      "Loss after mini-batch    20: 0.622\n",
      "Loss after mini-batch    21: 0.610\n",
      "Loss after mini-batch    22: 0.966\n",
      "Loss after mini-batch    23: 0.702\n",
      "Loss after mini-batch    24: 0.604\n",
      "Loss after mini-batch    25: 0.615\n",
      "Loss after mini-batch    26: 0.602\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.608\n",
      "Loss after mini-batch     2: 0.547\n",
      "Loss after mini-batch     3: 0.521\n",
      "Loss after mini-batch     4: 0.623\n",
      "Loss after mini-batch     5: 0.549\n",
      "Loss after mini-batch     6: 0.676\n",
      "Loss after mini-batch     7: 0.402\n",
      "Loss after mini-batch     8: 0.312\n",
      "Loss after mini-batch     9: 0.531\n",
      "Loss after mini-batch    10: 0.322\n",
      "Loss after mini-batch    11: 0.518\n",
      "Loss after mini-batch    12: 0.471\n",
      "Loss after mini-batch    13: 0.614\n",
      "Loss after mini-batch    14: 0.357\n",
      "Loss after mini-batch    15: 0.428\n",
      "Loss after mini-batch    16: 0.598\n",
      "Loss after mini-batch    17: 0.413\n",
      "Loss after mini-batch    18: 0.323\n",
      "Loss after mini-batch    19: 0.292\n",
      "Loss after mini-batch    20: 0.467\n",
      "Loss after mini-batch    21: 0.368\n",
      "Loss after mini-batch    22: 0.411\n",
      "Loss after mini-batch    23: 0.211\n",
      "Loss after mini-batch    24: 0.502\n",
      "Loss after mini-batch    25: 0.540\n",
      "Loss after mini-batch    26: 0.560\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.329\n",
      "Loss after mini-batch     2: 0.312\n",
      "Loss after mini-batch     3: 0.546\n",
      "Loss after mini-batch     4: 0.232\n",
      "Loss after mini-batch     5: 0.207\n",
      "Loss after mini-batch     6: 0.384\n",
      "Loss after mini-batch     7: 0.263\n",
      "Loss after mini-batch     8: 0.376\n",
      "Loss after mini-batch     9: 0.216\n",
      "Loss after mini-batch    10: 0.226\n",
      "Loss after mini-batch    11: 0.485\n",
      "Loss after mini-batch    12: 0.296\n",
      "Loss after mini-batch    13: 0.158\n",
      "Loss after mini-batch    14: 0.244\n",
      "Loss after mini-batch    15: 0.517\n",
      "Loss after mini-batch    16: 0.392\n",
      "Loss after mini-batch    17: 0.543\n",
      "Loss after mini-batch    18: 0.251\n",
      "Loss after mini-batch    19: 0.122\n",
      "Loss after mini-batch    20: 0.070\n",
      "Loss after mini-batch    21: 0.470\n",
      "Loss after mini-batch    22: 0.311\n",
      "Loss after mini-batch    23: 0.099\n",
      "Loss after mini-batch    24: 0.208\n",
      "Loss after mini-batch    25: 0.706\n",
      "Loss after mini-batch    26: 0.004\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.117\n",
      "Loss after mini-batch     2: 0.324\n",
      "Loss after mini-batch     3: 0.148\n",
      "Loss after mini-batch     4: 0.263\n",
      "Loss after mini-batch     5: 0.160\n",
      "Loss after mini-batch     6: 0.243\n",
      "Loss after mini-batch     7: 0.357\n",
      "Loss after mini-batch     8: 0.129\n",
      "Loss after mini-batch     9: 0.240\n",
      "Loss after mini-batch    10: 0.218\n",
      "Loss after mini-batch    11: 0.300\n",
      "Loss after mini-batch    12: 0.287\n",
      "Loss after mini-batch    13: 0.220\n",
      "Loss after mini-batch    14: 0.283\n",
      "Loss after mini-batch    15: 0.348\n",
      "Loss after mini-batch    16: 0.323\n",
      "Loss after mini-batch    17: 0.147\n",
      "Loss after mini-batch    18: 0.134\n",
      "Loss after mini-batch    19: 0.259\n",
      "Loss after mini-batch    20: 0.079\n",
      "Loss after mini-batch    21: 0.218\n",
      "Loss after mini-batch    22: 0.230\n",
      "Loss after mini-batch    23: 0.075\n",
      "Loss after mini-batch    24: 0.187\n",
      "Loss after mini-batch    25: 0.100\n",
      "Loss after mini-batch    26: 0.184\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.513\n",
      "Loss after mini-batch     2: 0.112\n",
      "Loss after mini-batch     3: 0.151\n",
      "Loss after mini-batch     4: 0.146\n",
      "Loss after mini-batch     5: 0.268\n",
      "Loss after mini-batch     6: 0.107\n",
      "Loss after mini-batch     7: 0.050\n",
      "Loss after mini-batch     8: 0.132\n",
      "Loss after mini-batch     9: 0.130\n",
      "Loss after mini-batch    10: 0.115\n",
      "Loss after mini-batch    11: 0.164\n",
      "Loss after mini-batch    12: 0.081\n",
      "Loss after mini-batch    13: 0.290\n",
      "Loss after mini-batch    14: 0.447\n",
      "Loss after mini-batch    15: 0.203\n",
      "Loss after mini-batch    16: 0.184\n",
      "Loss after mini-batch    17: 0.198\n",
      "Loss after mini-batch    18: 0.151\n",
      "Loss after mini-batch    19: 0.145\n",
      "Loss after mini-batch    20: 0.159\n",
      "Loss after mini-batch    21: 0.162\n",
      "Loss after mini-batch    22: 0.156\n",
      "Loss after mini-batch    23: 0.160\n",
      "Loss after mini-batch    24: 0.138\n",
      "Loss after mini-batch    25: 0.190\n",
      "Loss after mini-batch    26: 0.037\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.175\n",
      "Loss after mini-batch     2: 0.289\n",
      "Loss after mini-batch     3: 0.121\n",
      "Loss after mini-batch     4: 0.069\n",
      "Loss after mini-batch     5: 0.034\n",
      "Loss after mini-batch     6: 0.301\n",
      "Loss after mini-batch     7: 0.286\n",
      "Loss after mini-batch     8: 0.062\n",
      "Loss after mini-batch     9: 0.099\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.030\n",
      "Loss after mini-batch    12: 0.139\n",
      "Loss after mini-batch    13: 0.162\n",
      "Loss after mini-batch    14: 0.022\n",
      "Loss after mini-batch    15: 0.019\n",
      "Loss after mini-batch    16: 0.019\n",
      "Loss after mini-batch    17: 0.072\n",
      "Loss after mini-batch    18: 0.210\n",
      "Loss after mini-batch    19: 0.096\n",
      "Loss after mini-batch    20: 0.126\n",
      "Loss after mini-batch    21: 0.183\n",
      "Loss after mini-batch    22: 0.146\n",
      "Loss after mini-batch    23: 0.055\n",
      "Loss after mini-batch    24: 0.076\n",
      "Loss after mini-batch    25: 0.168\n",
      "Loss after mini-batch    26: 0.027\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.088\n",
      "Loss after mini-batch     2: 0.092\n",
      "Loss after mini-batch     3: 0.031\n",
      "Loss after mini-batch     4: 0.067\n",
      "Loss after mini-batch     5: 0.088\n",
      "Loss after mini-batch     6: 0.117\n",
      "Loss after mini-batch     7: 0.083\n",
      "Loss after mini-batch     8: 0.080\n",
      "Loss after mini-batch     9: 0.061\n",
      "Loss after mini-batch    10: 0.025\n",
      "Loss after mini-batch    11: 0.055\n",
      "Loss after mini-batch    12: 0.257\n",
      "Loss after mini-batch    13: 0.079\n",
      "Loss after mini-batch    14: 0.039\n",
      "Loss after mini-batch    15: 0.017\n",
      "Loss after mini-batch    16: 0.250\n",
      "Loss after mini-batch    17: 0.026\n",
      "Loss after mini-batch    18: 0.140\n",
      "Loss after mini-batch    19: 0.059\n",
      "Loss after mini-batch    20: 0.026\n",
      "Loss after mini-batch    21: 0.052\n",
      "Loss after mini-batch    22: 0.060\n",
      "Loss after mini-batch    23: 0.130\n",
      "Loss after mini-batch    24: 0.128\n",
      "Loss after mini-batch    25: 0.115\n",
      "Loss after mini-batch    26: 0.042\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.044\n",
      "Loss after mini-batch     2: 0.047\n",
      "Loss after mini-batch     3: 0.042\n",
      "Loss after mini-batch     4: 0.064\n",
      "Loss after mini-batch     5: 0.024\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.036\n",
      "Loss after mini-batch     8: 0.066\n",
      "Loss after mini-batch     9: 0.093\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.041\n",
      "Loss after mini-batch    14: 0.044\n",
      "Loss after mini-batch    15: 0.175\n",
      "Loss after mini-batch    16: 0.037\n",
      "Loss after mini-batch    17: 0.058\n",
      "Loss after mini-batch    18: 0.052\n",
      "Loss after mini-batch    19: 0.215\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    21: 0.018\n",
      "Loss after mini-batch    22: 0.035\n",
      "Loss after mini-batch    23: 0.054\n",
      "Loss after mini-batch    24: 0.016\n",
      "Loss after mini-batch    25: 0.042\n",
      "Loss after mini-batch    26: 0.223\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.066\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.084\n",
      "Loss after mini-batch     4: 0.213\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.020\n",
      "Loss after mini-batch     7: 0.164\n",
      "Loss after mini-batch     8: 0.038\n",
      "Loss after mini-batch     9: 0.075\n",
      "Loss after mini-batch    10: 0.059\n",
      "Loss after mini-batch    11: 0.049\n",
      "Loss after mini-batch    12: 0.011\n",
      "Loss after mini-batch    13: 0.018\n",
      "Loss after mini-batch    14: 0.027\n",
      "Loss after mini-batch    15: 0.006\n",
      "Loss after mini-batch    16: 0.031\n",
      "Loss after mini-batch    17: 0.027\n",
      "Loss after mini-batch    18: 0.024\n",
      "Loss after mini-batch    19: 0.026\n",
      "Loss after mini-batch    20: 0.026\n",
      "Loss after mini-batch    21: 0.021\n",
      "Loss after mini-batch    22: 0.055\n",
      "Loss after mini-batch    23: 0.044\n",
      "Loss after mini-batch    24: 0.010\n",
      "Loss after mini-batch    25: 0.024\n",
      "Loss after mini-batch    26: 0.013\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.169\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.037\n",
      "Loss after mini-batch     5: 0.019\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.042\n",
      "Loss after mini-batch     9: 0.013\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.019\n",
      "Loss after mini-batch    12: 0.013\n",
      "Loss after mini-batch    13: 0.029\n",
      "Loss after mini-batch    14: 0.119\n",
      "Loss after mini-batch    15: 0.013\n",
      "Loss after mini-batch    16: 0.006\n",
      "Loss after mini-batch    17: 0.012\n",
      "Loss after mini-batch    18: 0.023\n",
      "Loss after mini-batch    19: 0.011\n",
      "Loss after mini-batch    20: 0.017\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.042\n",
      "Loss after mini-batch    23: 0.021\n",
      "Loss after mini-batch    24: 0.007\n",
      "Loss after mini-batch    25: 0.005\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 78 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.680\n",
      "Loss after mini-batch     2: 0.741\n",
      "Loss after mini-batch     3: 0.505\n",
      "Loss after mini-batch     4: 0.940\n",
      "Loss after mini-batch     5: 1.207\n",
      "Loss after mini-batch     6: 0.654\n",
      "Loss after mini-batch     7: 0.696\n",
      "Loss after mini-batch     8: 0.916\n",
      "Loss after mini-batch     9: 0.871\n",
      "Loss after mini-batch    10: 0.678\n",
      "Loss after mini-batch    11: 0.730\n",
      "Loss after mini-batch    12: 0.949\n",
      "Loss after mini-batch    13: 0.798\n",
      "Loss after mini-batch    14: 0.802\n",
      "Loss after mini-batch    15: 0.673\n",
      "Loss after mini-batch    16: 0.583\n",
      "Loss after mini-batch    17: 0.690\n",
      "Loss after mini-batch    18: 0.673\n",
      "Loss after mini-batch    19: 0.712\n",
      "Loss after mini-batch    20: 0.615\n",
      "Loss after mini-batch    21: 0.564\n",
      "Loss after mini-batch    22: 0.614\n",
      "Loss after mini-batch    23: 0.608\n",
      "Loss after mini-batch    24: 0.722\n",
      "Loss after mini-batch    25: 0.637\n",
      "Loss after mini-batch    26: 0.597\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.616\n",
      "Loss after mini-batch     2: 0.679\n",
      "Loss after mini-batch     3: 0.511\n",
      "Loss after mini-batch     4: 0.645\n",
      "Loss after mini-batch     5: 0.789\n",
      "Loss after mini-batch     6: 0.571\n",
      "Loss after mini-batch     7: 0.536\n",
      "Loss after mini-batch     8: 0.710\n",
      "Loss after mini-batch     9: 0.529\n",
      "Loss after mini-batch    10: 0.484\n",
      "Loss after mini-batch    11: 0.400\n",
      "Loss after mini-batch    12: 0.339\n",
      "Loss after mini-batch    13: 0.480\n",
      "Loss after mini-batch    14: 0.560\n",
      "Loss after mini-batch    15: 0.446\n",
      "Loss after mini-batch    16: 0.459\n",
      "Loss after mini-batch    17: 0.622\n",
      "Loss after mini-batch    18: 0.499\n",
      "Loss after mini-batch    19: 0.406\n",
      "Loss after mini-batch    20: 0.598\n",
      "Loss after mini-batch    21: 0.482\n",
      "Loss after mini-batch    22: 0.357\n",
      "Loss after mini-batch    23: 0.410\n",
      "Loss after mini-batch    24: 0.497\n",
      "Loss after mini-batch    25: 0.370\n",
      "Loss after mini-batch    26: 0.674\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.427\n",
      "Loss after mini-batch     2: 0.135\n",
      "Loss after mini-batch     3: 0.340\n",
      "Loss after mini-batch     4: 0.385\n",
      "Loss after mini-batch     5: 0.596\n",
      "Loss after mini-batch     6: 0.421\n",
      "Loss after mini-batch     7: 0.304\n",
      "Loss after mini-batch     8: 0.374\n",
      "Loss after mini-batch     9: 0.198\n",
      "Loss after mini-batch    10: 0.487\n",
      "Loss after mini-batch    11: 0.351\n",
      "Loss after mini-batch    12: 0.484\n",
      "Loss after mini-batch    13: 0.483\n",
      "Loss after mini-batch    14: 0.742\n",
      "Loss after mini-batch    15: 0.480\n",
      "Loss after mini-batch    16: 0.191\n",
      "Loss after mini-batch    17: 0.370\n",
      "Loss after mini-batch    18: 0.265\n",
      "Loss after mini-batch    19: 0.368\n",
      "Loss after mini-batch    20: 0.457\n",
      "Loss after mini-batch    21: 0.826\n",
      "Loss after mini-batch    22: 0.301\n",
      "Loss after mini-batch    23: 0.306\n",
      "Loss after mini-batch    24: 0.538\n",
      "Loss after mini-batch    25: 0.243\n",
      "Loss after mini-batch    26: 0.246\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.205\n",
      "Loss after mini-batch     2: 0.605\n",
      "Loss after mini-batch     3: 0.346\n",
      "Loss after mini-batch     4: 0.302\n",
      "Loss after mini-batch     5: 0.514\n",
      "Loss after mini-batch     6: 0.157\n",
      "Loss after mini-batch     7: 0.309\n",
      "Loss after mini-batch     8: 0.339\n",
      "Loss after mini-batch     9: 0.520\n",
      "Loss after mini-batch    10: 0.465\n",
      "Loss after mini-batch    11: 0.157\n",
      "Loss after mini-batch    12: 0.194\n",
      "Loss after mini-batch    13: 0.336\n",
      "Loss after mini-batch    14: 0.295\n",
      "Loss after mini-batch    15: 0.433\n",
      "Loss after mini-batch    16: 0.190\n",
      "Loss after mini-batch    17: 0.172\n",
      "Loss after mini-batch    18: 0.389\n",
      "Loss after mini-batch    19: 0.471\n",
      "Loss after mini-batch    20: 0.186\n",
      "Loss after mini-batch    21: 0.361\n",
      "Loss after mini-batch    22: 0.289\n",
      "Loss after mini-batch    23: 0.264\n",
      "Loss after mini-batch    24: 0.376\n",
      "Loss after mini-batch    25: 0.360\n",
      "Loss after mini-batch    26: 0.118\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.228\n",
      "Loss after mini-batch     2: 0.312\n",
      "Loss after mini-batch     3: 0.128\n",
      "Loss after mini-batch     4: 0.493\n",
      "Loss after mini-batch     5: 0.133\n",
      "Loss after mini-batch     6: 0.259\n",
      "Loss after mini-batch     7: 0.223\n",
      "Loss after mini-batch     8: 0.059\n",
      "Loss after mini-batch     9: 0.070\n",
      "Loss after mini-batch    10: 0.293\n",
      "Loss after mini-batch    11: 0.293\n",
      "Loss after mini-batch    12: 0.342\n",
      "Loss after mini-batch    13: 0.109\n",
      "Loss after mini-batch    14: 0.178\n",
      "Loss after mini-batch    15: 0.324\n",
      "Loss after mini-batch    16: 0.532\n",
      "Loss after mini-batch    17: 0.164\n",
      "Loss after mini-batch    18: 0.263\n",
      "Loss after mini-batch    19: 0.178\n",
      "Loss after mini-batch    20: 0.148\n",
      "Loss after mini-batch    21: 0.079\n",
      "Loss after mini-batch    22: 0.081\n",
      "Loss after mini-batch    23: 0.363\n",
      "Loss after mini-batch    24: 0.474\n",
      "Loss after mini-batch    25: 0.365\n",
      "Loss after mini-batch    26: 0.130\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.196\n",
      "Loss after mini-batch     2: 0.367\n",
      "Loss after mini-batch     3: 0.145\n",
      "Loss after mini-batch     4: 0.139\n",
      "Loss after mini-batch     5: 0.136\n",
      "Loss after mini-batch     6: 0.271\n",
      "Loss after mini-batch     7: 0.357\n",
      "Loss after mini-batch     8: 0.271\n",
      "Loss after mini-batch     9: 0.110\n",
      "Loss after mini-batch    10: 0.173\n",
      "Loss after mini-batch    11: 0.054\n",
      "Loss after mini-batch    12: 0.109\n",
      "Loss after mini-batch    13: 0.145\n",
      "Loss after mini-batch    14: 0.168\n",
      "Loss after mini-batch    15: 0.121\n",
      "Loss after mini-batch    16: 0.210\n",
      "Loss after mini-batch    17: 0.122\n",
      "Loss after mini-batch    18: 0.286\n",
      "Loss after mini-batch    19: 0.096\n",
      "Loss after mini-batch    20: 0.177\n",
      "Loss after mini-batch    21: 0.200\n",
      "Loss after mini-batch    22: 0.439\n",
      "Loss after mini-batch    23: 0.215\n",
      "Loss after mini-batch    24: 0.131\n",
      "Loss after mini-batch    25: 0.146\n",
      "Loss after mini-batch    26: 0.740\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.206\n",
      "Loss after mini-batch     2: 0.070\n",
      "Loss after mini-batch     3: 0.238\n",
      "Loss after mini-batch     4: 0.121\n",
      "Loss after mini-batch     5: 0.207\n",
      "Loss after mini-batch     6: 0.264\n",
      "Loss after mini-batch     7: 0.112\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.087\n",
      "Loss after mini-batch    10: 0.094\n",
      "Loss after mini-batch    11: 0.049\n",
      "Loss after mini-batch    12: 0.140\n",
      "Loss after mini-batch    13: 0.103\n",
      "Loss after mini-batch    14: 0.082\n",
      "Loss after mini-batch    15: 0.066\n",
      "Loss after mini-batch    16: 0.056\n",
      "Loss after mini-batch    17: 0.468\n",
      "Loss after mini-batch    18: 0.276\n",
      "Loss after mini-batch    19: 0.092\n",
      "Loss after mini-batch    20: 0.051\n",
      "Loss after mini-batch    21: 0.175\n",
      "Loss after mini-batch    22: 0.215\n",
      "Loss after mini-batch    23: 0.124\n",
      "Loss after mini-batch    24: 0.144\n",
      "Loss after mini-batch    25: 0.166\n",
      "Loss after mini-batch    26: 0.002\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.052\n",
      "Loss after mini-batch     2: 0.068\n",
      "Loss after mini-batch     3: 0.128\n",
      "Loss after mini-batch     4: 0.087\n",
      "Loss after mini-batch     5: 0.044\n",
      "Loss after mini-batch     6: 0.071\n",
      "Loss after mini-batch     7: 0.146\n",
      "Loss after mini-batch     8: 0.013\n",
      "Loss after mini-batch     9: 0.046\n",
      "Loss after mini-batch    10: 0.010\n",
      "Loss after mini-batch    11: 0.012\n",
      "Loss after mini-batch    12: 0.175\n",
      "Loss after mini-batch    13: 0.207\n",
      "Loss after mini-batch    14: 0.015\n",
      "Loss after mini-batch    15: 0.176\n",
      "Loss after mini-batch    16: 0.282\n",
      "Loss after mini-batch    17: 0.009\n",
      "Loss after mini-batch    18: 0.174\n",
      "Loss after mini-batch    19: 0.049\n",
      "Loss after mini-batch    20: 0.153\n",
      "Loss after mini-batch    21: 0.022\n",
      "Loss after mini-batch    22: 0.211\n",
      "Loss after mini-batch    23: 0.213\n",
      "Loss after mini-batch    24: 0.063\n",
      "Loss after mini-batch    25: 0.101\n",
      "Loss after mini-batch    26: 0.021\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.109\n",
      "Loss after mini-batch     2: 0.050\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.052\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.135\n",
      "Loss after mini-batch     7: 0.089\n",
      "Loss after mini-batch     8: 0.062\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.027\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.014\n",
      "Loss after mini-batch    14: 0.102\n",
      "Loss after mini-batch    15: 0.245\n",
      "Loss after mini-batch    16: 0.013\n",
      "Loss after mini-batch    17: 0.129\n",
      "Loss after mini-batch    18: 0.042\n",
      "Loss after mini-batch    19: 0.098\n",
      "Loss after mini-batch    20: 0.160\n",
      "Loss after mini-batch    21: 0.228\n",
      "Loss after mini-batch    22: 0.027\n",
      "Loss after mini-batch    23: 0.024\n",
      "Loss after mini-batch    24: 0.060\n",
      "Loss after mini-batch    25: 0.099\n",
      "Loss after mini-batch    26: 0.018\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.064\n",
      "Loss after mini-batch     5: 0.047\n",
      "Loss after mini-batch     6: 0.053\n",
      "Loss after mini-batch     7: 0.155\n",
      "Loss after mini-batch     8: 0.030\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.024\n",
      "Loss after mini-batch    12: 0.010\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.041\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.123\n",
      "Loss after mini-batch    19: 0.003\n",
      "Loss after mini-batch    20: 0.097\n",
      "Loss after mini-batch    21: 0.042\n",
      "Loss after mini-batch    22: 0.023\n",
      "Loss after mini-batch    23: 0.074\n",
      "Loss after mini-batch    24: 0.086\n",
      "Loss after mini-batch    25: 0.046\n",
      "Loss after mini-batch    26: 0.003\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 78 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.988\n",
      "Loss after mini-batch     2: 0.655\n",
      "Loss after mini-batch     3: 1.186\n",
      "Loss after mini-batch     4: 0.839\n",
      "Loss after mini-batch     5: 0.826\n",
      "Loss after mini-batch     6: 0.719\n",
      "Loss after mini-batch     7: 0.521\n",
      "Loss after mini-batch     8: 0.898\n",
      "Loss after mini-batch     9: 0.629\n",
      "Loss after mini-batch    10: 1.236\n",
      "Loss after mini-batch    11: 0.686\n",
      "Loss after mini-batch    12: 0.667\n",
      "Loss after mini-batch    13: 0.614\n",
      "Loss after mini-batch    14: 0.814\n",
      "Loss after mini-batch    15: 0.740\n",
      "Loss after mini-batch    16: 0.620\n",
      "Loss after mini-batch    17: 0.699\n",
      "Loss after mini-batch    18: 0.621\n",
      "Loss after mini-batch    19: 0.607\n",
      "Loss after mini-batch    20: 0.571\n",
      "Loss after mini-batch    21: 0.541\n",
      "Loss after mini-batch    22: 0.596\n",
      "Loss after mini-batch    23: 0.751\n",
      "Loss after mini-batch    24: 0.682\n",
      "Loss after mini-batch    25: 0.580\n",
      "Loss after mini-batch    26: 0.249\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.650\n",
      "Loss after mini-batch     2: 0.735\n",
      "Loss after mini-batch     3: 0.672\n",
      "Loss after mini-batch     4: 0.623\n",
      "Loss after mini-batch     5: 0.362\n",
      "Loss after mini-batch     6: 0.444\n",
      "Loss after mini-batch     7: 0.984\n",
      "Loss after mini-batch     8: 0.765\n",
      "Loss after mini-batch     9: 1.146\n",
      "Loss after mini-batch    10: 0.501\n",
      "Loss after mini-batch    11: 0.399\n",
      "Loss after mini-batch    12: 0.666\n",
      "Loss after mini-batch    13: 0.485\n",
      "Loss after mini-batch    14: 0.531\n",
      "Loss after mini-batch    15: 0.326\n",
      "Loss after mini-batch    16: 0.353\n",
      "Loss after mini-batch    17: 0.854\n",
      "Loss after mini-batch    18: 0.693\n",
      "Loss after mini-batch    19: 0.562\n",
      "Loss after mini-batch    20: 0.641\n",
      "Loss after mini-batch    21: 0.666\n",
      "Loss after mini-batch    22: 0.707\n",
      "Loss after mini-batch    23: 0.368\n",
      "Loss after mini-batch    24: 0.534\n",
      "Loss after mini-batch    25: 0.487\n",
      "Loss after mini-batch    26: 0.376\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.463\n",
      "Loss after mini-batch     2: 0.360\n",
      "Loss after mini-batch     3: 0.243\n",
      "Loss after mini-batch     4: 0.413\n",
      "Loss after mini-batch     5: 0.354\n",
      "Loss after mini-batch     6: 0.581\n",
      "Loss after mini-batch     7: 0.370\n",
      "Loss after mini-batch     8: 0.485\n",
      "Loss after mini-batch     9: 0.392\n",
      "Loss after mini-batch    10: 0.538\n",
      "Loss after mini-batch    11: 0.351\n",
      "Loss after mini-batch    12: 0.335\n",
      "Loss after mini-batch    13: 0.262\n",
      "Loss after mini-batch    14: 0.379\n",
      "Loss after mini-batch    15: 0.568\n",
      "Loss after mini-batch    16: 0.205\n",
      "Loss after mini-batch    17: 0.463\n",
      "Loss after mini-batch    18: 0.267\n",
      "Loss after mini-batch    19: 0.382\n",
      "Loss after mini-batch    20: 0.446\n",
      "Loss after mini-batch    21: 0.583\n",
      "Loss after mini-batch    22: 0.202\n",
      "Loss after mini-batch    23: 0.206\n",
      "Loss after mini-batch    24: 0.499\n",
      "Loss after mini-batch    25: 0.287\n",
      "Loss after mini-batch    26: 0.102\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.337\n",
      "Loss after mini-batch     2: 0.528\n",
      "Loss after mini-batch     3: 0.360\n",
      "Loss after mini-batch     4: 0.120\n",
      "Loss after mini-batch     5: 0.336\n",
      "Loss after mini-batch     6: 0.252\n",
      "Loss after mini-batch     7: 0.323\n",
      "Loss after mini-batch     8: 0.445\n",
      "Loss after mini-batch     9: 0.292\n",
      "Loss after mini-batch    10: 0.114\n",
      "Loss after mini-batch    11: 0.202\n",
      "Loss after mini-batch    12: 0.285\n",
      "Loss after mini-batch    13: 0.377\n",
      "Loss after mini-batch    14: 0.528\n",
      "Loss after mini-batch    15: 0.170\n",
      "Loss after mini-batch    16: 0.534\n",
      "Loss after mini-batch    17: 0.137\n",
      "Loss after mini-batch    18: 0.395\n",
      "Loss after mini-batch    19: 0.176\n",
      "Loss after mini-batch    20: 0.089\n",
      "Loss after mini-batch    21: 0.181\n",
      "Loss after mini-batch    22: 0.117\n",
      "Loss after mini-batch    23: 0.214\n",
      "Loss after mini-batch    24: 0.653\n",
      "Loss after mini-batch    25: 0.094\n",
      "Loss after mini-batch    26: 0.127\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.128\n",
      "Loss after mini-batch     2: 0.091\n",
      "Loss after mini-batch     3: 0.465\n",
      "Loss after mini-batch     4: 0.193\n",
      "Loss after mini-batch     5: 0.137\n",
      "Loss after mini-batch     6: 0.037\n",
      "Loss after mini-batch     7: 0.331\n",
      "Loss after mini-batch     8: 0.160\n",
      "Loss after mini-batch     9: 0.167\n",
      "Loss after mini-batch    10: 0.236\n",
      "Loss after mini-batch    11: 0.242\n",
      "Loss after mini-batch    12: 0.256\n",
      "Loss after mini-batch    13: 0.071\n",
      "Loss after mini-batch    14: 0.152\n",
      "Loss after mini-batch    15: 0.078\n",
      "Loss after mini-batch    16: 0.137\n",
      "Loss after mini-batch    17: 0.197\n",
      "Loss after mini-batch    18: 0.133\n",
      "Loss after mini-batch    19: 0.260\n",
      "Loss after mini-batch    20: 0.431\n",
      "Loss after mini-batch    21: 0.604\n",
      "Loss after mini-batch    22: 0.235\n",
      "Loss after mini-batch    23: 0.522\n",
      "Loss after mini-batch    24: 0.119\n",
      "Loss after mini-batch    25: 0.256\n",
      "Loss after mini-batch    26: 0.003\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.286\n",
      "Loss after mini-batch     2: 0.435\n",
      "Loss after mini-batch     3: 0.094\n",
      "Loss after mini-batch     4: 0.077\n",
      "Loss after mini-batch     5: 0.189\n",
      "Loss after mini-batch     6: 0.201\n",
      "Loss after mini-batch     7: 0.164\n",
      "Loss after mini-batch     8: 0.301\n",
      "Loss after mini-batch     9: 0.149\n",
      "Loss after mini-batch    10: 0.108\n",
      "Loss after mini-batch    11: 0.252\n",
      "Loss after mini-batch    12: 0.222\n",
      "Loss after mini-batch    13: 0.047\n",
      "Loss after mini-batch    14: 0.104\n",
      "Loss after mini-batch    15: 0.099\n",
      "Loss after mini-batch    16: 0.026\n",
      "Loss after mini-batch    17: 0.055\n",
      "Loss after mini-batch    18: 0.351\n",
      "Loss after mini-batch    19: 0.330\n",
      "Loss after mini-batch    20: 0.225\n",
      "Loss after mini-batch    21: 0.049\n",
      "Loss after mini-batch    22: 0.233\n",
      "Loss after mini-batch    23: 0.154\n",
      "Loss after mini-batch    24: 0.078\n",
      "Loss after mini-batch    25: 0.179\n",
      "Loss after mini-batch    26: 0.180\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.082\n",
      "Loss after mini-batch     2: 0.169\n",
      "Loss after mini-batch     3: 0.248\n",
      "Loss after mini-batch     4: 0.106\n",
      "Loss after mini-batch     5: 0.267\n",
      "Loss after mini-batch     6: 0.058\n",
      "Loss after mini-batch     7: 0.134\n",
      "Loss after mini-batch     8: 0.255\n",
      "Loss after mini-batch     9: 0.043\n",
      "Loss after mini-batch    10: 0.213\n",
      "Loss after mini-batch    11: 0.157\n",
      "Loss after mini-batch    12: 0.028\n",
      "Loss after mini-batch    13: 0.102\n",
      "Loss after mini-batch    14: 0.075\n",
      "Loss after mini-batch    15: 0.147\n",
      "Loss after mini-batch    16: 0.117\n",
      "Loss after mini-batch    17: 0.055\n",
      "Loss after mini-batch    18: 0.153\n",
      "Loss after mini-batch    19: 0.252\n",
      "Loss after mini-batch    20: 0.048\n",
      "Loss after mini-batch    21: 0.016\n",
      "Loss after mini-batch    22: 0.203\n",
      "Loss after mini-batch    23: 0.167\n",
      "Loss after mini-batch    24: 0.144\n",
      "Loss after mini-batch    25: 0.037\n",
      "Loss after mini-batch    26: 0.236\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.020\n",
      "Loss after mini-batch     2: 0.034\n",
      "Loss after mini-batch     3: 0.091\n",
      "Loss after mini-batch     4: 0.131\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.051\n",
      "Loss after mini-batch     7: 0.068\n",
      "Loss after mini-batch     8: 0.232\n",
      "Loss after mini-batch     9: 0.029\n",
      "Loss after mini-batch    10: 0.201\n",
      "Loss after mini-batch    11: 0.257\n",
      "Loss after mini-batch    12: 0.038\n",
      "Loss after mini-batch    13: 0.150\n",
      "Loss after mini-batch    14: 0.011\n",
      "Loss after mini-batch    15: 0.077\n",
      "Loss after mini-batch    16: 0.053\n",
      "Loss after mini-batch    17: 0.065\n",
      "Loss after mini-batch    18: 0.139\n",
      "Loss after mini-batch    19: 0.009\n",
      "Loss after mini-batch    20: 0.116\n",
      "Loss after mini-batch    21: 0.144\n",
      "Loss after mini-batch    22: 0.034\n",
      "Loss after mini-batch    23: 0.296\n",
      "Loss after mini-batch    24: 0.028\n",
      "Loss after mini-batch    25: 0.081\n",
      "Loss after mini-batch    26: 0.246\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.113\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.026\n",
      "Loss after mini-batch     4: 0.019\n",
      "Loss after mini-batch     5: 0.034\n",
      "Loss after mini-batch     6: 0.131\n",
      "Loss after mini-batch     7: 0.049\n",
      "Loss after mini-batch     8: 0.136\n",
      "Loss after mini-batch     9: 0.062\n",
      "Loss after mini-batch    10: 0.206\n",
      "Loss after mini-batch    11: 0.037\n",
      "Loss after mini-batch    12: 0.061\n",
      "Loss after mini-batch    13: 0.214\n",
      "Loss after mini-batch    14: 0.151\n",
      "Loss after mini-batch    15: 0.007\n",
      "Loss after mini-batch    16: 0.039\n",
      "Loss after mini-batch    17: 0.087\n",
      "Loss after mini-batch    18: 0.038\n",
      "Loss after mini-batch    19: 0.085\n",
      "Loss after mini-batch    20: 0.021\n",
      "Loss after mini-batch    21: 0.061\n",
      "Loss after mini-batch    22: 0.028\n",
      "Loss after mini-batch    23: 0.048\n",
      "Loss after mini-batch    24: 0.087\n",
      "Loss after mini-batch    25: 0.014\n",
      "Loss after mini-batch    26: 0.159\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.040\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.076\n",
      "Loss after mini-batch     6: 0.119\n",
      "Loss after mini-batch     7: 0.100\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.093\n",
      "Loss after mini-batch    11: 0.010\n",
      "Loss after mini-batch    12: 0.095\n",
      "Loss after mini-batch    13: 0.044\n",
      "Loss after mini-batch    14: 0.087\n",
      "Loss after mini-batch    15: 0.032\n",
      "Loss after mini-batch    16: 0.045\n",
      "Loss after mini-batch    17: 0.006\n",
      "Loss after mini-batch    18: 0.062\n",
      "Loss after mini-batch    19: 0.031\n",
      "Loss after mini-batch    20: 0.035\n",
      "Loss after mini-batch    21: 0.131\n",
      "Loss after mini-batch    22: 0.059\n",
      "Loss after mini-batch    23: 0.090\n",
      "Loss after mini-batch    24: 0.065\n",
      "Loss after mini-batch    25: 0.069\n",
      "Loss after mini-batch    26: 0.005\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 85 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.683\n",
      "Loss after mini-batch     2: 1.807\n",
      "Loss after mini-batch     3: 0.828\n",
      "Loss after mini-batch     4: 0.701\n",
      "Loss after mini-batch     5: 0.678\n",
      "Loss after mini-batch     6: 0.717\n",
      "Loss after mini-batch     7: 0.724\n",
      "Loss after mini-batch     8: 0.759\n",
      "Loss after mini-batch     9: 0.736\n",
      "Loss after mini-batch    10: 0.708\n",
      "Loss after mini-batch    11: 0.666\n",
      "Loss after mini-batch    12: 0.675\n",
      "Loss after mini-batch    13: 0.673\n",
      "Loss after mini-batch    14: 0.669\n",
      "Loss after mini-batch    15: 0.722\n",
      "Loss after mini-batch    16: 0.775\n",
      "Loss after mini-batch    17: 0.769\n",
      "Loss after mini-batch    18: 0.622\n",
      "Loss after mini-batch    19: 0.661\n",
      "Loss after mini-batch    20: 0.676\n",
      "Loss after mini-batch    21: 0.688\n",
      "Loss after mini-batch    22: 0.686\n",
      "Loss after mini-batch    23: 0.668\n",
      "Loss after mini-batch    24: 0.680\n",
      "Loss after mini-batch    25: 0.664\n",
      "Loss after mini-batch    26: 0.445\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.587\n",
      "Loss after mini-batch     2: 0.684\n",
      "Loss after mini-batch     3: 0.670\n",
      "Loss after mini-batch     4: 0.727\n",
      "Loss after mini-batch     5: 0.692\n",
      "Loss after mini-batch     6: 1.039\n",
      "Loss after mini-batch     7: 0.781\n",
      "Loss after mini-batch     8: 0.904\n",
      "Loss after mini-batch     9: 0.730\n",
      "Loss after mini-batch    10: 0.696\n",
      "Loss after mini-batch    11: 0.631\n",
      "Loss after mini-batch    12: 0.643\n",
      "Loss after mini-batch    13: 0.561\n",
      "Loss after mini-batch    14: 0.635\n",
      "Loss after mini-batch    15: 0.706\n",
      "Loss after mini-batch    16: 0.564\n",
      "Loss after mini-batch    17: 0.751\n",
      "Loss after mini-batch    18: 0.595\n",
      "Loss after mini-batch    19: 0.861\n",
      "Loss after mini-batch    20: 0.687\n",
      "Loss after mini-batch    21: 0.542\n",
      "Loss after mini-batch    22: 0.386\n",
      "Loss after mini-batch    23: 0.604\n",
      "Loss after mini-batch    24: 0.694\n",
      "Loss after mini-batch    25: 0.607\n",
      "Loss after mini-batch    26: 0.650\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.519\n",
      "Loss after mini-batch     2: 0.548\n",
      "Loss after mini-batch     3: 0.548\n",
      "Loss after mini-batch     4: 0.441\n",
      "Loss after mini-batch     5: 0.545\n",
      "Loss after mini-batch     6: 0.571\n",
      "Loss after mini-batch     7: 0.405\n",
      "Loss after mini-batch     8: 0.556\n",
      "Loss after mini-batch     9: 0.348\n",
      "Loss after mini-batch    10: 0.585\n",
      "Loss after mini-batch    11: 0.406\n",
      "Loss after mini-batch    12: 0.599\n",
      "Loss after mini-batch    13: 0.255\n",
      "Loss after mini-batch    14: 0.287\n",
      "Loss after mini-batch    15: 0.356\n",
      "Loss after mini-batch    16: 0.497\n",
      "Loss after mini-batch    17: 0.401\n",
      "Loss after mini-batch    18: 0.595\n",
      "Loss after mini-batch    19: 0.389\n",
      "Loss after mini-batch    20: 0.244\n",
      "Loss after mini-batch    21: 0.464\n",
      "Loss after mini-batch    22: 0.544\n",
      "Loss after mini-batch    23: 0.216\n",
      "Loss after mini-batch    24: 0.454\n",
      "Loss after mini-batch    25: 0.341\n",
      "Loss after mini-batch    26: 0.097\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.219\n",
      "Loss after mini-batch     2: 0.397\n",
      "Loss after mini-batch     3: 0.291\n",
      "Loss after mini-batch     4: 0.295\n",
      "Loss after mini-batch     5: 0.347\n",
      "Loss after mini-batch     6: 0.312\n",
      "Loss after mini-batch     7: 0.347\n",
      "Loss after mini-batch     8: 0.434\n",
      "Loss after mini-batch     9: 0.627\n",
      "Loss after mini-batch    10: 0.071\n",
      "Loss after mini-batch    11: 0.281\n",
      "Loss after mini-batch    12: 0.391\n",
      "Loss after mini-batch    13: 0.384\n",
      "Loss after mini-batch    14: 0.369\n",
      "Loss after mini-batch    15: 0.407\n",
      "Loss after mini-batch    16: 0.460\n",
      "Loss after mini-batch    17: 0.371\n",
      "Loss after mini-batch    18: 0.227\n",
      "Loss after mini-batch    19: 0.489\n",
      "Loss after mini-batch    20: 0.375\n",
      "Loss after mini-batch    21: 0.221\n",
      "Loss after mini-batch    22: 0.301\n",
      "Loss after mini-batch    23: 0.398\n",
      "Loss after mini-batch    24: 0.374\n",
      "Loss after mini-batch    25: 0.251\n",
      "Loss after mini-batch    26: 0.063\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.175\n",
      "Loss after mini-batch     2: 0.125\n",
      "Loss after mini-batch     3: 0.248\n",
      "Loss after mini-batch     4: 0.236\n",
      "Loss after mini-batch     5: 0.116\n",
      "Loss after mini-batch     6: 0.192\n",
      "Loss after mini-batch     7: 0.135\n",
      "Loss after mini-batch     8: 0.208\n",
      "Loss after mini-batch     9: 0.190\n",
      "Loss after mini-batch    10: 0.101\n",
      "Loss after mini-batch    11: 0.184\n",
      "Loss after mini-batch    12: 0.472\n",
      "Loss after mini-batch    13: 0.099\n",
      "Loss after mini-batch    14: 0.092\n",
      "Loss after mini-batch    15: 0.055\n",
      "Loss after mini-batch    16: 0.203\n",
      "Loss after mini-batch    17: 0.892\n",
      "Loss after mini-batch    18: 0.483\n",
      "Loss after mini-batch    19: 0.668\n",
      "Loss after mini-batch    20: 0.203\n",
      "Loss after mini-batch    21: 0.135\n",
      "Loss after mini-batch    22: 0.429\n",
      "Loss after mini-batch    23: 0.147\n",
      "Loss after mini-batch    24: 0.212\n",
      "Loss after mini-batch    25: 0.473\n",
      "Loss after mini-batch    26: 0.186\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.183\n",
      "Loss after mini-batch     2: 0.227\n",
      "Loss after mini-batch     3: 0.199\n",
      "Loss after mini-batch     4: 0.303\n",
      "Loss after mini-batch     5: 0.172\n",
      "Loss after mini-batch     6: 0.160\n",
      "Loss after mini-batch     7: 0.128\n",
      "Loss after mini-batch     8: 0.031\n",
      "Loss after mini-batch     9: 0.190\n",
      "Loss after mini-batch    10: 0.082\n",
      "Loss after mini-batch    11: 0.066\n",
      "Loss after mini-batch    12: 0.263\n",
      "Loss after mini-batch    13: 0.107\n",
      "Loss after mini-batch    14: 0.400\n",
      "Loss after mini-batch    15: 0.217\n",
      "Loss after mini-batch    16: 0.495\n",
      "Loss after mini-batch    17: 0.025\n",
      "Loss after mini-batch    18: 0.283\n",
      "Loss after mini-batch    19: 0.286\n",
      "Loss after mini-batch    20: 0.203\n",
      "Loss after mini-batch    21: 0.033\n",
      "Loss after mini-batch    22: 0.289\n",
      "Loss after mini-batch    23: 0.251\n",
      "Loss after mini-batch    24: 0.144\n",
      "Loss after mini-batch    25: 0.321\n",
      "Loss after mini-batch    26: 0.048\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.315\n",
      "Loss after mini-batch     2: 0.186\n",
      "Loss after mini-batch     3: 0.085\n",
      "Loss after mini-batch     4: 0.051\n",
      "Loss after mini-batch     5: 0.093\n",
      "Loss after mini-batch     6: 0.063\n",
      "Loss after mini-batch     7: 0.106\n",
      "Loss after mini-batch     8: 0.308\n",
      "Loss after mini-batch     9: 0.171\n",
      "Loss after mini-batch    10: 0.357\n",
      "Loss after mini-batch    11: 0.210\n",
      "Loss after mini-batch    12: 0.216\n",
      "Loss after mini-batch    13: 0.051\n",
      "Loss after mini-batch    14: 0.188\n",
      "Loss after mini-batch    15: 0.126\n",
      "Loss after mini-batch    16: 0.128\n",
      "Loss after mini-batch    17: 0.180\n",
      "Loss after mini-batch    18: 0.052\n",
      "Loss after mini-batch    19: 0.257\n",
      "Loss after mini-batch    20: 0.073\n",
      "Loss after mini-batch    21: 0.295\n",
      "Loss after mini-batch    22: 0.017\n",
      "Loss after mini-batch    23: 0.032\n",
      "Loss after mini-batch    24: 0.091\n",
      "Loss after mini-batch    25: 0.118\n",
      "Loss after mini-batch    26: 0.320\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.195\n",
      "Loss after mini-batch     2: 0.036\n",
      "Loss after mini-batch     3: 0.110\n",
      "Loss after mini-batch     4: 0.087\n",
      "Loss after mini-batch     5: 0.225\n",
      "Loss after mini-batch     6: 0.145\n",
      "Loss after mini-batch     7: 0.110\n",
      "Loss after mini-batch     8: 0.036\n",
      "Loss after mini-batch     9: 0.088\n",
      "Loss after mini-batch    10: 0.074\n",
      "Loss after mini-batch    11: 0.153\n",
      "Loss after mini-batch    12: 0.137\n",
      "Loss after mini-batch    13: 0.121\n",
      "Loss after mini-batch    14: 0.089\n",
      "Loss after mini-batch    15: 0.034\n",
      "Loss after mini-batch    16: 0.124\n",
      "Loss after mini-batch    17: 0.020\n",
      "Loss after mini-batch    18: 0.137\n",
      "Loss after mini-batch    19: 0.331\n",
      "Loss after mini-batch    20: 0.152\n",
      "Loss after mini-batch    21: 0.089\n",
      "Loss after mini-batch    22: 0.042\n",
      "Loss after mini-batch    23: 0.072\n",
      "Loss after mini-batch    24: 0.038\n",
      "Loss after mini-batch    25: 0.127\n",
      "Loss after mini-batch    26: 0.001\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.146\n",
      "Loss after mini-batch     2: 0.063\n",
      "Loss after mini-batch     3: 0.180\n",
      "Loss after mini-batch     4: 0.035\n",
      "Loss after mini-batch     5: 0.024\n",
      "Loss after mini-batch     6: 0.145\n",
      "Loss after mini-batch     7: 0.060\n",
      "Loss after mini-batch     8: 0.029\n",
      "Loss after mini-batch     9: 0.094\n",
      "Loss after mini-batch    10: 0.060\n",
      "Loss after mini-batch    11: 0.015\n",
      "Loss after mini-batch    12: 0.013\n",
      "Loss after mini-batch    13: 0.076\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.013\n",
      "Loss after mini-batch    16: 0.134\n",
      "Loss after mini-batch    17: 0.078\n",
      "Loss after mini-batch    18: 0.076\n",
      "Loss after mini-batch    19: 0.068\n",
      "Loss after mini-batch    20: 0.086\n",
      "Loss after mini-batch    21: 0.021\n",
      "Loss after mini-batch    22: 0.104\n",
      "Loss after mini-batch    23: 0.032\n",
      "Loss after mini-batch    24: 0.048\n",
      "Loss after mini-batch    25: 0.022\n",
      "Loss after mini-batch    26: 0.046\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.027\n",
      "Loss after mini-batch     2: 0.021\n",
      "Loss after mini-batch     3: 0.029\n",
      "Loss after mini-batch     4: 0.021\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.041\n",
      "Loss after mini-batch     7: 0.147\n",
      "Loss after mini-batch     8: 0.042\n",
      "Loss after mini-batch     9: 0.086\n",
      "Loss after mini-batch    10: 0.031\n",
      "Loss after mini-batch    11: 0.034\n",
      "Loss after mini-batch    12: 0.076\n",
      "Loss after mini-batch    13: 0.005\n",
      "Loss after mini-batch    14: 0.035\n",
      "Loss after mini-batch    15: 0.083\n",
      "Loss after mini-batch    16: 0.043\n",
      "Loss after mini-batch    17: 0.036\n",
      "Loss after mini-batch    18: 0.028\n",
      "Loss after mini-batch    19: 0.027\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.017\n",
      "Loss after mini-batch    22: 0.037\n",
      "Loss after mini-batch    23: 0.002\n",
      "Loss after mini-batch    24: 0.019\n",
      "Loss after mini-batch    25: 0.023\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 92 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.738\n",
      "Loss after mini-batch     2: 0.673\n",
      "Loss after mini-batch     3: 0.709\n",
      "Loss after mini-batch     4: 0.690\n",
      "Loss after mini-batch     5: 0.613\n",
      "Loss after mini-batch     6: 0.734\n",
      "Loss after mini-batch     7: 0.796\n",
      "Loss after mini-batch     8: 0.651\n",
      "Loss after mini-batch     9: 0.676\n",
      "Loss after mini-batch    10: 0.679\n",
      "Loss after mini-batch    11: 0.607\n",
      "Loss after mini-batch    12: 0.722\n",
      "Loss after mini-batch    13: 0.549\n",
      "Loss after mini-batch    14: 0.618\n",
      "Loss after mini-batch    15: 0.628\n",
      "Loss after mini-batch    16: 0.656\n",
      "Loss after mini-batch    17: 0.639\n",
      "Loss after mini-batch    18: 0.625\n",
      "Loss after mini-batch    19: 0.603\n",
      "Loss after mini-batch    20: 0.701\n",
      "Loss after mini-batch    21: 0.602\n",
      "Loss after mini-batch    22: 0.490\n",
      "Loss after mini-batch    23: 0.495\n",
      "Loss after mini-batch    24: 0.543\n",
      "Loss after mini-batch    25: 0.570\n",
      "Loss after mini-batch    26: 0.685\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.568\n",
      "Loss after mini-batch     2: 0.542\n",
      "Loss after mini-batch     3: 0.376\n",
      "Loss after mini-batch     4: 0.485\n",
      "Loss after mini-batch     5: 0.501\n",
      "Loss after mini-batch     6: 0.572\n",
      "Loss after mini-batch     7: 0.455\n",
      "Loss after mini-batch     8: 0.345\n",
      "Loss after mini-batch     9: 0.485\n",
      "Loss after mini-batch    10: 0.316\n",
      "Loss after mini-batch    11: 0.427\n",
      "Loss after mini-batch    12: 0.344\n",
      "Loss after mini-batch    13: 0.424\n",
      "Loss after mini-batch    14: 0.560\n",
      "Loss after mini-batch    15: 0.480\n",
      "Loss after mini-batch    16: 0.560\n",
      "Loss after mini-batch    17: 0.372\n",
      "Loss after mini-batch    18: 0.689\n",
      "Loss after mini-batch    19: 0.401\n",
      "Loss after mini-batch    20: 0.279\n",
      "Loss after mini-batch    21: 0.182\n",
      "Loss after mini-batch    22: 0.374\n",
      "Loss after mini-batch    23: 0.593\n",
      "Loss after mini-batch    24: 0.448\n",
      "Loss after mini-batch    25: 0.979\n",
      "Loss after mini-batch    26: 0.378\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.351\n",
      "Loss after mini-batch     2: 0.326\n",
      "Loss after mini-batch     3: 0.313\n",
      "Loss after mini-batch     4: 0.425\n",
      "Loss after mini-batch     5: 0.601\n",
      "Loss after mini-batch     6: 0.168\n",
      "Loss after mini-batch     7: 0.147\n",
      "Loss after mini-batch     8: 0.294\n",
      "Loss after mini-batch     9: 0.439\n",
      "Loss after mini-batch    10: 0.692\n",
      "Loss after mini-batch    11: 0.628\n",
      "Loss after mini-batch    12: 0.500\n",
      "Loss after mini-batch    13: 0.417\n",
      "Loss after mini-batch    14: 0.392\n",
      "Loss after mini-batch    15: 0.332\n",
      "Loss after mini-batch    16: 0.601\n",
      "Loss after mini-batch    17: 0.555\n",
      "Loss after mini-batch    18: 0.583\n",
      "Loss after mini-batch    19: 0.343\n",
      "Loss after mini-batch    20: 0.321\n",
      "Loss after mini-batch    21: 0.242\n",
      "Loss after mini-batch    22: 0.273\n",
      "Loss after mini-batch    23: 0.516\n",
      "Loss after mini-batch    24: 0.219\n",
      "Loss after mini-batch    25: 0.423\n",
      "Loss after mini-batch    26: 1.274\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.350\n",
      "Loss after mini-batch     2: 0.277\n",
      "Loss after mini-batch     3: 0.383\n",
      "Loss after mini-batch     4: 0.225\n",
      "Loss after mini-batch     5: 0.394\n",
      "Loss after mini-batch     6: 0.401\n",
      "Loss after mini-batch     7: 0.363\n",
      "Loss after mini-batch     8: 0.364\n",
      "Loss after mini-batch     9: 0.199\n",
      "Loss after mini-batch    10: 0.252\n",
      "Loss after mini-batch    11: 0.422\n",
      "Loss after mini-batch    12: 0.189\n",
      "Loss after mini-batch    13: 0.199\n",
      "Loss after mini-batch    14: 0.345\n",
      "Loss after mini-batch    15: 0.237\n",
      "Loss after mini-batch    16: 0.315\n",
      "Loss after mini-batch    17: 0.336\n",
      "Loss after mini-batch    18: 0.286\n",
      "Loss after mini-batch    19: 0.223\n",
      "Loss after mini-batch    20: 0.076\n",
      "Loss after mini-batch    21: 0.247\n",
      "Loss after mini-batch    22: 0.414\n",
      "Loss after mini-batch    23: 0.238\n",
      "Loss after mini-batch    24: 0.540\n",
      "Loss after mini-batch    25: 0.246\n",
      "Loss after mini-batch    26: 0.000\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.172\n",
      "Loss after mini-batch     2: 0.270\n",
      "Loss after mini-batch     3: 0.042\n",
      "Loss after mini-batch     4: 0.242\n",
      "Loss after mini-batch     5: 0.222\n",
      "Loss after mini-batch     6: 0.170\n",
      "Loss after mini-batch     7: 0.273\n",
      "Loss after mini-batch     8: 0.348\n",
      "Loss after mini-batch     9: 0.168\n",
      "Loss after mini-batch    10: 0.132\n",
      "Loss after mini-batch    11: 0.253\n",
      "Loss after mini-batch    12: 0.250\n",
      "Loss after mini-batch    13: 0.024\n",
      "Loss after mini-batch    14: 0.048\n",
      "Loss after mini-batch    15: 0.122\n",
      "Loss after mini-batch    16: 0.323\n",
      "Loss after mini-batch    17: 0.485\n",
      "Loss after mini-batch    18: 0.398\n",
      "Loss after mini-batch    19: 0.153\n",
      "Loss after mini-batch    20: 0.223\n",
      "Loss after mini-batch    21: 0.245\n",
      "Loss after mini-batch    22: 0.353\n",
      "Loss after mini-batch    23: 0.405\n",
      "Loss after mini-batch    24: 0.174\n",
      "Loss after mini-batch    25: 0.163\n",
      "Loss after mini-batch    26: 0.045\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.134\n",
      "Loss after mini-batch     2: 0.102\n",
      "Loss after mini-batch     3: 0.053\n",
      "Loss after mini-batch     4: 0.310\n",
      "Loss after mini-batch     5: 0.385\n",
      "Loss after mini-batch     6: 0.159\n",
      "Loss after mini-batch     7: 0.389\n",
      "Loss after mini-batch     8: 0.053\n",
      "Loss after mini-batch     9: 0.145\n",
      "Loss after mini-batch    10: 0.193\n",
      "Loss after mini-batch    11: 0.107\n",
      "Loss after mini-batch    12: 0.146\n",
      "Loss after mini-batch    13: 0.235\n",
      "Loss after mini-batch    14: 0.140\n",
      "Loss after mini-batch    15: 0.088\n",
      "Loss after mini-batch    16: 0.044\n",
      "Loss after mini-batch    17: 0.077\n",
      "Loss after mini-batch    18: 0.138\n",
      "Loss after mini-batch    19: 0.087\n",
      "Loss after mini-batch    20: 0.144\n",
      "Loss after mini-batch    21: 0.140\n",
      "Loss after mini-batch    22: 0.091\n",
      "Loss after mini-batch    23: 0.031\n",
      "Loss after mini-batch    24: 0.135\n",
      "Loss after mini-batch    25: 0.054\n",
      "Loss after mini-batch    26: 0.014\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.043\n",
      "Loss after mini-batch     2: 0.155\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.050\n",
      "Loss after mini-batch     5: 0.060\n",
      "Loss after mini-batch     6: 0.021\n",
      "Loss after mini-batch     7: 0.045\n",
      "Loss after mini-batch     8: 0.112\n",
      "Loss after mini-batch     9: 0.032\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.217\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.300\n",
      "Loss after mini-batch    14: 0.331\n",
      "Loss after mini-batch    15: 0.166\n",
      "Loss after mini-batch    16: 0.104\n",
      "Loss after mini-batch    17: 0.010\n",
      "Loss after mini-batch    18: 0.167\n",
      "Loss after mini-batch    19: 0.072\n",
      "Loss after mini-batch    20: 0.035\n",
      "Loss after mini-batch    21: 0.021\n",
      "Loss after mini-batch    22: 0.148\n",
      "Loss after mini-batch    23: 0.156\n",
      "Loss after mini-batch    24: 0.164\n",
      "Loss after mini-batch    25: 0.039\n",
      "Loss after mini-batch    26: 0.085\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.036\n",
      "Loss after mini-batch     2: 0.198\n",
      "Loss after mini-batch     3: 0.150\n",
      "Loss after mini-batch     4: 0.071\n",
      "Loss after mini-batch     5: 0.114\n",
      "Loss after mini-batch     6: 0.039\n",
      "Loss after mini-batch     7: 0.092\n",
      "Loss after mini-batch     8: 0.012\n",
      "Loss after mini-batch     9: 0.058\n",
      "Loss after mini-batch    10: 0.061\n",
      "Loss after mini-batch    11: 0.080\n",
      "Loss after mini-batch    12: 0.041\n",
      "Loss after mini-batch    13: 0.070\n",
      "Loss after mini-batch    14: 0.109\n",
      "Loss after mini-batch    15: 0.014\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.019\n",
      "Loss after mini-batch    18: 0.202\n",
      "Loss after mini-batch    19: 0.022\n",
      "Loss after mini-batch    20: 0.134\n",
      "Loss after mini-batch    21: 0.104\n",
      "Loss after mini-batch    22: 0.032\n",
      "Loss after mini-batch    23: 0.018\n",
      "Loss after mini-batch    24: 0.013\n",
      "Loss after mini-batch    25: 0.017\n",
      "Loss after mini-batch    26: 0.008\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.034\n",
      "Loss after mini-batch     3: 0.027\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.025\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.030\n",
      "Loss after mini-batch     9: 0.017\n",
      "Loss after mini-batch    10: 0.040\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.104\n",
      "Loss after mini-batch    13: 0.068\n",
      "Loss after mini-batch    14: 0.033\n",
      "Loss after mini-batch    15: 0.075\n",
      "Loss after mini-batch    16: 0.022\n",
      "Loss after mini-batch    17: 0.143\n",
      "Loss after mini-batch    18: 0.041\n",
      "Loss after mini-batch    19: 0.037\n",
      "Loss after mini-batch    20: 0.112\n",
      "Loss after mini-batch    21: 0.005\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.016\n",
      "Loss after mini-batch    24: 0.061\n",
      "Loss after mini-batch    25: 0.020\n",
      "Loss after mini-batch    26: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.031\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.123\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.046\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.015\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.013\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.057\n",
      "Loss after mini-batch    17: 0.035\n",
      "Loss after mini-batch    18: 0.021\n",
      "Loss after mini-batch    19: 0.012\n",
      "Loss after mini-batch    20: 0.090\n",
      "Loss after mini-batch    21: 0.006\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.001\n",
      "Loss after mini-batch    24: 0.009\n",
      "Loss after mini-batch    25: 0.057\n",
      "Loss after mini-batch    26: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 5: 89 %\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.677\n",
      "Loss after mini-batch     2: 1.585\n",
      "Loss after mini-batch     3: 0.751\n",
      "Loss after mini-batch     4: 0.807\n",
      "Loss after mini-batch     5: 0.695\n",
      "Loss after mini-batch     6: 0.723\n",
      "Loss after mini-batch     7: 0.786\n",
      "Loss after mini-batch     8: 0.640\n",
      "Loss after mini-batch     9: 0.681\n",
      "Loss after mini-batch    10: 0.691\n",
      "Loss after mini-batch    11: 0.691\n",
      "Loss after mini-batch    12: 0.677\n",
      "Loss after mini-batch    13: 0.664\n",
      "Loss after mini-batch    14: 0.685\n",
      "Loss after mini-batch    15: 0.661\n",
      "Loss after mini-batch    16: 0.705\n",
      "Loss after mini-batch    17: 0.782\n",
      "Loss after mini-batch    18: 0.673\n",
      "Loss after mini-batch    19: 0.659\n",
      "Loss after mini-batch    20: 0.666\n",
      "Loss after mini-batch    21: 0.708\n",
      "Loss after mini-batch    22: 0.656\n",
      "Loss after mini-batch    23: 0.640\n",
      "Loss after mini-batch    24: 0.655\n",
      "Loss after mini-batch    25: 0.685\n",
      "Loss after mini-batch    26: 0.604\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.668\n",
      "Loss after mini-batch     2: 0.632\n",
      "Loss after mini-batch     3: 0.638\n",
      "Loss after mini-batch     4: 0.666\n",
      "Loss after mini-batch     5: 0.608\n",
      "Loss after mini-batch     6: 0.594\n",
      "Loss after mini-batch     7: 0.540\n",
      "Loss after mini-batch     8: 0.564\n",
      "Loss after mini-batch     9: 0.591\n",
      "Loss after mini-batch    10: 0.613\n",
      "Loss after mini-batch    11: 0.562\n",
      "Loss after mini-batch    12: 0.540\n",
      "Loss after mini-batch    13: 0.603\n",
      "Loss after mini-batch    14: 0.493\n",
      "Loss after mini-batch    15: 0.628\n",
      "Loss after mini-batch    16: 0.555\n",
      "Loss after mini-batch    17: 0.511\n",
      "Loss after mini-batch    18: 0.551\n",
      "Loss after mini-batch    19: 0.569\n",
      "Loss after mini-batch    20: 0.453\n",
      "Loss after mini-batch    21: 0.629\n",
      "Loss after mini-batch    22: 0.524\n",
      "Loss after mini-batch    23: 0.527\n",
      "Loss after mini-batch    24: 0.529\n",
      "Loss after mini-batch    25: 0.477\n",
      "Loss after mini-batch    26: 0.523\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.535\n",
      "Loss after mini-batch     2: 0.493\n",
      "Loss after mini-batch     3: 0.575\n",
      "Loss after mini-batch     4: 0.606\n",
      "Loss after mini-batch     5: 0.501\n",
      "Loss after mini-batch     6: 0.677\n",
      "Loss after mini-batch     7: 0.425\n",
      "Loss after mini-batch     8: 0.368\n",
      "Loss after mini-batch     9: 0.402\n",
      "Loss after mini-batch    10: 0.264\n",
      "Loss after mini-batch    11: 0.608\n",
      "Loss after mini-batch    12: 0.434\n",
      "Loss after mini-batch    13: 0.331\n",
      "Loss after mini-batch    14: 0.372\n",
      "Loss after mini-batch    15: 0.288\n",
      "Loss after mini-batch    16: 0.216\n",
      "Loss after mini-batch    17: 0.412\n",
      "Loss after mini-batch    18: 0.172\n",
      "Loss after mini-batch    19: 0.349\n",
      "Loss after mini-batch    20: 0.387\n",
      "Loss after mini-batch    21: 0.521\n",
      "Loss after mini-batch    22: 0.336\n",
      "Loss after mini-batch    23: 0.555\n",
      "Loss after mini-batch    24: 0.195\n",
      "Loss after mini-batch    25: 0.307\n",
      "Loss after mini-batch    26: 0.354\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.667\n",
      "Loss after mini-batch     2: 0.396\n",
      "Loss after mini-batch     3: 0.338\n",
      "Loss after mini-batch     4: 0.146\n",
      "Loss after mini-batch     5: 0.476\n",
      "Loss after mini-batch     6: 0.415\n",
      "Loss after mini-batch     7: 0.309\n",
      "Loss after mini-batch     8: 0.471\n",
      "Loss after mini-batch     9: 0.288\n",
      "Loss after mini-batch    10: 0.533\n",
      "Loss after mini-batch    11: 0.209\n",
      "Loss after mini-batch    12: 0.363\n",
      "Loss after mini-batch    13: 0.246\n",
      "Loss after mini-batch    14: 0.246\n",
      "Loss after mini-batch    15: 0.405\n",
      "Loss after mini-batch    16: 0.301\n",
      "Loss after mini-batch    17: 0.274\n",
      "Loss after mini-batch    18: 0.208\n",
      "Loss after mini-batch    19: 0.430\n",
      "Loss after mini-batch    20: 0.513\n",
      "Loss after mini-batch    21: 0.321\n",
      "Loss after mini-batch    22: 0.369\n",
      "Loss after mini-batch    23: 0.293\n",
      "Loss after mini-batch    24: 0.298\n",
      "Loss after mini-batch    25: 0.357\n",
      "Loss after mini-batch    26: 0.121\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.346\n",
      "Loss after mini-batch     2: 0.022\n",
      "Loss after mini-batch     3: 0.411\n",
      "Loss after mini-batch     4: 0.374\n",
      "Loss after mini-batch     5: 0.281\n",
      "Loss after mini-batch     6: 0.568\n",
      "Loss after mini-batch     7: 0.458\n",
      "Loss after mini-batch     8: 0.237\n",
      "Loss after mini-batch     9: 0.168\n",
      "Loss after mini-batch    10: 0.099\n",
      "Loss after mini-batch    11: 0.545\n",
      "Loss after mini-batch    12: 0.148\n",
      "Loss after mini-batch    13: 0.289\n",
      "Loss after mini-batch    14: 0.574\n",
      "Loss after mini-batch    15: 0.575\n",
      "Loss after mini-batch    16: 0.423\n",
      "Loss after mini-batch    17: 0.182\n",
      "Loss after mini-batch    18: 0.218\n",
      "Loss after mini-batch    19: 0.091\n",
      "Loss after mini-batch    20: 0.109\n",
      "Loss after mini-batch    21: 0.293\n",
      "Loss after mini-batch    22: 0.320\n",
      "Loss after mini-batch    23: 0.267\n",
      "Loss after mini-batch    24: 0.385\n",
      "Loss after mini-batch    25: 0.436\n",
      "Loss after mini-batch    26: 0.022\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.201\n",
      "Loss after mini-batch     2: 0.133\n",
      "Loss after mini-batch     3: 0.280\n",
      "Loss after mini-batch     4: 0.417\n",
      "Loss after mini-batch     5: 0.188\n",
      "Loss after mini-batch     6: 0.226\n",
      "Loss after mini-batch     7: 0.215\n",
      "Loss after mini-batch     8: 0.205\n",
      "Loss after mini-batch     9: 0.290\n",
      "Loss after mini-batch    10: 0.200\n",
      "Loss after mini-batch    11: 0.159\n",
      "Loss after mini-batch    12: 0.233\n",
      "Loss after mini-batch    13: 0.057\n",
      "Loss after mini-batch    14: 0.148\n",
      "Loss after mini-batch    15: 0.311\n",
      "Loss after mini-batch    16: 0.293\n",
      "Loss after mini-batch    17: 0.313\n",
      "Loss after mini-batch    18: 0.292\n",
      "Loss after mini-batch    19: 0.407\n",
      "Loss after mini-batch    20: 0.231\n",
      "Loss after mini-batch    21: 0.143\n",
      "Loss after mini-batch    22: 0.215\n",
      "Loss after mini-batch    23: 0.053\n",
      "Loss after mini-batch    24: 0.050\n",
      "Loss after mini-batch    25: 0.088\n",
      "Loss after mini-batch    26: 0.654\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.239\n",
      "Loss after mini-batch     2: 0.206\n",
      "Loss after mini-batch     3: 0.096\n",
      "Loss after mini-batch     4: 0.052\n",
      "Loss after mini-batch     5: 0.223\n",
      "Loss after mini-batch     6: 0.182\n",
      "Loss after mini-batch     7: 0.142\n",
      "Loss after mini-batch     8: 0.109\n",
      "Loss after mini-batch     9: 0.096\n",
      "Loss after mini-batch    10: 0.218\n",
      "Loss after mini-batch    11: 0.030\n",
      "Loss after mini-batch    12: 0.042\n",
      "Loss after mini-batch    13: 0.376\n",
      "Loss after mini-batch    14: 0.164\n",
      "Loss after mini-batch    15: 0.008\n",
      "Loss after mini-batch    16: 0.107\n",
      "Loss after mini-batch    17: 0.135\n",
      "Loss after mini-batch    18: 0.051\n",
      "Loss after mini-batch    19: 0.088\n",
      "Loss after mini-batch    20: 0.106\n",
      "Loss after mini-batch    21: 0.479\n",
      "Loss after mini-batch    22: 0.105\n",
      "Loss after mini-batch    23: 0.245\n",
      "Loss after mini-batch    24: 0.047\n",
      "Loss after mini-batch    25: 0.134\n",
      "Loss after mini-batch    26: 0.319\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.027\n",
      "Loss after mini-batch     2: 0.053\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.071\n",
      "Loss after mini-batch     5: 0.156\n",
      "Loss after mini-batch     6: 0.355\n",
      "Loss after mini-batch     7: 0.053\n",
      "Loss after mini-batch     8: 0.061\n",
      "Loss after mini-batch     9: 0.089\n",
      "Loss after mini-batch    10: 0.065\n",
      "Loss after mini-batch    11: 0.221\n",
      "Loss after mini-batch    12: 0.022\n",
      "Loss after mini-batch    13: 0.045\n",
      "Loss after mini-batch    14: 0.075\n",
      "Loss after mini-batch    15: 0.175\n",
      "Loss after mini-batch    16: 0.207\n",
      "Loss after mini-batch    17: 0.088\n",
      "Loss after mini-batch    18: 0.042\n",
      "Loss after mini-batch    19: 0.032\n",
      "Loss after mini-batch    20: 0.135\n",
      "Loss after mini-batch    21: 0.078\n",
      "Loss after mini-batch    22: 0.078\n",
      "Loss after mini-batch    23: 0.034\n",
      "Loss after mini-batch    24: 0.041\n",
      "Loss after mini-batch    25: 0.035\n",
      "Loss after mini-batch    26: 0.006\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.028\n",
      "Loss after mini-batch     2: 0.032\n",
      "Loss after mini-batch     3: 0.070\n",
      "Loss after mini-batch     4: 0.101\n",
      "Loss after mini-batch     5: 0.009\n",
      "Loss after mini-batch     6: 0.018\n",
      "Loss after mini-batch     7: 0.017\n",
      "Loss after mini-batch     8: 0.044\n",
      "Loss after mini-batch     9: 0.019\n",
      "Loss after mini-batch    10: 0.080\n",
      "Loss after mini-batch    11: 0.034\n",
      "Loss after mini-batch    12: 0.163\n",
      "Loss after mini-batch    13: 0.110\n",
      "Loss after mini-batch    14: 0.006\n",
      "Loss after mini-batch    15: 0.030\n",
      "Loss after mini-batch    16: 0.062\n",
      "Loss after mini-batch    17: 0.084\n",
      "Loss after mini-batch    18: 0.060\n",
      "Loss after mini-batch    19: 0.012\n",
      "Loss after mini-batch    20: 0.031\n",
      "Loss after mini-batch    21: 0.022\n",
      "Loss after mini-batch    22: 0.103\n",
      "Loss after mini-batch    23: 0.034\n",
      "Loss after mini-batch    24: 0.009\n",
      "Loss after mini-batch    25: 0.027\n",
      "Loss after mini-batch    26: 0.004\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.028\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.037\n",
      "Loss after mini-batch     6: 0.106\n",
      "Loss after mini-batch     7: 0.013\n",
      "Loss after mini-batch     8: 0.015\n",
      "Loss after mini-batch     9: 0.023\n",
      "Loss after mini-batch    10: 0.060\n",
      "Loss after mini-batch    11: 0.065\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.114\n",
      "Loss after mini-batch    14: 0.013\n",
      "Loss after mini-batch    15: 0.033\n",
      "Loss after mini-batch    16: 0.009\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.019\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.018\n",
      "Loss after mini-batch    21: 0.032\n",
      "Loss after mini-batch    22: 0.031\n",
      "Loss after mini-batch    23: 0.014\n",
      "Loss after mini-batch    24: 0.001\n",
      "Loss after mini-batch    25: 0.021\n",
      "Loss after mini-batch    26: 0.003\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 6: 92 %\n",
      "--------------------------------\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.738\n",
      "Loss after mini-batch     2: 1.187\n",
      "Loss after mini-batch     3: 0.689\n",
      "Loss after mini-batch     4: 1.047\n",
      "Loss after mini-batch     5: 0.877\n",
      "Loss after mini-batch     6: 0.799\n",
      "Loss after mini-batch     7: 0.701\n",
      "Loss after mini-batch     8: 0.951\n",
      "Loss after mini-batch     9: 1.058\n",
      "Loss after mini-batch    10: 0.686\n",
      "Loss after mini-batch    11: 0.703\n",
      "Loss after mini-batch    12: 0.519\n",
      "Loss after mini-batch    13: 1.011\n",
      "Loss after mini-batch    14: 0.849\n",
      "Loss after mini-batch    15: 0.848\n",
      "Loss after mini-batch    16: 0.705\n",
      "Loss after mini-batch    17: 0.658\n",
      "Loss after mini-batch    18: 0.695\n",
      "Loss after mini-batch    19: 0.657\n",
      "Loss after mini-batch    20: 0.609\n",
      "Loss after mini-batch    21: 0.610\n",
      "Loss after mini-batch    22: 0.762\n",
      "Loss after mini-batch    23: 0.593\n",
      "Loss after mini-batch    24: 0.550\n",
      "Loss after mini-batch    25: 0.669\n",
      "Loss after mini-batch    26: 0.660\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.535\n",
      "Loss after mini-batch     2: 0.636\n",
      "Loss after mini-batch     3: 0.656\n",
      "Loss after mini-batch     4: 0.474\n",
      "Loss after mini-batch     5: 0.482\n",
      "Loss after mini-batch     6: 0.738\n",
      "Loss after mini-batch     7: 0.496\n",
      "Loss after mini-batch     8: 0.491\n",
      "Loss after mini-batch     9: 0.522\n",
      "Loss after mini-batch    10: 0.539\n",
      "Loss after mini-batch    11: 0.413\n",
      "Loss after mini-batch    12: 0.465\n",
      "Loss after mini-batch    13: 0.497\n",
      "Loss after mini-batch    14: 0.455\n",
      "Loss after mini-batch    15: 0.478\n",
      "Loss after mini-batch    16: 0.436\n",
      "Loss after mini-batch    17: 0.398\n",
      "Loss after mini-batch    18: 0.223\n",
      "Loss after mini-batch    19: 0.504\n",
      "Loss after mini-batch    20: 0.312\n",
      "Loss after mini-batch    21: 0.431\n",
      "Loss after mini-batch    22: 0.750\n",
      "Loss after mini-batch    23: 0.391\n",
      "Loss after mini-batch    24: 0.548\n",
      "Loss after mini-batch    25: 0.563\n",
      "Loss after mini-batch    26: 1.117\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.314\n",
      "Loss after mini-batch     2: 0.390\n",
      "Loss after mini-batch     3: 0.775\n",
      "Loss after mini-batch     4: 0.269\n",
      "Loss after mini-batch     5: 0.422\n",
      "Loss after mini-batch     6: 0.378\n",
      "Loss after mini-batch     7: 0.397\n",
      "Loss after mini-batch     8: 0.254\n",
      "Loss after mini-batch     9: 0.301\n",
      "Loss after mini-batch    10: 0.195\n",
      "Loss after mini-batch    11: 0.500\n",
      "Loss after mini-batch    12: 0.456\n",
      "Loss after mini-batch    13: 0.624\n",
      "Loss after mini-batch    14: 0.515\n",
      "Loss after mini-batch    15: 0.229\n",
      "Loss after mini-batch    16: 0.358\n",
      "Loss after mini-batch    17: 0.357\n",
      "Loss after mini-batch    18: 0.351\n",
      "Loss after mini-batch    19: 0.173\n",
      "Loss after mini-batch    20: 0.340\n",
      "Loss after mini-batch    21: 0.560\n",
      "Loss after mini-batch    22: 0.412\n",
      "Loss after mini-batch    23: 0.304\n",
      "Loss after mini-batch    24: 0.142\n",
      "Loss after mini-batch    25: 0.325\n",
      "Loss after mini-batch    26: 0.556\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.171\n",
      "Loss after mini-batch     2: 0.308\n",
      "Loss after mini-batch     3: 0.109\n",
      "Loss after mini-batch     4: 0.470\n",
      "Loss after mini-batch     5: 0.317\n",
      "Loss after mini-batch     6: 0.082\n",
      "Loss after mini-batch     7: 0.271\n",
      "Loss after mini-batch     8: 0.379\n",
      "Loss after mini-batch     9: 0.145\n",
      "Loss after mini-batch    10: 0.236\n",
      "Loss after mini-batch    11: 0.158\n",
      "Loss after mini-batch    12: 0.524\n",
      "Loss after mini-batch    13: 0.545\n",
      "Loss after mini-batch    14: 0.194\n",
      "Loss after mini-batch    15: 0.231\n",
      "Loss after mini-batch    16: 0.291\n",
      "Loss after mini-batch    17: 0.128\n",
      "Loss after mini-batch    18: 0.448\n",
      "Loss after mini-batch    19: 0.578\n",
      "Loss after mini-batch    20: 0.634\n",
      "Loss after mini-batch    21: 0.486\n",
      "Loss after mini-batch    22: 0.154\n",
      "Loss after mini-batch    23: 0.147\n",
      "Loss after mini-batch    24: 0.218\n",
      "Loss after mini-batch    25: 0.332\n",
      "Loss after mini-batch    26: 0.086\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.345\n",
      "Loss after mini-batch     2: 0.140\n",
      "Loss after mini-batch     3: 0.309\n",
      "Loss after mini-batch     4: 0.124\n",
      "Loss after mini-batch     5: 0.269\n",
      "Loss after mini-batch     6: 0.318\n",
      "Loss after mini-batch     7: 0.440\n",
      "Loss after mini-batch     8: 0.336\n",
      "Loss after mini-batch     9: 0.204\n",
      "Loss after mini-batch    10: 0.210\n",
      "Loss after mini-batch    11: 0.377\n",
      "Loss after mini-batch    12: 0.110\n",
      "Loss after mini-batch    13: 0.222\n",
      "Loss after mini-batch    14: 0.395\n",
      "Loss after mini-batch    15: 0.072\n",
      "Loss after mini-batch    16: 0.378\n",
      "Loss after mini-batch    17: 0.295\n",
      "Loss after mini-batch    18: 0.037\n",
      "Loss after mini-batch    19: 0.300\n",
      "Loss after mini-batch    20: 0.068\n",
      "Loss after mini-batch    21: 0.204\n",
      "Loss after mini-batch    22: 0.157\n",
      "Loss after mini-batch    23: 0.124\n",
      "Loss after mini-batch    24: 0.083\n",
      "Loss after mini-batch    25: 0.249\n",
      "Loss after mini-batch    26: 0.134\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.323\n",
      "Loss after mini-batch     2: 0.159\n",
      "Loss after mini-batch     3: 0.168\n",
      "Loss after mini-batch     4: 0.208\n",
      "Loss after mini-batch     5: 0.265\n",
      "Loss after mini-batch     6: 0.100\n",
      "Loss after mini-batch     7: 0.210\n",
      "Loss after mini-batch     8: 0.101\n",
      "Loss after mini-batch     9: 0.093\n",
      "Loss after mini-batch    10: 0.057\n",
      "Loss after mini-batch    11: 0.096\n",
      "Loss after mini-batch    12: 0.053\n",
      "Loss after mini-batch    13: 0.184\n",
      "Loss after mini-batch    14: 0.074\n",
      "Loss after mini-batch    15: 0.214\n",
      "Loss after mini-batch    16: 0.482\n",
      "Loss after mini-batch    17: 0.044\n",
      "Loss after mini-batch    18: 0.253\n",
      "Loss after mini-batch    19: 0.227\n",
      "Loss after mini-batch    20: 0.078\n",
      "Loss after mini-batch    21: 0.127\n",
      "Loss after mini-batch    22: 0.157\n",
      "Loss after mini-batch    23: 0.177\n",
      "Loss after mini-batch    24: 0.126\n",
      "Loss after mini-batch    25: 0.105\n",
      "Loss after mini-batch    26: 0.895\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.130\n",
      "Loss after mini-batch     2: 0.158\n",
      "Loss after mini-batch     3: 0.125\n",
      "Loss after mini-batch     4: 0.037\n",
      "Loss after mini-batch     5: 0.209\n",
      "Loss after mini-batch     6: 0.046\n",
      "Loss after mini-batch     7: 0.171\n",
      "Loss after mini-batch     8: 0.083\n",
      "Loss after mini-batch     9: 0.319\n",
      "Loss after mini-batch    10: 0.273\n",
      "Loss after mini-batch    11: 0.151\n",
      "Loss after mini-batch    12: 0.100\n",
      "Loss after mini-batch    13: 0.172\n",
      "Loss after mini-batch    14: 0.098\n",
      "Loss after mini-batch    15: 0.115\n",
      "Loss after mini-batch    16: 0.247\n",
      "Loss after mini-batch    17: 0.106\n",
      "Loss after mini-batch    18: 0.071\n",
      "Loss after mini-batch    19: 0.167\n",
      "Loss after mini-batch    20: 0.090\n",
      "Loss after mini-batch    21: 0.192\n",
      "Loss after mini-batch    22: 0.145\n",
      "Loss after mini-batch    23: 0.073\n",
      "Loss after mini-batch    24: 0.182\n",
      "Loss after mini-batch    25: 0.218\n",
      "Loss after mini-batch    26: 0.002\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.065\n",
      "Loss after mini-batch     2: 0.071\n",
      "Loss after mini-batch     3: 0.113\n",
      "Loss after mini-batch     4: 0.093\n",
      "Loss after mini-batch     5: 0.037\n",
      "Loss after mini-batch     6: 0.174\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.078\n",
      "Loss after mini-batch     9: 0.110\n",
      "Loss after mini-batch    10: 0.088\n",
      "Loss after mini-batch    11: 0.090\n",
      "Loss after mini-batch    12: 0.029\n",
      "Loss after mini-batch    13: 0.143\n",
      "Loss after mini-batch    14: 0.054\n",
      "Loss after mini-batch    15: 0.177\n",
      "Loss after mini-batch    16: 0.034\n",
      "Loss after mini-batch    17: 0.091\n",
      "Loss after mini-batch    18: 0.022\n",
      "Loss after mini-batch    19: 0.012\n",
      "Loss after mini-batch    20: 0.115\n",
      "Loss after mini-batch    21: 0.063\n",
      "Loss after mini-batch    22: 0.042\n",
      "Loss after mini-batch    23: 0.102\n",
      "Loss after mini-batch    24: 0.161\n",
      "Loss after mini-batch    25: 0.066\n",
      "Loss after mini-batch    26: 0.001\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.030\n",
      "Loss after mini-batch     2: 0.044\n",
      "Loss after mini-batch     3: 0.036\n",
      "Loss after mini-batch     4: 0.058\n",
      "Loss after mini-batch     5: 0.028\n",
      "Loss after mini-batch     6: 0.081\n",
      "Loss after mini-batch     7: 0.031\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.028\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.082\n",
      "Loss after mini-batch    13: 0.052\n",
      "Loss after mini-batch    14: 0.009\n",
      "Loss after mini-batch    15: 0.042\n",
      "Loss after mini-batch    16: 0.047\n",
      "Loss after mini-batch    17: 0.002\n",
      "Loss after mini-batch    18: 0.018\n",
      "Loss after mini-batch    19: 0.030\n",
      "Loss after mini-batch    20: 0.053\n",
      "Loss after mini-batch    21: 0.089\n",
      "Loss after mini-batch    22: 0.127\n",
      "Loss after mini-batch    23: 0.067\n",
      "Loss after mini-batch    24: 0.003\n",
      "Loss after mini-batch    25: 0.055\n",
      "Loss after mini-batch    26: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.039\n",
      "Loss after mini-batch     4: 0.019\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.024\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.038\n",
      "Loss after mini-batch     9: 0.012\n",
      "Loss after mini-batch    10: 0.056\n",
      "Loss after mini-batch    11: 0.079\n",
      "Loss after mini-batch    12: 0.020\n",
      "Loss after mini-batch    13: 0.031\n",
      "Loss after mini-batch    14: 0.028\n",
      "Loss after mini-batch    15: 0.013\n",
      "Loss after mini-batch    16: 0.018\n",
      "Loss after mini-batch    17: 0.028\n",
      "Loss after mini-batch    18: 0.003\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.018\n",
      "Loss after mini-batch    23: 0.018\n",
      "Loss after mini-batch    24: 0.027\n",
      "Loss after mini-batch    25: 0.095\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 7: 75 %\n",
      "--------------------------------\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.861\n",
      "Loss after mini-batch     2: 0.740\n",
      "Loss after mini-batch     3: 0.666\n",
      "Loss after mini-batch     4: 1.064\n",
      "Loss after mini-batch     5: 0.605\n",
      "Loss after mini-batch     6: 0.916\n",
      "Loss after mini-batch     7: 1.069\n",
      "Loss after mini-batch     8: 1.041\n",
      "Loss after mini-batch     9: 0.858\n",
      "Loss after mini-batch    10: 0.622\n",
      "Loss after mini-batch    11: 0.685\n",
      "Loss after mini-batch    12: 0.522\n",
      "Loss after mini-batch    13: 0.822\n",
      "Loss after mini-batch    14: 0.651\n",
      "Loss after mini-batch    15: 0.883\n",
      "Loss after mini-batch    16: 0.858\n",
      "Loss after mini-batch    17: 0.606\n",
      "Loss after mini-batch    18: 0.583\n",
      "Loss after mini-batch    19: 0.590\n",
      "Loss after mini-batch    20: 0.514\n",
      "Loss after mini-batch    21: 0.552\n",
      "Loss after mini-batch    22: 0.612\n",
      "Loss after mini-batch    23: 0.730\n",
      "Loss after mini-batch    24: 0.669\n",
      "Loss after mini-batch    25: 0.560\n",
      "Loss after mini-batch    26: 1.065\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.421\n",
      "Loss after mini-batch     2: 0.610\n",
      "Loss after mini-batch     3: 0.464\n",
      "Loss after mini-batch     4: 0.531\n",
      "Loss after mini-batch     5: 0.602\n",
      "Loss after mini-batch     6: 0.445\n",
      "Loss after mini-batch     7: 0.555\n",
      "Loss after mini-batch     8: 0.458\n",
      "Loss after mini-batch     9: 0.432\n",
      "Loss after mini-batch    10: 0.370\n",
      "Loss after mini-batch    11: 0.307\n",
      "Loss after mini-batch    12: 0.602\n",
      "Loss after mini-batch    13: 0.489\n",
      "Loss after mini-batch    14: 0.218\n",
      "Loss after mini-batch    15: 0.534\n",
      "Loss after mini-batch    16: 0.245\n",
      "Loss after mini-batch    17: 0.345\n",
      "Loss after mini-batch    18: 0.522\n",
      "Loss after mini-batch    19: 0.355\n",
      "Loss after mini-batch    20: 0.335\n",
      "Loss after mini-batch    21: 0.483\n",
      "Loss after mini-batch    22: 0.303\n",
      "Loss after mini-batch    23: 0.351\n",
      "Loss after mini-batch    24: 0.541\n",
      "Loss after mini-batch    25: 0.515\n",
      "Loss after mini-batch    26: 0.100\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.241\n",
      "Loss after mini-batch     2: 0.453\n",
      "Loss after mini-batch     3: 0.407\n",
      "Loss after mini-batch     4: 0.371\n",
      "Loss after mini-batch     5: 0.365\n",
      "Loss after mini-batch     6: 0.365\n",
      "Loss after mini-batch     7: 0.186\n",
      "Loss after mini-batch     8: 0.266\n",
      "Loss after mini-batch     9: 0.331\n",
      "Loss after mini-batch    10: 0.355\n",
      "Loss after mini-batch    11: 0.140\n",
      "Loss after mini-batch    12: 0.300\n",
      "Loss after mini-batch    13: 0.239\n",
      "Loss after mini-batch    14: 0.206\n",
      "Loss after mini-batch    15: 0.407\n",
      "Loss after mini-batch    16: 0.329\n",
      "Loss after mini-batch    17: 0.324\n",
      "Loss after mini-batch    18: 0.281\n",
      "Loss after mini-batch    19: 0.473\n",
      "Loss after mini-batch    20: 0.091\n",
      "Loss after mini-batch    21: 0.335\n",
      "Loss after mini-batch    22: 0.296\n",
      "Loss after mini-batch    23: 0.446\n",
      "Loss after mini-batch    24: 0.489\n",
      "Loss after mini-batch    25: 0.577\n",
      "Loss after mini-batch    26: 0.253\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.318\n",
      "Loss after mini-batch     2: 0.399\n",
      "Loss after mini-batch     3: 0.286\n",
      "Loss after mini-batch     4: 0.131\n",
      "Loss after mini-batch     5: 0.268\n",
      "Loss after mini-batch     6: 0.212\n",
      "Loss after mini-batch     7: 0.173\n",
      "Loss after mini-batch     8: 0.113\n",
      "Loss after mini-batch     9: 0.172\n",
      "Loss after mini-batch    10: 0.363\n",
      "Loss after mini-batch    11: 0.371\n",
      "Loss after mini-batch    12: 0.214\n",
      "Loss after mini-batch    13: 0.415\n",
      "Loss after mini-batch    14: 0.114\n",
      "Loss after mini-batch    15: 0.330\n",
      "Loss after mini-batch    16: 0.301\n",
      "Loss after mini-batch    17: 0.257\n",
      "Loss after mini-batch    18: 0.174\n",
      "Loss after mini-batch    19: 0.086\n",
      "Loss after mini-batch    20: 0.327\n",
      "Loss after mini-batch    21: 0.170\n",
      "Loss after mini-batch    22: 0.278\n",
      "Loss after mini-batch    23: 0.199\n",
      "Loss after mini-batch    24: 0.372\n",
      "Loss after mini-batch    25: 0.248\n",
      "Loss after mini-batch    26: 0.071\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.043\n",
      "Loss after mini-batch     2: 0.150\n",
      "Loss after mini-batch     3: 0.142\n",
      "Loss after mini-batch     4: 0.157\n",
      "Loss after mini-batch     5: 0.240\n",
      "Loss after mini-batch     6: 0.244\n",
      "Loss after mini-batch     7: 0.072\n",
      "Loss after mini-batch     8: 0.095\n",
      "Loss after mini-batch     9: 0.105\n",
      "Loss after mini-batch    10: 0.040\n",
      "Loss after mini-batch    11: 0.296\n",
      "Loss after mini-batch    12: 0.188\n",
      "Loss after mini-batch    13: 0.245\n",
      "Loss after mini-batch    14: 0.155\n",
      "Loss after mini-batch    15: 0.202\n",
      "Loss after mini-batch    16: 0.272\n",
      "Loss after mini-batch    17: 0.171\n",
      "Loss after mini-batch    18: 0.422\n",
      "Loss after mini-batch    19: 0.143\n",
      "Loss after mini-batch    20: 0.112\n",
      "Loss after mini-batch    21: 0.198\n",
      "Loss after mini-batch    22: 0.400\n",
      "Loss after mini-batch    23: 0.138\n",
      "Loss after mini-batch    24: 0.110\n",
      "Loss after mini-batch    25: 0.123\n",
      "Loss after mini-batch    26: 0.073\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.119\n",
      "Loss after mini-batch     2: 0.188\n",
      "Loss after mini-batch     3: 0.041\n",
      "Loss after mini-batch     4: 0.124\n",
      "Loss after mini-batch     5: 0.154\n",
      "Loss after mini-batch     6: 0.174\n",
      "Loss after mini-batch     7: 0.285\n",
      "Loss after mini-batch     8: 0.220\n",
      "Loss after mini-batch     9: 0.025\n",
      "Loss after mini-batch    10: 0.218\n",
      "Loss after mini-batch    11: 0.261\n",
      "Loss after mini-batch    12: 0.069\n",
      "Loss after mini-batch    13: 0.029\n",
      "Loss after mini-batch    14: 0.039\n",
      "Loss after mini-batch    15: 0.437\n",
      "Loss after mini-batch    16: 0.056\n",
      "Loss after mini-batch    17: 0.184\n",
      "Loss after mini-batch    18: 0.072\n",
      "Loss after mini-batch    19: 0.141\n",
      "Loss after mini-batch    20: 0.361\n",
      "Loss after mini-batch    21: 0.190\n",
      "Loss after mini-batch    22: 0.046\n",
      "Loss after mini-batch    23: 0.017\n",
      "Loss after mini-batch    24: 0.105\n",
      "Loss after mini-batch    25: 0.106\n",
      "Loss after mini-batch    26: 0.034\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.157\n",
      "Loss after mini-batch     2: 0.175\n",
      "Loss after mini-batch     3: 0.036\n",
      "Loss after mini-batch     4: 0.195\n",
      "Loss after mini-batch     5: 0.294\n",
      "Loss after mini-batch     6: 0.061\n",
      "Loss after mini-batch     7: 0.129\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.022\n",
      "Loss after mini-batch    11: 0.025\n",
      "Loss after mini-batch    12: 0.080\n",
      "Loss after mini-batch    13: 0.064\n",
      "Loss after mini-batch    14: 0.323\n",
      "Loss after mini-batch    15: 0.123\n",
      "Loss after mini-batch    16: 0.078\n",
      "Loss after mini-batch    17: 0.097\n",
      "Loss after mini-batch    18: 0.113\n",
      "Loss after mini-batch    19: 0.070\n",
      "Loss after mini-batch    20: 0.045\n",
      "Loss after mini-batch    21: 0.060\n",
      "Loss after mini-batch    22: 0.090\n",
      "Loss after mini-batch    23: 0.087\n",
      "Loss after mini-batch    24: 0.022\n",
      "Loss after mini-batch    25: 0.046\n",
      "Loss after mini-batch    26: 0.015\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.050\n",
      "Loss after mini-batch     2: 0.095\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.276\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.034\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.027\n",
      "Loss after mini-batch    10: 0.172\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.022\n",
      "Loss after mini-batch    13: 0.071\n",
      "Loss after mini-batch    14: 0.032\n",
      "Loss after mini-batch    15: 0.105\n",
      "Loss after mini-batch    16: 0.067\n",
      "Loss after mini-batch    17: 0.017\n",
      "Loss after mini-batch    18: 0.039\n",
      "Loss after mini-batch    19: 0.085\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.028\n",
      "Loss after mini-batch    22: 0.108\n",
      "Loss after mini-batch    23: 0.004\n",
      "Loss after mini-batch    24: 0.006\n",
      "Loss after mini-batch    25: 0.001\n",
      "Loss after mini-batch    26: 0.011\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.129\n",
      "Loss after mini-batch     4: 0.018\n",
      "Loss after mini-batch     5: 0.067\n",
      "Loss after mini-batch     6: 0.044\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.044\n",
      "Loss after mini-batch    12: 0.034\n",
      "Loss after mini-batch    13: 0.004\n",
      "Loss after mini-batch    14: 0.064\n",
      "Loss after mini-batch    15: 0.037\n",
      "Loss after mini-batch    16: 0.025\n",
      "Loss after mini-batch    17: 0.051\n",
      "Loss after mini-batch    18: 0.021\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.162\n",
      "Loss after mini-batch    23: 0.087\n",
      "Loss after mini-batch    24: 0.031\n",
      "Loss after mini-batch    25: 0.029\n",
      "Loss after mini-batch    26: 0.000\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.008\n",
      "Loss after mini-batch     2: 0.016\n",
      "Loss after mini-batch     3: 0.052\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.038\n",
      "Loss after mini-batch     9: 0.046\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.010\n",
      "Loss after mini-batch    14: 0.008\n",
      "Loss after mini-batch    15: 0.142\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.011\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.066\n",
      "Loss after mini-batch    20: 0.016\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.015\n",
      "Loss after mini-batch    23: 0.016\n",
      "Loss after mini-batch    24: 0.006\n",
      "Loss after mini-batch    25: 0.006\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 8: 89 %\n",
      "--------------------------------\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.820\n",
      "Loss after mini-batch     2: 0.702\n",
      "Loss after mini-batch     3: 0.712\n",
      "Loss after mini-batch     4: 0.575\n",
      "Loss after mini-batch     5: 0.837\n",
      "Loss after mini-batch     6: 1.041\n",
      "Loss after mini-batch     7: 0.833\n",
      "Loss after mini-batch     8: 0.637\n",
      "Loss after mini-batch     9: 0.622\n",
      "Loss after mini-batch    10: 0.721\n",
      "Loss after mini-batch    11: 0.678\n",
      "Loss after mini-batch    12: 0.694\n",
      "Loss after mini-batch    13: 0.702\n",
      "Loss after mini-batch    14: 0.695\n",
      "Loss after mini-batch    15: 0.680\n",
      "Loss after mini-batch    16: 0.691\n",
      "Loss after mini-batch    17: 0.690\n",
      "Loss after mini-batch    18: 0.676\n",
      "Loss after mini-batch    19: 0.682\n",
      "Loss after mini-batch    20: 0.685\n",
      "Loss after mini-batch    21: 0.689\n",
      "Loss after mini-batch    22: 0.674\n",
      "Loss after mini-batch    23: 0.635\n",
      "Loss after mini-batch    24: 0.645\n",
      "Loss after mini-batch    25: 0.696\n",
      "Loss after mini-batch    26: 0.863\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.621\n",
      "Loss after mini-batch     2: 0.713\n",
      "Loss after mini-batch     3: 0.681\n",
      "Loss after mini-batch     4: 0.638\n",
      "Loss after mini-batch     5: 0.740\n",
      "Loss after mini-batch     6: 0.643\n",
      "Loss after mini-batch     7: 0.694\n",
      "Loss after mini-batch     8: 0.666\n",
      "Loss after mini-batch     9: 0.669\n",
      "Loss after mini-batch    10: 0.666\n",
      "Loss after mini-batch    11: 0.663\n",
      "Loss after mini-batch    12: 0.684\n",
      "Loss after mini-batch    13: 0.672\n",
      "Loss after mini-batch    14: 0.662\n",
      "Loss after mini-batch    15: 0.671\n",
      "Loss after mini-batch    16: 0.673\n",
      "Loss after mini-batch    17: 0.650\n",
      "Loss after mini-batch    18: 0.690\n",
      "Loss after mini-batch    19: 0.657\n",
      "Loss after mini-batch    20: 0.673\n",
      "Loss after mini-batch    21: 0.633\n",
      "Loss after mini-batch    22: 0.639\n",
      "Loss after mini-batch    23: 0.635\n",
      "Loss after mini-batch    24: 0.543\n",
      "Loss after mini-batch    25: 0.517\n",
      "Loss after mini-batch    26: 0.544\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.562\n",
      "Loss after mini-batch     2: 0.593\n",
      "Loss after mini-batch     3: 0.546\n",
      "Loss after mini-batch     4: 0.550\n",
      "Loss after mini-batch     5: 0.618\n",
      "Loss after mini-batch     6: 0.353\n",
      "Loss after mini-batch     7: 0.422\n",
      "Loss after mini-batch     8: 0.603\n",
      "Loss after mini-batch     9: 0.460\n",
      "Loss after mini-batch    10: 0.438\n",
      "Loss after mini-batch    11: 0.300\n",
      "Loss after mini-batch    12: 0.334\n",
      "Loss after mini-batch    13: 0.615\n",
      "Loss after mini-batch    14: 0.488\n",
      "Loss after mini-batch    15: 0.487\n",
      "Loss after mini-batch    16: 0.330\n",
      "Loss after mini-batch    17: 0.411\n",
      "Loss after mini-batch    18: 0.520\n",
      "Loss after mini-batch    19: 0.504\n",
      "Loss after mini-batch    20: 0.573\n",
      "Loss after mini-batch    21: 0.402\n",
      "Loss after mini-batch    22: 0.696\n",
      "Loss after mini-batch    23: 0.322\n",
      "Loss after mini-batch    24: 0.426\n",
      "Loss after mini-batch    25: 0.344\n",
      "Loss after mini-batch    26: 0.651\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.335\n",
      "Loss after mini-batch     2: 0.829\n",
      "Loss after mini-batch     3: 0.396\n",
      "Loss after mini-batch     4: 0.151\n",
      "Loss after mini-batch     5: 0.696\n",
      "Loss after mini-batch     6: 0.650\n",
      "Loss after mini-batch     7: 0.291\n",
      "Loss after mini-batch     8: 0.386\n",
      "Loss after mini-batch     9: 0.354\n",
      "Loss after mini-batch    10: 0.238\n",
      "Loss after mini-batch    11: 0.430\n",
      "Loss after mini-batch    12: 0.295\n",
      "Loss after mini-batch    13: 0.176\n",
      "Loss after mini-batch    14: 0.137\n",
      "Loss after mini-batch    15: 0.787\n",
      "Loss after mini-batch    16: 0.278\n",
      "Loss after mini-batch    17: 0.490\n",
      "Loss after mini-batch    18: 0.446\n",
      "Loss after mini-batch    19: 0.341\n",
      "Loss after mini-batch    20: 0.248\n",
      "Loss after mini-batch    21: 0.197\n",
      "Loss after mini-batch    22: 0.093\n",
      "Loss after mini-batch    23: 0.141\n",
      "Loss after mini-batch    24: 0.405\n",
      "Loss after mini-batch    25: 0.688\n",
      "Loss after mini-batch    26: 0.406\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.226\n",
      "Loss after mini-batch     2: 0.069\n",
      "Loss after mini-batch     3: 0.464\n",
      "Loss after mini-batch     4: 0.167\n",
      "Loss after mini-batch     5: 0.336\n",
      "Loss after mini-batch     6: 0.546\n",
      "Loss after mini-batch     7: 0.084\n",
      "Loss after mini-batch     8: 0.298\n",
      "Loss after mini-batch     9: 0.245\n",
      "Loss after mini-batch    10: 0.835\n",
      "Loss after mini-batch    11: 0.357\n",
      "Loss after mini-batch    12: 0.353\n",
      "Loss after mini-batch    13: 0.244\n",
      "Loss after mini-batch    14: 0.533\n",
      "Loss after mini-batch    15: 0.136\n",
      "Loss after mini-batch    16: 0.278\n",
      "Loss after mini-batch    17: 0.170\n",
      "Loss after mini-batch    18: 0.423\n",
      "Loss after mini-batch    19: 0.212\n",
      "Loss after mini-batch    20: 0.348\n",
      "Loss after mini-batch    21: 0.258\n",
      "Loss after mini-batch    22: 0.114\n",
      "Loss after mini-batch    23: 0.315\n",
      "Loss after mini-batch    24: 0.219\n",
      "Loss after mini-batch    25: 0.228\n",
      "Loss after mini-batch    26: 0.013\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.227\n",
      "Loss after mini-batch     2: 0.214\n",
      "Loss after mini-batch     3: 0.067\n",
      "Loss after mini-batch     4: 0.623\n",
      "Loss after mini-batch     5: 0.352\n",
      "Loss after mini-batch     6: 0.170\n",
      "Loss after mini-batch     7: 0.178\n",
      "Loss after mini-batch     8: 0.253\n",
      "Loss after mini-batch     9: 0.355\n",
      "Loss after mini-batch    10: 0.268\n",
      "Loss after mini-batch    11: 0.054\n",
      "Loss after mini-batch    12: 0.343\n",
      "Loss after mini-batch    13: 0.071\n",
      "Loss after mini-batch    14: 0.293\n",
      "Loss after mini-batch    15: 0.048\n",
      "Loss after mini-batch    16: 0.217\n",
      "Loss after mini-batch    17: 0.074\n",
      "Loss after mini-batch    18: 0.503\n",
      "Loss after mini-batch    19: 0.190\n",
      "Loss after mini-batch    20: 0.239\n",
      "Loss after mini-batch    21: 0.132\n",
      "Loss after mini-batch    22: 0.162\n",
      "Loss after mini-batch    23: 0.308\n",
      "Loss after mini-batch    24: 0.308\n",
      "Loss after mini-batch    25: 0.143\n",
      "Loss after mini-batch    26: 0.139\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.079\n",
      "Loss after mini-batch     2: 0.204\n",
      "Loss after mini-batch     3: 0.169\n",
      "Loss after mini-batch     4: 0.113\n",
      "Loss after mini-batch     5: 0.127\n",
      "Loss after mini-batch     6: 0.162\n",
      "Loss after mini-batch     7: 0.068\n",
      "Loss after mini-batch     8: 0.056\n",
      "Loss after mini-batch     9: 0.215\n",
      "Loss after mini-batch    10: 0.100\n",
      "Loss after mini-batch    11: 0.114\n",
      "Loss after mini-batch    12: 0.184\n",
      "Loss after mini-batch    13: 0.033\n",
      "Loss after mini-batch    14: 0.135\n",
      "Loss after mini-batch    15: 0.177\n",
      "Loss after mini-batch    16: 0.211\n",
      "Loss after mini-batch    17: 0.209\n",
      "Loss after mini-batch    18: 0.199\n",
      "Loss after mini-batch    19: 0.042\n",
      "Loss after mini-batch    20: 0.173\n",
      "Loss after mini-batch    21: 0.156\n",
      "Loss after mini-batch    22: 0.021\n",
      "Loss after mini-batch    23: 0.209\n",
      "Loss after mini-batch    24: 0.377\n",
      "Loss after mini-batch    25: 0.235\n",
      "Loss after mini-batch    26: 0.298\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.166\n",
      "Loss after mini-batch     2: 0.167\n",
      "Loss after mini-batch     3: 0.028\n",
      "Loss after mini-batch     4: 0.084\n",
      "Loss after mini-batch     5: 0.086\n",
      "Loss after mini-batch     6: 0.050\n",
      "Loss after mini-batch     7: 0.191\n",
      "Loss after mini-batch     8: 0.053\n",
      "Loss after mini-batch     9: 0.046\n",
      "Loss after mini-batch    10: 0.084\n",
      "Loss after mini-batch    11: 0.086\n",
      "Loss after mini-batch    12: 0.175\n",
      "Loss after mini-batch    13: 0.073\n",
      "Loss after mini-batch    14: 0.035\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.036\n",
      "Loss after mini-batch    17: 0.037\n",
      "Loss after mini-batch    18: 0.131\n",
      "Loss after mini-batch    19: 0.050\n",
      "Loss after mini-batch    20: 0.168\n",
      "Loss after mini-batch    21: 0.223\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.130\n",
      "Loss after mini-batch    24: 0.162\n",
      "Loss after mini-batch    25: 0.028\n",
      "Loss after mini-batch    26: 0.016\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.101\n",
      "Loss after mini-batch     4: 0.034\n",
      "Loss after mini-batch     5: 0.028\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.044\n",
      "Loss after mini-batch     8: 0.080\n",
      "Loss after mini-batch     9: 0.071\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.191\n",
      "Loss after mini-batch    12: 0.027\n",
      "Loss after mini-batch    13: 0.050\n",
      "Loss after mini-batch    14: 0.049\n",
      "Loss after mini-batch    15: 0.017\n",
      "Loss after mini-batch    16: 0.030\n",
      "Loss after mini-batch    17: 0.166\n",
      "Loss after mini-batch    18: 0.008\n",
      "Loss after mini-batch    19: 0.024\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.025\n",
      "Loss after mini-batch    22: 0.046\n",
      "Loss after mini-batch    23: 0.109\n",
      "Loss after mini-batch    24: 0.012\n",
      "Loss after mini-batch    25: 0.018\n",
      "Loss after mini-batch    26: 0.003\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.027\n",
      "Loss after mini-batch     2: 0.057\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.012\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.036\n",
      "Loss after mini-batch     9: 0.022\n",
      "Loss after mini-batch    10: 0.024\n",
      "Loss after mini-batch    11: 0.035\n",
      "Loss after mini-batch    12: 0.034\n",
      "Loss after mini-batch    13: 0.013\n",
      "Loss after mini-batch    14: 0.003\n",
      "Loss after mini-batch    15: 0.009\n",
      "Loss after mini-batch    16: 0.010\n",
      "Loss after mini-batch    17: 0.013\n",
      "Loss after mini-batch    18: 0.010\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.051\n",
      "Loss after mini-batch    22: 0.172\n",
      "Loss after mini-batch    23: 0.116\n",
      "Loss after mini-batch    24: 0.004\n",
      "Loss after mini-batch    25: 0.103\n",
      "Loss after mini-batch    26: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 9: 78 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 75.0 %\n",
      "Fold 1: 78.57142857142857 %\n",
      "Fold 2: 78.57142857142857 %\n",
      "Fold 3: 85.71428571428571 %\n",
      "Fold 4: 92.85714285714286 %\n",
      "Fold 5: 89.28571428571429 %\n",
      "Fold 6: 92.85714285714286 %\n",
      "Fold 7: 75.0 %\n",
      "Fold 8: 89.28571428571429 %\n",
      "Fold 9: 78.57142857142857 %\n",
      "Average: 83.57142857142857 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 10\n",
    "  num_epochs = 10\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.848\n",
      "Loss after mini-batch     2: 0.705\n",
      "Loss after mini-batch     3: 0.730\n",
      "Loss after mini-batch     4: 0.929\n",
      "Loss after mini-batch     5: 0.682\n",
      "Loss after mini-batch     6: 0.845\n",
      "Loss after mini-batch     7: 0.782\n",
      "Loss after mini-batch     8: 0.589\n",
      "Loss after mini-batch     9: 0.687\n",
      "Loss after mini-batch    10: 0.722\n",
      "Loss after mini-batch    11: 0.642\n",
      "Loss after mini-batch    12: 0.683\n",
      "Loss after mini-batch    13: 0.601\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.760\n",
      "Loss after mini-batch     2: 0.555\n",
      "Loss after mini-batch     3: 0.554\n",
      "Loss after mini-batch     4: 0.645\n",
      "Loss after mini-batch     5: 0.531\n",
      "Loss after mini-batch     6: 0.640\n",
      "Loss after mini-batch     7: 0.477\n",
      "Loss after mini-batch     8: 0.455\n",
      "Loss after mini-batch     9: 0.752\n",
      "Loss after mini-batch    10: 0.592\n",
      "Loss after mini-batch    11: 0.529\n",
      "Loss after mini-batch    12: 0.380\n",
      "Loss after mini-batch    13: 0.569\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.551\n",
      "Loss after mini-batch     2: 0.472\n",
      "Loss after mini-batch     3: 0.403\n",
      "Loss after mini-batch     4: 0.674\n",
      "Loss after mini-batch     5: 0.474\n",
      "Loss after mini-batch     6: 0.320\n",
      "Loss after mini-batch     7: 0.224\n",
      "Loss after mini-batch     8: 0.407\n",
      "Loss after mini-batch     9: 0.388\n",
      "Loss after mini-batch    10: 0.379\n",
      "Loss after mini-batch    11: 0.505\n",
      "Loss after mini-batch    12: 0.258\n",
      "Loss after mini-batch    13: 0.405\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.339\n",
      "Loss after mini-batch     2: 0.337\n",
      "Loss after mini-batch     3: 0.224\n",
      "Loss after mini-batch     4: 0.246\n",
      "Loss after mini-batch     5: 0.349\n",
      "Loss after mini-batch     6: 0.239\n",
      "Loss after mini-batch     7: 0.271\n",
      "Loss after mini-batch     8: 0.434\n",
      "Loss after mini-batch     9: 0.358\n",
      "Loss after mini-batch    10: 0.495\n",
      "Loss after mini-batch    11: 0.147\n",
      "Loss after mini-batch    12: 0.229\n",
      "Loss after mini-batch    13: 0.213\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.205\n",
      "Loss after mini-batch     2: 0.311\n",
      "Loss after mini-batch     3: 0.188\n",
      "Loss after mini-batch     4: 0.399\n",
      "Loss after mini-batch     5: 0.162\n",
      "Loss after mini-batch     6: 0.305\n",
      "Loss after mini-batch     7: 0.162\n",
      "Loss after mini-batch     8: 0.213\n",
      "Loss after mini-batch     9: 0.230\n",
      "Loss after mini-batch    10: 0.115\n",
      "Loss after mini-batch    11: 0.444\n",
      "Loss after mini-batch    12: 0.350\n",
      "Loss after mini-batch    13: 0.260\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.232\n",
      "Loss after mini-batch     2: 0.157\n",
      "Loss after mini-batch     3: 0.216\n",
      "Loss after mini-batch     4: 0.238\n",
      "Loss after mini-batch     5: 0.118\n",
      "Loss after mini-batch     6: 0.218\n",
      "Loss after mini-batch     7: 0.159\n",
      "Loss after mini-batch     8: 0.406\n",
      "Loss after mini-batch     9: 0.175\n",
      "Loss after mini-batch    10: 0.172\n",
      "Loss after mini-batch    11: 0.131\n",
      "Loss after mini-batch    12: 0.233\n",
      "Loss after mini-batch    13: 0.146\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch     2: 0.142\n",
      "Loss after mini-batch     3: 0.163\n",
      "Loss after mini-batch     4: 0.186\n",
      "Loss after mini-batch     5: 0.127\n",
      "Loss after mini-batch     6: 0.133\n",
      "Loss after mini-batch     7: 0.072\n",
      "Loss after mini-batch     8: 0.176\n",
      "Loss after mini-batch     9: 0.086\n",
      "Loss after mini-batch    10: 0.113\n",
      "Loss after mini-batch    11: 0.092\n",
      "Loss after mini-batch    12: 0.076\n",
      "Loss after mini-batch    13: 0.170\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.161\n",
      "Loss after mini-batch     2: 0.128\n",
      "Loss after mini-batch     3: 0.056\n",
      "Loss after mini-batch     4: 0.128\n",
      "Loss after mini-batch     5: 0.051\n",
      "Loss after mini-batch     6: 0.049\n",
      "Loss after mini-batch     7: 0.084\n",
      "Loss after mini-batch     8: 0.058\n",
      "Loss after mini-batch     9: 0.134\n",
      "Loss after mini-batch    10: 0.057\n",
      "Loss after mini-batch    11: 0.061\n",
      "Loss after mini-batch    12: 0.027\n",
      "Loss after mini-batch    13: 0.118\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.080\n",
      "Loss after mini-batch     2: 0.049\n",
      "Loss after mini-batch     3: 0.091\n",
      "Loss after mini-batch     4: 0.047\n",
      "Loss after mini-batch     5: 0.021\n",
      "Loss after mini-batch     6: 0.042\n",
      "Loss after mini-batch     7: 0.058\n",
      "Loss after mini-batch     8: 0.041\n",
      "Loss after mini-batch     9: 0.053\n",
      "Loss after mini-batch    10: 0.084\n",
      "Loss after mini-batch    11: 0.090\n",
      "Loss after mini-batch    12: 0.034\n",
      "Loss after mini-batch    13: 0.030\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.058\n",
      "Loss after mini-batch     2: 0.067\n",
      "Loss after mini-batch     3: 0.040\n",
      "Loss after mini-batch     4: 0.024\n",
      "Loss after mini-batch     5: 0.045\n",
      "Loss after mini-batch     6: 0.027\n",
      "Loss after mini-batch     7: 0.048\n",
      "Loss after mini-batch     8: 0.053\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.022\n",
      "Loss after mini-batch    11: 0.026\n",
      "Loss after mini-batch    12: 0.021\n",
      "Loss after mini-batch    13: 0.035\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.042\n",
      "Loss after mini-batch     2: 0.015\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.031\n",
      "Loss after mini-batch     6: 0.021\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.046\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.016\n",
      "Loss after mini-batch    11: 0.014\n",
      "Loss after mini-batch    12: 0.040\n",
      "Loss after mini-batch    13: 0.093\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.016\n",
      "Loss after mini-batch     3: 0.011\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.021\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.059\n",
      "Loss after mini-batch     8: 0.040\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.032\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.008\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.029\n",
      "Loss after mini-batch     3: 0.013\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.017\n",
      "Loss after mini-batch     7: 0.021\n",
      "Loss after mini-batch     8: 0.030\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.027\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.018\n",
      "Loss after mini-batch     2: 0.017\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.044\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.008\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.014\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.033\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.030\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.026\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.015\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.013\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.028\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.009\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.017\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.003\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.007\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 92 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.653\n",
      "Loss after mini-batch     2: 0.985\n",
      "Loss after mini-batch     3: 0.661\n",
      "Loss after mini-batch     4: 0.849\n",
      "Loss after mini-batch     5: 0.738\n",
      "Loss after mini-batch     6: 0.760\n",
      "Loss after mini-batch     7: 0.731\n",
      "Loss after mini-batch     8: 0.673\n",
      "Loss after mini-batch     9: 0.615\n",
      "Loss after mini-batch    10: 0.647\n",
      "Loss after mini-batch    11: 0.753\n",
      "Loss after mini-batch    12: 0.776\n",
      "Loss after mini-batch    13: 0.603\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.608\n",
      "Loss after mini-batch     2: 0.595\n",
      "Loss after mini-batch     3: 0.655\n",
      "Loss after mini-batch     4: 0.590\n",
      "Loss after mini-batch     5: 0.572\n",
      "Loss after mini-batch     6: 0.605\n",
      "Loss after mini-batch     7: 0.525\n",
      "Loss after mini-batch     8: 0.510\n",
      "Loss after mini-batch     9: 0.450\n",
      "Loss after mini-batch    10: 0.634\n",
      "Loss after mini-batch    11: 0.540\n",
      "Loss after mini-batch    12: 0.444\n",
      "Loss after mini-batch    13: 0.428\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.517\n",
      "Loss after mini-batch     2: 0.284\n",
      "Loss after mini-batch     3: 0.339\n",
      "Loss after mini-batch     4: 0.287\n",
      "Loss after mini-batch     5: 0.381\n",
      "Loss after mini-batch     6: 0.361\n",
      "Loss after mini-batch     7: 0.464\n",
      "Loss after mini-batch     8: 0.379\n",
      "Loss after mini-batch     9: 0.271\n",
      "Loss after mini-batch    10: 0.463\n",
      "Loss after mini-batch    11: 0.373\n",
      "Loss after mini-batch    12: 0.511\n",
      "Loss after mini-batch    13: 0.400\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.343\n",
      "Loss after mini-batch     2: 0.468\n",
      "Loss after mini-batch     3: 0.275\n",
      "Loss after mini-batch     4: 0.229\n",
      "Loss after mini-batch     5: 0.256\n",
      "Loss after mini-batch     6: 0.183\n",
      "Loss after mini-batch     7: 0.474\n",
      "Loss after mini-batch     8: 0.469\n",
      "Loss after mini-batch     9: 0.204\n",
      "Loss after mini-batch    10: 0.186\n",
      "Loss after mini-batch    11: 0.284\n",
      "Loss after mini-batch    12: 0.419\n",
      "Loss after mini-batch    13: 0.286\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.153\n",
      "Loss after mini-batch     2: 0.326\n",
      "Loss after mini-batch     3: 0.418\n",
      "Loss after mini-batch     4: 0.201\n",
      "Loss after mini-batch     5: 0.409\n",
      "Loss after mini-batch     6: 0.231\n",
      "Loss after mini-batch     7: 0.144\n",
      "Loss after mini-batch     8: 0.154\n",
      "Loss after mini-batch     9: 0.115\n",
      "Loss after mini-batch    10: 0.278\n",
      "Loss after mini-batch    11: 0.083\n",
      "Loss after mini-batch    12: 0.231\n",
      "Loss after mini-batch    13: 0.363\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.195\n",
      "Loss after mini-batch     2: 0.296\n",
      "Loss after mini-batch     3: 0.182\n",
      "Loss after mini-batch     4: 0.200\n",
      "Loss after mini-batch     5: 0.109\n",
      "Loss after mini-batch     6: 0.243\n",
      "Loss after mini-batch     7: 0.147\n",
      "Loss after mini-batch     8: 0.342\n",
      "Loss after mini-batch     9: 0.091\n",
      "Loss after mini-batch    10: 0.195\n",
      "Loss after mini-batch    11: 0.079\n",
      "Loss after mini-batch    12: 0.231\n",
      "Loss after mini-batch    13: 0.077\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.176\n",
      "Loss after mini-batch     2: 0.129\n",
      "Loss after mini-batch     3: 0.226\n",
      "Loss after mini-batch     4: 0.131\n",
      "Loss after mini-batch     5: 0.046\n",
      "Loss after mini-batch     6: 0.166\n",
      "Loss after mini-batch     7: 0.082\n",
      "Loss after mini-batch     8: 0.211\n",
      "Loss after mini-batch     9: 0.213\n",
      "Loss after mini-batch    10: 0.069\n",
      "Loss after mini-batch    11: 0.122\n",
      "Loss after mini-batch    12: 0.030\n",
      "Loss after mini-batch    13: 0.357\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.102\n",
      "Loss after mini-batch     2: 0.037\n",
      "Loss after mini-batch     3: 0.092\n",
      "Loss after mini-batch     4: 0.066\n",
      "Loss after mini-batch     5: 0.094\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.153\n",
      "Loss after mini-batch     8: 0.285\n",
      "Loss after mini-batch     9: 0.104\n",
      "Loss after mini-batch    10: 0.167\n",
      "Loss after mini-batch    11: 0.081\n",
      "Loss after mini-batch    12: 0.107\n",
      "Loss after mini-batch    13: 0.053\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.039\n",
      "Loss after mini-batch     2: 0.053\n",
      "Loss after mini-batch     3: 0.044\n",
      "Loss after mini-batch     4: 0.109\n",
      "Loss after mini-batch     5: 0.098\n",
      "Loss after mini-batch     6: 0.044\n",
      "Loss after mini-batch     7: 0.115\n",
      "Loss after mini-batch     8: 0.191\n",
      "Loss after mini-batch     9: 0.021\n",
      "Loss after mini-batch    10: 0.085\n",
      "Loss after mini-batch    11: 0.095\n",
      "Loss after mini-batch    12: 0.080\n",
      "Loss after mini-batch    13: 0.061\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.013\n",
      "Loss after mini-batch     2: 0.064\n",
      "Loss after mini-batch     3: 0.041\n",
      "Loss after mini-batch     4: 0.044\n",
      "Loss after mini-batch     5: 0.045\n",
      "Loss after mini-batch     6: 0.057\n",
      "Loss after mini-batch     7: 0.081\n",
      "Loss after mini-batch     8: 0.166\n",
      "Loss after mini-batch     9: 0.060\n",
      "Loss after mini-batch    10: 0.128\n",
      "Loss after mini-batch    11: 0.030\n",
      "Loss after mini-batch    12: 0.023\n",
      "Loss after mini-batch    13: 0.037\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.023\n",
      "Loss after mini-batch     2: 0.066\n",
      "Loss after mini-batch     3: 0.037\n",
      "Loss after mini-batch     4: 0.041\n",
      "Loss after mini-batch     5: 0.153\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.020\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.035\n",
      "Loss after mini-batch    10: 0.018\n",
      "Loss after mini-batch    11: 0.062\n",
      "Loss after mini-batch    12: 0.026\n",
      "Loss after mini-batch    13: 0.013\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.030\n",
      "Loss after mini-batch     2: 0.026\n",
      "Loss after mini-batch     3: 0.038\n",
      "Loss after mini-batch     4: 0.031\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.035\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.011\n",
      "Loss after mini-batch    12: 0.034\n",
      "Loss after mini-batch    13: 0.029\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.015\n",
      "Loss after mini-batch     3: 0.032\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.015\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.035\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.033\n",
      "Loss after mini-batch    12: 0.076\n",
      "Loss after mini-batch    13: 0.007\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.036\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.020\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.040\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.010\n",
      "Loss after mini-batch    12: 0.027\n",
      "Loss after mini-batch    13: 0.016\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.017\n",
      "Loss after mini-batch     3: 0.028\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.036\n",
      "Loss after mini-batch    13: 0.019\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.023\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.026\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.024\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.009\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.015\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.017\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 75 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 1.974\n",
      "Loss after mini-batch     2: 1.744\n",
      "Loss after mini-batch     3: 0.689\n",
      "Loss after mini-batch     4: 2.706\n",
      "Loss after mini-batch     5: 0.738\n",
      "Loss after mini-batch     6: 1.057\n",
      "Loss after mini-batch     7: 0.920\n",
      "Loss after mini-batch     8: 0.830\n",
      "Loss after mini-batch     9: 0.768\n",
      "Loss after mini-batch    10: 0.743\n",
      "Loss after mini-batch    11: 0.681\n",
      "Loss after mini-batch    12: 0.681\n",
      "Loss after mini-batch    13: 0.567\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.955\n",
      "Loss after mini-batch     2: 1.148\n",
      "Loss after mini-batch     3: 0.666\n",
      "Loss after mini-batch     4: 0.615\n",
      "Loss after mini-batch     5: 0.689\n",
      "Loss after mini-batch     6: 0.624\n",
      "Loss after mini-batch     7: 0.667\n",
      "Loss after mini-batch     8: 0.628\n",
      "Loss after mini-batch     9: 0.664\n",
      "Loss after mini-batch    10: 0.648\n",
      "Loss after mini-batch    11: 0.596\n",
      "Loss after mini-batch    12: 0.602\n",
      "Loss after mini-batch    13: 0.666\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.675\n",
      "Loss after mini-batch     2: 0.584\n",
      "Loss after mini-batch     3: 0.530\n",
      "Loss after mini-batch     4: 0.606\n",
      "Loss after mini-batch     5: 0.623\n",
      "Loss after mini-batch     6: 0.517\n",
      "Loss after mini-batch     7: 0.546\n",
      "Loss after mini-batch     8: 0.676\n",
      "Loss after mini-batch     9: 0.515\n",
      "Loss after mini-batch    10: 0.520\n",
      "Loss after mini-batch    11: 0.565\n",
      "Loss after mini-batch    12: 0.544\n",
      "Loss after mini-batch    13: 0.600\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.441\n",
      "Loss after mini-batch     2: 0.508\n",
      "Loss after mini-batch     3: 0.450\n",
      "Loss after mini-batch     4: 0.570\n",
      "Loss after mini-batch     5: 0.472\n",
      "Loss after mini-batch     6: 0.505\n",
      "Loss after mini-batch     7: 0.457\n",
      "Loss after mini-batch     8: 0.473\n",
      "Loss after mini-batch     9: 0.481\n",
      "Loss after mini-batch    10: 0.496\n",
      "Loss after mini-batch    11: 0.444\n",
      "Loss after mini-batch    12: 0.476\n",
      "Loss after mini-batch    13: 0.345\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.485\n",
      "Loss after mini-batch     2: 0.397\n",
      "Loss after mini-batch     3: 0.380\n",
      "Loss after mini-batch     4: 0.570\n",
      "Loss after mini-batch     5: 0.459\n",
      "Loss after mini-batch     6: 0.244\n",
      "Loss after mini-batch     7: 0.353\n",
      "Loss after mini-batch     8: 0.500\n",
      "Loss after mini-batch     9: 0.407\n",
      "Loss after mini-batch    10: 0.292\n",
      "Loss after mini-batch    11: 0.335\n",
      "Loss after mini-batch    12: 0.276\n",
      "Loss after mini-batch    13: 0.416\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.401\n",
      "Loss after mini-batch     2: 0.430\n",
      "Loss after mini-batch     3: 0.284\n",
      "Loss after mini-batch     4: 0.347\n",
      "Loss after mini-batch     5: 0.231\n",
      "Loss after mini-batch     6: 0.368\n",
      "Loss after mini-batch     7: 0.336\n",
      "Loss after mini-batch     8: 0.412\n",
      "Loss after mini-batch     9: 0.289\n",
      "Loss after mini-batch    10: 0.287\n",
      "Loss after mini-batch    11: 0.501\n",
      "Loss after mini-batch    12: 0.320\n",
      "Loss after mini-batch    13: 0.322\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.346\n",
      "Loss after mini-batch     2: 0.433\n",
      "Loss after mini-batch     3: 0.200\n",
      "Loss after mini-batch     4: 0.289\n",
      "Loss after mini-batch     5: 0.448\n",
      "Loss after mini-batch     6: 0.272\n",
      "Loss after mini-batch     7: 0.195\n",
      "Loss after mini-batch     8: 0.185\n",
      "Loss after mini-batch     9: 0.361\n",
      "Loss after mini-batch    10: 0.222\n",
      "Loss after mini-batch    11: 0.272\n",
      "Loss after mini-batch    12: 0.117\n",
      "Loss after mini-batch    13: 0.294\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.312\n",
      "Loss after mini-batch     2: 0.144\n",
      "Loss after mini-batch     3: 0.164\n",
      "Loss after mini-batch     4: 0.250\n",
      "Loss after mini-batch     5: 0.267\n",
      "Loss after mini-batch     6: 0.410\n",
      "Loss after mini-batch     7: 0.227\n",
      "Loss after mini-batch     8: 0.230\n",
      "Loss after mini-batch     9: 0.107\n",
      "Loss after mini-batch    10: 0.121\n",
      "Loss after mini-batch    11: 0.271\n",
      "Loss after mini-batch    12: 0.237\n",
      "Loss after mini-batch    13: 0.345\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.293\n",
      "Loss after mini-batch     2: 0.281\n",
      "Loss after mini-batch     3: 0.151\n",
      "Loss after mini-batch     4: 0.203\n",
      "Loss after mini-batch     5: 0.184\n",
      "Loss after mini-batch     6: 0.186\n",
      "Loss after mini-batch     7: 0.154\n",
      "Loss after mini-batch     8: 0.119\n",
      "Loss after mini-batch     9: 0.068\n",
      "Loss after mini-batch    10: 0.181\n",
      "Loss after mini-batch    11: 0.219\n",
      "Loss after mini-batch    12: 0.183\n",
      "Loss after mini-batch    13: 0.277\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.088\n",
      "Loss after mini-batch     2: 0.259\n",
      "Loss after mini-batch     3: 0.126\n",
      "Loss after mini-batch     4: 0.114\n",
      "Loss after mini-batch     5: 0.151\n",
      "Loss after mini-batch     6: 0.112\n",
      "Loss after mini-batch     7: 0.160\n",
      "Loss after mini-batch     8: 0.289\n",
      "Loss after mini-batch     9: 0.145\n",
      "Loss after mini-batch    10: 0.177\n",
      "Loss after mini-batch    11: 0.090\n",
      "Loss after mini-batch    12: 0.136\n",
      "Loss after mini-batch    13: 0.097\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.142\n",
      "Loss after mini-batch     2: 0.174\n",
      "Loss after mini-batch     3: 0.103\n",
      "Loss after mini-batch     4: 0.087\n",
      "Loss after mini-batch     5: 0.111\n",
      "Loss after mini-batch     6: 0.178\n",
      "Loss after mini-batch     7: 0.151\n",
      "Loss after mini-batch     8: 0.133\n",
      "Loss after mini-batch     9: 0.204\n",
      "Loss after mini-batch    10: 0.112\n",
      "Loss after mini-batch    11: 0.124\n",
      "Loss after mini-batch    12: 0.121\n",
      "Loss after mini-batch    13: 0.059\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.151\n",
      "Loss after mini-batch     2: 0.109\n",
      "Loss after mini-batch     3: 0.079\n",
      "Loss after mini-batch     4: 0.025\n",
      "Loss after mini-batch     5: 0.125\n",
      "Loss after mini-batch     6: 0.081\n",
      "Loss after mini-batch     7: 0.198\n",
      "Loss after mini-batch     8: 0.093\n",
      "Loss after mini-batch     9: 0.071\n",
      "Loss after mini-batch    10: 0.071\n",
      "Loss after mini-batch    11: 0.066\n",
      "Loss after mini-batch    12: 0.139\n",
      "Loss after mini-batch    13: 0.018\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.039\n",
      "Loss after mini-batch     2: 0.072\n",
      "Loss after mini-batch     3: 0.057\n",
      "Loss after mini-batch     4: 0.087\n",
      "Loss after mini-batch     5: 0.081\n",
      "Loss after mini-batch     6: 0.067\n",
      "Loss after mini-batch     7: 0.132\n",
      "Loss after mini-batch     8: 0.054\n",
      "Loss after mini-batch     9: 0.138\n",
      "Loss after mini-batch    10: 0.073\n",
      "Loss after mini-batch    11: 0.020\n",
      "Loss after mini-batch    12: 0.029\n",
      "Loss after mini-batch    13: 0.195\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.053\n",
      "Loss after mini-batch     2: 0.118\n",
      "Loss after mini-batch     3: 0.051\n",
      "Loss after mini-batch     4: 0.024\n",
      "Loss after mini-batch     5: 0.080\n",
      "Loss after mini-batch     6: 0.072\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.114\n",
      "Loss after mini-batch     9: 0.089\n",
      "Loss after mini-batch    10: 0.073\n",
      "Loss after mini-batch    11: 0.019\n",
      "Loss after mini-batch    12: 0.088\n",
      "Loss after mini-batch    13: 0.071\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.097\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.070\n",
      "Loss after mini-batch     4: 0.018\n",
      "Loss after mini-batch     5: 0.065\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.030\n",
      "Loss after mini-batch     8: 0.021\n",
      "Loss after mini-batch     9: 0.044\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.100\n",
      "Loss after mini-batch    12: 0.042\n",
      "Loss after mini-batch    13: 0.005\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.053\n",
      "Loss after mini-batch     2: 0.070\n",
      "Loss after mini-batch     3: 0.020\n",
      "Loss after mini-batch     4: 0.032\n",
      "Loss after mini-batch     5: 0.050\n",
      "Loss after mini-batch     6: 0.041\n",
      "Loss after mini-batch     7: 0.080\n",
      "Loss after mini-batch     8: 0.054\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.039\n",
      "Loss after mini-batch    11: 0.025\n",
      "Loss after mini-batch    12: 0.011\n",
      "Loss after mini-batch    13: 0.008\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.042\n",
      "Loss after mini-batch     2: 0.066\n",
      "Loss after mini-batch     3: 0.064\n",
      "Loss after mini-batch     4: 0.029\n",
      "Loss after mini-batch     5: 0.021\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.020\n",
      "Loss after mini-batch     8: 0.018\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.013\n",
      "Loss after mini-batch    12: 0.030\n",
      "Loss after mini-batch    13: 0.007\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.062\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.031\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.013\n",
      "Loss after mini-batch     9: 0.025\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.013\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.011\n",
      "Loss after mini-batch     4: 0.015\n",
      "Loss after mini-batch     5: 0.032\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.012\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.038\n",
      "Loss after mini-batch    11: 0.038\n",
      "Loss after mini-batch    12: 0.008\n",
      "Loss after mini-batch    13: 0.043\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.032\n",
      "Loss after mini-batch     2: 0.015\n",
      "Loss after mini-batch     3: 0.013\n",
      "Loss after mini-batch     4: 0.019\n",
      "Loss after mini-batch     5: 0.025\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.008\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.041\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.021\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.006\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.011\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.030\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.013\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.026\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.018\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.029\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.019\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.024\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.011\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.015\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.017\n",
      "Loss after mini-batch    13: 0.010\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.017\n",
      "Loss after mini-batch    12: 0.007\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.009\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.010\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.003\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 78 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.694\n",
      "Loss after mini-batch     2: 0.889\n",
      "Loss after mini-batch     3: 1.039\n",
      "Loss after mini-batch     4: 0.974\n",
      "Loss after mini-batch     5: 0.609\n",
      "Loss after mini-batch     6: 0.655\n",
      "Loss after mini-batch     7: 0.968\n",
      "Loss after mini-batch     8: 0.595\n",
      "Loss after mini-batch     9: 1.020\n",
      "Loss after mini-batch    10: 0.651\n",
      "Loss after mini-batch    11: 0.611\n",
      "Loss after mini-batch    12: 0.648\n",
      "Loss after mini-batch    13: 0.916\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.704\n",
      "Loss after mini-batch     2: 0.547\n",
      "Loss after mini-batch     3: 0.440\n",
      "Loss after mini-batch     4: 0.526\n",
      "Loss after mini-batch     5: 0.530\n",
      "Loss after mini-batch     6: 0.320\n",
      "Loss after mini-batch     7: 0.428\n",
      "Loss after mini-batch     8: 0.300\n",
      "Loss after mini-batch     9: 0.504\n",
      "Loss after mini-batch    10: 0.402\n",
      "Loss after mini-batch    11: 0.287\n",
      "Loss after mini-batch    12: 0.341\n",
      "Loss after mini-batch    13: 0.485\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.274\n",
      "Loss after mini-batch     2: 0.352\n",
      "Loss after mini-batch     3: 0.295\n",
      "Loss after mini-batch     4: 0.435\n",
      "Loss after mini-batch     5: 0.297\n",
      "Loss after mini-batch     6: 0.296\n",
      "Loss after mini-batch     7: 0.304\n",
      "Loss after mini-batch     8: 0.565\n",
      "Loss after mini-batch     9: 0.262\n",
      "Loss after mini-batch    10: 0.268\n",
      "Loss after mini-batch    11: 0.222\n",
      "Loss after mini-batch    12: 0.534\n",
      "Loss after mini-batch    13: 0.280\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.164\n",
      "Loss after mini-batch     2: 0.349\n",
      "Loss after mini-batch     3: 0.342\n",
      "Loss after mini-batch     4: 0.280\n",
      "Loss after mini-batch     5: 0.156\n",
      "Loss after mini-batch     6: 0.316\n",
      "Loss after mini-batch     7: 0.326\n",
      "Loss after mini-batch     8: 0.219\n",
      "Loss after mini-batch     9: 0.120\n",
      "Loss after mini-batch    10: 0.473\n",
      "Loss after mini-batch    11: 0.259\n",
      "Loss after mini-batch    12: 0.286\n",
      "Loss after mini-batch    13: 0.171\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.256\n",
      "Loss after mini-batch     2: 0.298\n",
      "Loss after mini-batch     3: 0.270\n",
      "Loss after mini-batch     4: 0.326\n",
      "Loss after mini-batch     5: 0.157\n",
      "Loss after mini-batch     6: 0.066\n",
      "Loss after mini-batch     7: 0.197\n",
      "Loss after mini-batch     8: 0.189\n",
      "Loss after mini-batch     9: 0.342\n",
      "Loss after mini-batch    10: 0.160\n",
      "Loss after mini-batch    11: 0.188\n",
      "Loss after mini-batch    12: 0.153\n",
      "Loss after mini-batch    13: 0.082\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.143\n",
      "Loss after mini-batch     2: 0.151\n",
      "Loss after mini-batch     3: 0.166\n",
      "Loss after mini-batch     4: 0.168\n",
      "Loss after mini-batch     5: 0.091\n",
      "Loss after mini-batch     6: 0.104\n",
      "Loss after mini-batch     7: 0.186\n",
      "Loss after mini-batch     8: 0.164\n",
      "Loss after mini-batch     9: 0.233\n",
      "Loss after mini-batch    10: 0.109\n",
      "Loss after mini-batch    11: 0.230\n",
      "Loss after mini-batch    12: 0.124\n",
      "Loss after mini-batch    13: 0.142\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.159\n",
      "Loss after mini-batch     2: 0.079\n",
      "Loss after mini-batch     3: 0.115\n",
      "Loss after mini-batch     4: 0.042\n",
      "Loss after mini-batch     5: 0.193\n",
      "Loss after mini-batch     6: 0.085\n",
      "Loss after mini-batch     7: 0.057\n",
      "Loss after mini-batch     8: 0.132\n",
      "Loss after mini-batch     9: 0.151\n",
      "Loss after mini-batch    10: 0.180\n",
      "Loss after mini-batch    11: 0.066\n",
      "Loss after mini-batch    12: 0.183\n",
      "Loss after mini-batch    13: 0.200\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.235\n",
      "Loss after mini-batch     3: 0.243\n",
      "Loss after mini-batch     4: 0.166\n",
      "Loss after mini-batch     5: 0.065\n",
      "Loss after mini-batch     6: 0.165\n",
      "Loss after mini-batch     7: 0.130\n",
      "Loss after mini-batch     8: 0.127\n",
      "Loss after mini-batch     9: 0.072\n",
      "Loss after mini-batch    10: 0.035\n",
      "Loss after mini-batch    11: 0.045\n",
      "Loss after mini-batch    12: 0.060\n",
      "Loss after mini-batch    13: 0.066\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.075\n",
      "Loss after mini-batch     2: 0.069\n",
      "Loss after mini-batch     3: 0.061\n",
      "Loss after mini-batch     4: 0.050\n",
      "Loss after mini-batch     5: 0.027\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.096\n",
      "Loss after mini-batch     8: 0.060\n",
      "Loss after mini-batch     9: 0.074\n",
      "Loss after mini-batch    10: 0.053\n",
      "Loss after mini-batch    11: 0.113\n",
      "Loss after mini-batch    12: 0.118\n",
      "Loss after mini-batch    13: 0.110\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.025\n",
      "Loss after mini-batch     2: 0.052\n",
      "Loss after mini-batch     3: 0.095\n",
      "Loss after mini-batch     4: 0.115\n",
      "Loss after mini-batch     5: 0.076\n",
      "Loss after mini-batch     6: 0.067\n",
      "Loss after mini-batch     7: 0.055\n",
      "Loss after mini-batch     8: 0.046\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.033\n",
      "Loss after mini-batch    11: 0.045\n",
      "Loss after mini-batch    12: 0.020\n",
      "Loss after mini-batch    13: 0.078\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.043\n",
      "Loss after mini-batch     2: 0.011\n",
      "Loss after mini-batch     3: 0.017\n",
      "Loss after mini-batch     4: 0.023\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.033\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.127\n",
      "Loss after mini-batch    10: 0.028\n",
      "Loss after mini-batch    11: 0.035\n",
      "Loss after mini-batch    12: 0.024\n",
      "Loss after mini-batch    13: 0.012\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.023\n",
      "Loss after mini-batch     4: 0.043\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.020\n",
      "Loss after mini-batch     7: 0.028\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.027\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.074\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch     2: 0.024\n",
      "Loss after mini-batch     3: 0.047\n",
      "Loss after mini-batch     4: 0.040\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.011\n",
      "Loss after mini-batch     8: 0.013\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.035\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.009\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.029\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.011\n",
      "Loss after mini-batch    11: 0.013\n",
      "Loss after mini-batch    12: 0.010\n",
      "Loss after mini-batch    13: 0.038\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.022\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.020\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.015\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.013\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.014\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.008\n",
      "Loss after mini-batch    13: 0.014\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.008\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.011\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.010\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.018\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.004\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 85 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.882\n",
      "Loss after mini-batch     2: 0.959\n",
      "Loss after mini-batch     3: 1.025\n",
      "Loss after mini-batch     4: 0.679\n",
      "Loss after mini-batch     5: 1.004\n",
      "Loss after mini-batch     6: 0.685\n",
      "Loss after mini-batch     7: 0.653\n",
      "Loss after mini-batch     8: 0.704\n",
      "Loss after mini-batch     9: 0.652\n",
      "Loss after mini-batch    10: 0.679\n",
      "Loss after mini-batch    11: 0.644\n",
      "Loss after mini-batch    12: 0.701\n",
      "Loss after mini-batch    13: 0.645\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.679\n",
      "Loss after mini-batch     2: 0.593\n",
      "Loss after mini-batch     3: 0.632\n",
      "Loss after mini-batch     4: 0.572\n",
      "Loss after mini-batch     5: 0.616\n",
      "Loss after mini-batch     6: 0.618\n",
      "Loss after mini-batch     7: 0.598\n",
      "Loss after mini-batch     8: 0.629\n",
      "Loss after mini-batch     9: 0.572\n",
      "Loss after mini-batch    10: 0.547\n",
      "Loss after mini-batch    11: 0.566\n",
      "Loss after mini-batch    12: 0.732\n",
      "Loss after mini-batch    13: 0.474\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.558\n",
      "Loss after mini-batch     2: 0.532\n",
      "Loss after mini-batch     3: 0.517\n",
      "Loss after mini-batch     4: 0.483\n",
      "Loss after mini-batch     5: 0.730\n",
      "Loss after mini-batch     6: 0.490\n",
      "Loss after mini-batch     7: 0.412\n",
      "Loss after mini-batch     8: 0.497\n",
      "Loss after mini-batch     9: 0.479\n",
      "Loss after mini-batch    10: 0.533\n",
      "Loss after mini-batch    11: 0.409\n",
      "Loss after mini-batch    12: 0.421\n",
      "Loss after mini-batch    13: 0.505\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.447\n",
      "Loss after mini-batch     2: 0.625\n",
      "Loss after mini-batch     3: 0.374\n",
      "Loss after mini-batch     4: 0.638\n",
      "Loss after mini-batch     5: 0.453\n",
      "Loss after mini-batch     6: 0.431\n",
      "Loss after mini-batch     7: 0.273\n",
      "Loss after mini-batch     8: 0.387\n",
      "Loss after mini-batch     9: 0.486\n",
      "Loss after mini-batch    10: 0.402\n",
      "Loss after mini-batch    11: 0.297\n",
      "Loss after mini-batch    12: 0.391\n",
      "Loss after mini-batch    13: 0.364\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.593\n",
      "Loss after mini-batch     2: 0.268\n",
      "Loss after mini-batch     3: 0.208\n",
      "Loss after mini-batch     4: 0.634\n",
      "Loss after mini-batch     5: 0.631\n",
      "Loss after mini-batch     6: 0.367\n",
      "Loss after mini-batch     7: 0.395\n",
      "Loss after mini-batch     8: 0.339\n",
      "Loss after mini-batch     9: 0.406\n",
      "Loss after mini-batch    10: 0.347\n",
      "Loss after mini-batch    11: 0.573\n",
      "Loss after mini-batch    12: 0.444\n",
      "Loss after mini-batch    13: 0.479\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.298\n",
      "Loss after mini-batch     2: 0.317\n",
      "Loss after mini-batch     3: 0.436\n",
      "Loss after mini-batch     4: 0.413\n",
      "Loss after mini-batch     5: 0.273\n",
      "Loss after mini-batch     6: 0.295\n",
      "Loss after mini-batch     7: 0.251\n",
      "Loss after mini-batch     8: 0.217\n",
      "Loss after mini-batch     9: 0.441\n",
      "Loss after mini-batch    10: 0.220\n",
      "Loss after mini-batch    11: 0.307\n",
      "Loss after mini-batch    12: 0.337\n",
      "Loss after mini-batch    13: 0.254\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.145\n",
      "Loss after mini-batch     2: 0.222\n",
      "Loss after mini-batch     3: 0.275\n",
      "Loss after mini-batch     4: 0.315\n",
      "Loss after mini-batch     5: 0.295\n",
      "Loss after mini-batch     6: 0.302\n",
      "Loss after mini-batch     7: 0.156\n",
      "Loss after mini-batch     8: 0.255\n",
      "Loss after mini-batch     9: 0.376\n",
      "Loss after mini-batch    10: 0.364\n",
      "Loss after mini-batch    11: 0.176\n",
      "Loss after mini-batch    12: 0.362\n",
      "Loss after mini-batch    13: 0.278\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.168\n",
      "Loss after mini-batch     2: 0.275\n",
      "Loss after mini-batch     3: 0.252\n",
      "Loss after mini-batch     4: 0.342\n",
      "Loss after mini-batch     5: 0.224\n",
      "Loss after mini-batch     6: 0.376\n",
      "Loss after mini-batch     7: 0.213\n",
      "Loss after mini-batch     8: 0.139\n",
      "Loss after mini-batch     9: 0.284\n",
      "Loss after mini-batch    10: 0.195\n",
      "Loss after mini-batch    11: 0.241\n",
      "Loss after mini-batch    12: 0.304\n",
      "Loss after mini-batch    13: 0.222\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.147\n",
      "Loss after mini-batch     2: 0.151\n",
      "Loss after mini-batch     3: 0.296\n",
      "Loss after mini-batch     4: 0.206\n",
      "Loss after mini-batch     5: 0.126\n",
      "Loss after mini-batch     6: 0.154\n",
      "Loss after mini-batch     7: 0.216\n",
      "Loss after mini-batch     8: 0.170\n",
      "Loss after mini-batch     9: 0.277\n",
      "Loss after mini-batch    10: 0.310\n",
      "Loss after mini-batch    11: 0.155\n",
      "Loss after mini-batch    12: 0.134\n",
      "Loss after mini-batch    13: 0.290\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.256\n",
      "Loss after mini-batch     2: 0.181\n",
      "Loss after mini-batch     3: 0.237\n",
      "Loss after mini-batch     4: 0.113\n",
      "Loss after mini-batch     5: 0.144\n",
      "Loss after mini-batch     6: 0.178\n",
      "Loss after mini-batch     7: 0.163\n",
      "Loss after mini-batch     8: 0.138\n",
      "Loss after mini-batch     9: 0.148\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.203\n",
      "Loss after mini-batch    12: 0.051\n",
      "Loss after mini-batch    13: 0.286\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.128\n",
      "Loss after mini-batch     2: 0.043\n",
      "Loss after mini-batch     3: 0.142\n",
      "Loss after mini-batch     4: 0.085\n",
      "Loss after mini-batch     5: 0.105\n",
      "Loss after mini-batch     6: 0.137\n",
      "Loss after mini-batch     7: 0.111\n",
      "Loss after mini-batch     8: 0.175\n",
      "Loss after mini-batch     9: 0.067\n",
      "Loss after mini-batch    10: 0.098\n",
      "Loss after mini-batch    11: 0.100\n",
      "Loss after mini-batch    12: 0.117\n",
      "Loss after mini-batch    13: 0.138\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.178\n",
      "Loss after mini-batch     2: 0.073\n",
      "Loss after mini-batch     3: 0.088\n",
      "Loss after mini-batch     4: 0.057\n",
      "Loss after mini-batch     5: 0.077\n",
      "Loss after mini-batch     6: 0.113\n",
      "Loss after mini-batch     7: 0.063\n",
      "Loss after mini-batch     8: 0.110\n",
      "Loss after mini-batch     9: 0.101\n",
      "Loss after mini-batch    10: 0.072\n",
      "Loss after mini-batch    11: 0.049\n",
      "Loss after mini-batch    12: 0.054\n",
      "Loss after mini-batch    13: 0.066\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.050\n",
      "Loss after mini-batch     2: 0.075\n",
      "Loss after mini-batch     3: 0.069\n",
      "Loss after mini-batch     4: 0.051\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.049\n",
      "Loss after mini-batch     7: 0.120\n",
      "Loss after mini-batch     8: 0.034\n",
      "Loss after mini-batch     9: 0.063\n",
      "Loss after mini-batch    10: 0.090\n",
      "Loss after mini-batch    11: 0.017\n",
      "Loss after mini-batch    12: 0.032\n",
      "Loss after mini-batch    13: 0.036\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.032\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.040\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.085\n",
      "Loss after mini-batch     6: 0.035\n",
      "Loss after mini-batch     7: 0.072\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.015\n",
      "Loss after mini-batch    10: 0.040\n",
      "Loss after mini-batch    11: 0.026\n",
      "Loss after mini-batch    12: 0.031\n",
      "Loss after mini-batch    13: 0.021\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.034\n",
      "Loss after mini-batch     2: 0.031\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.083\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.013\n",
      "Loss after mini-batch    10: 0.025\n",
      "Loss after mini-batch    11: 0.020\n",
      "Loss after mini-batch    12: 0.012\n",
      "Loss after mini-batch    13: 0.012\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.040\n",
      "Loss after mini-batch     3: 0.020\n",
      "Loss after mini-batch     4: 0.019\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.017\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.028\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.013\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.013\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.018\n",
      "Loss after mini-batch     3: 0.033\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.019\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.013\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.022\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.033\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.007\n",
      "Loss after mini-batch    13: 0.005\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.016\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.012\n",
      "Loss after mini-batch    13: 0.040\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.017\n",
      "Loss after mini-batch     6: 0.036\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.022\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.022\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.022\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.015\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.008\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 75 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 1.342\n",
      "Loss after mini-batch     2: 0.693\n",
      "Loss after mini-batch     3: 0.548\n",
      "Loss after mini-batch     4: 1.142\n",
      "Loss after mini-batch     5: 1.075\n",
      "Loss after mini-batch     6: 0.647\n",
      "Loss after mini-batch     7: 0.760\n",
      "Loss after mini-batch     8: 0.979\n",
      "Loss after mini-batch     9: 0.970\n",
      "Loss after mini-batch    10: 0.612\n",
      "Loss after mini-batch    11: 0.811\n",
      "Loss after mini-batch    12: 0.670\n",
      "Loss after mini-batch    13: 0.599\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.909\n",
      "Loss after mini-batch     2: 0.901\n",
      "Loss after mini-batch     3: 0.980\n",
      "Loss after mini-batch     4: 0.768\n",
      "Loss after mini-batch     5: 0.541\n",
      "Loss after mini-batch     6: 0.611\n",
      "Loss after mini-batch     7: 0.635\n",
      "Loss after mini-batch     8: 0.630\n",
      "Loss after mini-batch     9: 0.650\n",
      "Loss after mini-batch    10: 0.697\n",
      "Loss after mini-batch    11: 0.610\n",
      "Loss after mini-batch    12: 0.546\n",
      "Loss after mini-batch    13: 0.516\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.536\n",
      "Loss after mini-batch     2: 0.598\n",
      "Loss after mini-batch     3: 0.474\n",
      "Loss after mini-batch     4: 0.483\n",
      "Loss after mini-batch     5: 0.561\n",
      "Loss after mini-batch     6: 0.452\n",
      "Loss after mini-batch     7: 0.537\n",
      "Loss after mini-batch     8: 0.412\n",
      "Loss after mini-batch     9: 0.456\n",
      "Loss after mini-batch    10: 0.474\n",
      "Loss after mini-batch    11: 0.590\n",
      "Loss after mini-batch    12: 0.425\n",
      "Loss after mini-batch    13: 0.624\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.330\n",
      "Loss after mini-batch     2: 0.485\n",
      "Loss after mini-batch     3: 0.493\n",
      "Loss after mini-batch     4: 0.343\n",
      "Loss after mini-batch     5: 0.467\n",
      "Loss after mini-batch     6: 0.340\n",
      "Loss after mini-batch     7: 0.394\n",
      "Loss after mini-batch     8: 0.446\n",
      "Loss after mini-batch     9: 0.242\n",
      "Loss after mini-batch    10: 0.595\n",
      "Loss after mini-batch    11: 0.444\n",
      "Loss after mini-batch    12: 0.448\n",
      "Loss after mini-batch    13: 0.392\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.289\n",
      "Loss after mini-batch     2: 0.458\n",
      "Loss after mini-batch     3: 0.241\n",
      "Loss after mini-batch     4: 0.265\n",
      "Loss after mini-batch     5: 0.240\n",
      "Loss after mini-batch     6: 0.532\n",
      "Loss after mini-batch     7: 0.384\n",
      "Loss after mini-batch     8: 0.148\n",
      "Loss after mini-batch     9: 0.309\n",
      "Loss after mini-batch    10: 0.354\n",
      "Loss after mini-batch    11: 0.389\n",
      "Loss after mini-batch    12: 0.275\n",
      "Loss after mini-batch    13: 0.451\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.185\n",
      "Loss after mini-batch     2: 0.314\n",
      "Loss after mini-batch     3: 0.213\n",
      "Loss after mini-batch     4: 0.144\n",
      "Loss after mini-batch     5: 0.329\n",
      "Loss after mini-batch     6: 0.240\n",
      "Loss after mini-batch     7: 0.493\n",
      "Loss after mini-batch     8: 0.180\n",
      "Loss after mini-batch     9: 0.236\n",
      "Loss after mini-batch    10: 0.286\n",
      "Loss after mini-batch    11: 0.194\n",
      "Loss after mini-batch    12: 0.147\n",
      "Loss after mini-batch    13: 0.506\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.218\n",
      "Loss after mini-batch     2: 0.284\n",
      "Loss after mini-batch     3: 0.196\n",
      "Loss after mini-batch     4: 0.178\n",
      "Loss after mini-batch     5: 0.144\n",
      "Loss after mini-batch     6: 0.124\n",
      "Loss after mini-batch     7: 0.274\n",
      "Loss after mini-batch     8: 0.284\n",
      "Loss after mini-batch     9: 0.170\n",
      "Loss after mini-batch    10: 0.185\n",
      "Loss after mini-batch    11: 0.371\n",
      "Loss after mini-batch    12: 0.133\n",
      "Loss after mini-batch    13: 0.144\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.351\n",
      "Loss after mini-batch     2: 0.195\n",
      "Loss after mini-batch     3: 0.198\n",
      "Loss after mini-batch     4: 0.251\n",
      "Loss after mini-batch     5: 0.150\n",
      "Loss after mini-batch     6: 0.123\n",
      "Loss after mini-batch     7: 0.188\n",
      "Loss after mini-batch     8: 0.077\n",
      "Loss after mini-batch     9: 0.184\n",
      "Loss after mini-batch    10: 0.247\n",
      "Loss after mini-batch    11: 0.077\n",
      "Loss after mini-batch    12: 0.237\n",
      "Loss after mini-batch    13: 0.073\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.111\n",
      "Loss after mini-batch     2: 0.093\n",
      "Loss after mini-batch     3: 0.099\n",
      "Loss after mini-batch     4: 0.141\n",
      "Loss after mini-batch     5: 0.123\n",
      "Loss after mini-batch     6: 0.071\n",
      "Loss after mini-batch     7: 0.178\n",
      "Loss after mini-batch     8: 0.231\n",
      "Loss after mini-batch     9: 0.083\n",
      "Loss after mini-batch    10: 0.134\n",
      "Loss after mini-batch    11: 0.075\n",
      "Loss after mini-batch    12: 0.116\n",
      "Loss after mini-batch    13: 0.072\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.161\n",
      "Loss after mini-batch     2: 0.067\n",
      "Loss after mini-batch     3: 0.096\n",
      "Loss after mini-batch     4: 0.109\n",
      "Loss after mini-batch     5: 0.127\n",
      "Loss after mini-batch     6: 0.094\n",
      "Loss after mini-batch     7: 0.147\n",
      "Loss after mini-batch     8: 0.133\n",
      "Loss after mini-batch     9: 0.049\n",
      "Loss after mini-batch    10: 0.046\n",
      "Loss after mini-batch    11: 0.118\n",
      "Loss after mini-batch    12: 0.189\n",
      "Loss after mini-batch    13: 0.007\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.039\n",
      "Loss after mini-batch     2: 0.074\n",
      "Loss after mini-batch     3: 0.228\n",
      "Loss after mini-batch     4: 0.033\n",
      "Loss after mini-batch     5: 0.046\n",
      "Loss after mini-batch     6: 0.033\n",
      "Loss after mini-batch     7: 0.106\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.048\n",
      "Loss after mini-batch    10: 0.107\n",
      "Loss after mini-batch    11: 0.032\n",
      "Loss after mini-batch    12: 0.077\n",
      "Loss after mini-batch    13: 0.087\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.131\n",
      "Loss after mini-batch     2: 0.056\n",
      "Loss after mini-batch     3: 0.048\n",
      "Loss after mini-batch     4: 0.040\n",
      "Loss after mini-batch     5: 0.088\n",
      "Loss after mini-batch     6: 0.027\n",
      "Loss after mini-batch     7: 0.032\n",
      "Loss after mini-batch     8: 0.134\n",
      "Loss after mini-batch     9: 0.115\n",
      "Loss after mini-batch    10: 0.088\n",
      "Loss after mini-batch    11: 0.084\n",
      "Loss after mini-batch    12: 0.018\n",
      "Loss after mini-batch    13: 0.040\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.025\n",
      "Loss after mini-batch     2: 0.017\n",
      "Loss after mini-batch     3: 0.069\n",
      "Loss after mini-batch     4: 0.031\n",
      "Loss after mini-batch     5: 0.048\n",
      "Loss after mini-batch     6: 0.027\n",
      "Loss after mini-batch     7: 0.149\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.079\n",
      "Loss after mini-batch    10: 0.025\n",
      "Loss after mini-batch    11: 0.027\n",
      "Loss after mini-batch    12: 0.058\n",
      "Loss after mini-batch    13: 0.060\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.021\n",
      "Loss after mini-batch     2: 0.027\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.033\n",
      "Loss after mini-batch     5: 0.018\n",
      "Loss after mini-batch     6: 0.098\n",
      "Loss after mini-batch     7: 0.072\n",
      "Loss after mini-batch     8: 0.042\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.026\n",
      "Loss after mini-batch    11: 0.017\n",
      "Loss after mini-batch    12: 0.021\n",
      "Loss after mini-batch    13: 0.026\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.067\n",
      "Loss after mini-batch     2: 0.031\n",
      "Loss after mini-batch     3: 0.041\n",
      "Loss after mini-batch     4: 0.015\n",
      "Loss after mini-batch     5: 0.009\n",
      "Loss after mini-batch     6: 0.031\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.010\n",
      "Loss after mini-batch    11: 0.011\n",
      "Loss after mini-batch    12: 0.021\n",
      "Loss after mini-batch    13: 0.005\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.013\n",
      "Loss after mini-batch     3: 0.011\n",
      "Loss after mini-batch     4: 0.050\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.019\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.020\n",
      "Loss after mini-batch    13: 0.031\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.016\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.016\n",
      "Loss after mini-batch     5: 0.008\n",
      "Loss after mini-batch     6: 0.027\n",
      "Loss after mini-batch     7: 0.009\n",
      "Loss after mini-batch     8: 0.016\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.023\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.035\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.021\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.008\n",
      "Loss after mini-batch     6: 0.022\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.018\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.020\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.012\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.006\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.015\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.008\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.005\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Starting epoch 82\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] 액세스가 거부되었습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Iterate over the DataLoader for training data\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m   \u001b[38;5;66;03m# Get inputs\u001b[39;00m\n\u001b[0;32m    102\u001b[0m   inputs, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    103\u001b[0m   \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py310\\lib\\multiprocessing\\popen_spawn_win32.py:73\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(wfd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m to_child:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# start process\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m         hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpython_exe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m         _winapi\u001b[38;5;241m.\u001b[39mCloseHandle(ht)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] 액세스가 거부되었습니다"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 10\n",
    "  num_epochs = 100\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.097\n",
      "Loss after mini-batch     2: 0.084\n",
      "Loss after mini-batch     3: 0.076\n",
      "Loss after mini-batch     4: 0.070\n",
      "Loss after mini-batch     5: 0.194\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.029\n",
      "Loss after mini-batch     8: 0.084\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.103\n",
      "Loss after mini-batch    11: 0.091\n",
      "Loss after mini-batch    12: 0.047\n",
      "Loss after mini-batch    13: 0.002\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 75 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.049\n",
      "Loss after mini-batch     2: 0.024\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.032\n",
      "Loss after mini-batch     5: 0.029\n",
      "Loss after mini-batch     6: 0.076\n",
      "Loss after mini-batch     7: 0.073\n",
      "Loss after mini-batch     8: 0.023\n",
      "Loss after mini-batch     9: 0.049\n",
      "Loss after mini-batch    10: 0.034\n",
      "Loss after mini-batch    11: 0.038\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.042\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.015\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 85 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.175\n",
      "Loss after mini-batch     2: 0.055\n",
      "Loss after mini-batch     3: 0.213\n",
      "Loss after mini-batch     4: 0.071\n",
      "Loss after mini-batch     5: 0.060\n",
      "Loss after mini-batch     6: 0.104\n",
      "Loss after mini-batch     7: 0.074\n",
      "Loss after mini-batch     8: 0.046\n",
      "Loss after mini-batch     9: 0.082\n",
      "Loss after mini-batch    10: 0.071\n",
      "Loss after mini-batch    11: 0.102\n",
      "Loss after mini-batch    12: 0.048\n",
      "Loss after mini-batch    13: 0.103\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.025\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.031\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.002\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 82 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.086\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.030\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.025\n",
      "Loss after mini-batch     6: 0.032\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.041\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.034\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.011\n",
      "Loss after mini-batch    13: 0.025\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 78 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.023\n",
      "Loss after mini-batch     2: 0.053\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.037\n",
      "Loss after mini-batch     5: 0.028\n",
      "Loss after mini-batch     6: 0.096\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.013\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.049\n",
      "Loss after mini-batch    12: 0.071\n",
      "Loss after mini-batch    13: 0.019\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.016\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 89 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.079\n",
      "Loss after mini-batch     2: 0.073\n",
      "Loss after mini-batch     3: 0.082\n",
      "Loss after mini-batch     4: 0.051\n",
      "Loss after mini-batch     5: 0.017\n",
      "Loss after mini-batch     6: 0.054\n",
      "Loss after mini-batch     7: 0.067\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.101\n",
      "Loss after mini-batch    11: 0.033\n",
      "Loss after mini-batch    12: 0.054\n",
      "Loss after mini-batch    13: 0.050\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 5: 92 %\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.045\n",
      "Loss after mini-batch     2: 0.099\n",
      "Loss after mini-batch     3: 0.019\n",
      "Loss after mini-batch     4: 0.031\n",
      "Loss after mini-batch     5: 0.045\n",
      "Loss after mini-batch     6: 0.018\n",
      "Loss after mini-batch     7: 0.031\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.063\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.012\n",
      "Loss after mini-batch    12: 0.033\n",
      "Loss after mini-batch    13: 0.078\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 6: 89 %\n",
      "--------------------------------\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch     2: 0.035\n",
      "Loss after mini-batch     3: 0.071\n",
      "Loss after mini-batch     4: 0.048\n",
      "Loss after mini-batch     5: 0.022\n",
      "Loss after mini-batch     6: 0.030\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.046\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.036\n",
      "Loss after mini-batch    11: 0.045\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.006\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 7: 85 %\n",
      "--------------------------------\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.013\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    11: 0.010\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.028\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 8: 89 %\n",
      "--------------------------------\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(60, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.120\n",
      "Loss after mini-batch     4: 0.036\n",
      "Loss after mini-batch     5: 0.049\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.013\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.096\n",
      "Loss after mini-batch    11: 0.117\n",
      "Loss after mini-batch    12: 0.063\n",
      "Loss after mini-batch    13: 0.027\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 9: 89 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 75.0 %\n",
      "Fold 1: 85.71428571428571 %\n",
      "Fold 2: 82.14285714285714 %\n",
      "Fold 3: 78.57142857142857 %\n",
      "Fold 4: 89.28571428571429 %\n",
      "Fold 5: 92.85714285714286 %\n",
      "Fold 6: 89.28571428571429 %\n",
      "Fold 7: 85.71428571428571 %\n",
      "Fold 8: 89.28571428571429 %\n",
      "Fold 9: 89.28571428571429 %\n",
      "Average: 85.71428571428572 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 20, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 60, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(60, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 10\n",
    "  num_epochs = 20\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=20, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch%10 == 9:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0 and epoch % 10 == 9:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.784\n",
      "Loss after mini-batch     2: 0.672\n",
      "Loss after mini-batch     3: 0.675\n",
      "Loss after mini-batch     4: 0.744\n",
      "Loss after mini-batch     5: 0.653\n",
      "Loss after mini-batch     6: 0.821\n",
      "Loss after mini-batch     7: 0.847\n",
      "Loss after mini-batch     8: 0.931\n",
      "Loss after mini-batch     9: 0.938\n",
      "Loss after mini-batch    10: 0.732\n",
      "Loss after mini-batch    11: 0.577\n",
      "Loss after mini-batch    12: 0.700\n",
      "Loss after mini-batch    13: 0.666\n",
      "Loss after mini-batch    14: 0.614\n",
      "Loss after mini-batch    15: 0.524\n",
      "Loss after mini-batch    16: 0.758\n",
      "Loss after mini-batch    17: 0.538\n",
      "Loss after mini-batch    18: 0.417\n",
      "Loss after mini-batch    19: 0.688\n",
      "Loss after mini-batch    20: 0.489\n",
      "Loss after mini-batch    21: 0.665\n",
      "Loss after mini-batch    22: 0.388\n",
      "Loss after mini-batch    23: 0.792\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.480\n",
      "Loss after mini-batch     2: 0.534\n",
      "Loss after mini-batch     3: 0.398\n",
      "Loss after mini-batch     4: 0.619\n",
      "Loss after mini-batch     5: 0.312\n",
      "Loss after mini-batch     6: 0.446\n",
      "Loss after mini-batch     7: 0.241\n",
      "Loss after mini-batch     8: 0.393\n",
      "Loss after mini-batch     9: 0.395\n",
      "Loss after mini-batch    10: 0.394\n",
      "Loss after mini-batch    11: 0.296\n",
      "Loss after mini-batch    12: 0.285\n",
      "Loss after mini-batch    13: 0.451\n",
      "Loss after mini-batch    14: 0.334\n",
      "Loss after mini-batch    15: 0.542\n",
      "Loss after mini-batch    16: 0.291\n",
      "Loss after mini-batch    17: 0.275\n",
      "Loss after mini-batch    18: 0.277\n",
      "Loss after mini-batch    19: 0.574\n",
      "Loss after mini-batch    20: 0.338\n",
      "Loss after mini-batch    21: 0.481\n",
      "Loss after mini-batch    22: 0.371\n",
      "Loss after mini-batch    23: 0.439\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.145\n",
      "Loss after mini-batch     2: 0.307\n",
      "Loss after mini-batch     3: 0.559\n",
      "Loss after mini-batch     4: 0.096\n",
      "Loss after mini-batch     5: 0.243\n",
      "Loss after mini-batch     6: 0.208\n",
      "Loss after mini-batch     7: 0.246\n",
      "Loss after mini-batch     8: 0.517\n",
      "Loss after mini-batch     9: 0.396\n",
      "Loss after mini-batch    10: 0.389\n",
      "Loss after mini-batch    11: 0.147\n",
      "Loss after mini-batch    12: 0.222\n",
      "Loss after mini-batch    13: 0.166\n",
      "Loss after mini-batch    14: 0.265\n",
      "Loss after mini-batch    15: 0.298\n",
      "Loss after mini-batch    16: 0.169\n",
      "Loss after mini-batch    17: 0.192\n",
      "Loss after mini-batch    18: 0.057\n",
      "Loss after mini-batch    19: 0.278\n",
      "Loss after mini-batch    20: 0.153\n",
      "Loss after mini-batch    21: 0.097\n",
      "Loss after mini-batch    22: 0.483\n",
      "Loss after mini-batch    23: 0.413\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.067\n",
      "Loss after mini-batch     2: 0.209\n",
      "Loss after mini-batch     3: 0.147\n",
      "Loss after mini-batch     4: 0.046\n",
      "Loss after mini-batch     5: 0.224\n",
      "Loss after mini-batch     6: 0.287\n",
      "Loss after mini-batch     7: 0.104\n",
      "Loss after mini-batch     8: 0.095\n",
      "Loss after mini-batch     9: 0.145\n",
      "Loss after mini-batch    10: 0.045\n",
      "Loss after mini-batch    11: 0.142\n",
      "Loss after mini-batch    12: 0.224\n",
      "Loss after mini-batch    13: 0.311\n",
      "Loss after mini-batch    14: 0.054\n",
      "Loss after mini-batch    15: 0.080\n",
      "Loss after mini-batch    16: 0.209\n",
      "Loss after mini-batch    17: 0.312\n",
      "Loss after mini-batch    18: 0.610\n",
      "Loss after mini-batch    19: 0.129\n",
      "Loss after mini-batch    20: 0.200\n",
      "Loss after mini-batch    21: 0.084\n",
      "Loss after mini-batch    22: 0.125\n",
      "Loss after mini-batch    23: 0.122\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.180\n",
      "Loss after mini-batch     2: 0.109\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.313\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.096\n",
      "Loss after mini-batch     7: 0.071\n",
      "Loss after mini-batch     8: 0.211\n",
      "Loss after mini-batch     9: 0.153\n",
      "Loss after mini-batch    10: 0.016\n",
      "Loss after mini-batch    11: 0.135\n",
      "Loss after mini-batch    12: 0.223\n",
      "Loss after mini-batch    13: 0.026\n",
      "Loss after mini-batch    14: 0.214\n",
      "Loss after mini-batch    15: 0.039\n",
      "Loss after mini-batch    16: 0.033\n",
      "Loss after mini-batch    17: 0.127\n",
      "Loss after mini-batch    18: 0.030\n",
      "Loss after mini-batch    19: 0.040\n",
      "Loss after mini-batch    20: 0.126\n",
      "Loss after mini-batch    21: 0.032\n",
      "Loss after mini-batch    22: 0.052\n",
      "Loss after mini-batch    23: 0.175\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.178\n",
      "Loss after mini-batch     2: 0.076\n",
      "Loss after mini-batch     3: 0.017\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.137\n",
      "Loss after mini-batch     6: 0.027\n",
      "Loss after mini-batch     7: 0.024\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.090\n",
      "Loss after mini-batch    10: 0.049\n",
      "Loss after mini-batch    11: 0.102\n",
      "Loss after mini-batch    12: 0.030\n",
      "Loss after mini-batch    13: 0.048\n",
      "Loss after mini-batch    14: 0.013\n",
      "Loss after mini-batch    15: 0.047\n",
      "Loss after mini-batch    16: 0.077\n",
      "Loss after mini-batch    17: 0.052\n",
      "Loss after mini-batch    18: 0.124\n",
      "Loss after mini-batch    19: 0.021\n",
      "Loss after mini-batch    20: 0.097\n",
      "Loss after mini-batch    21: 0.034\n",
      "Loss after mini-batch    22: 0.106\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.185\n",
      "Loss after mini-batch     4: 0.041\n",
      "Loss after mini-batch     5: 0.055\n",
      "Loss after mini-batch     6: 0.102\n",
      "Loss after mini-batch     7: 0.021\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.035\n",
      "Loss after mini-batch    10: 0.145\n",
      "Loss after mini-batch    11: 0.029\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.024\n",
      "Loss after mini-batch    14: 0.040\n",
      "Loss after mini-batch    15: 0.006\n",
      "Loss after mini-batch    16: 0.040\n",
      "Loss after mini-batch    17: 0.080\n",
      "Loss after mini-batch    18: 0.023\n",
      "Loss after mini-batch    19: 0.037\n",
      "Loss after mini-batch    20: 0.009\n",
      "Loss after mini-batch    21: 0.080\n",
      "Loss after mini-batch    22: 0.008\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.105\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.012\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.030\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.107\n",
      "Loss after mini-batch    12: 0.041\n",
      "Loss after mini-batch    13: 0.014\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.034\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.135\n",
      "Loss after mini-batch    19: 0.019\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.008\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.078\n",
      "Loss after mini-batch     3: 0.041\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.070\n",
      "Loss after mini-batch    10: 0.029\n",
      "Loss after mini-batch    11: 0.029\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.018\n",
      "Loss after mini-batch    14: 0.003\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.008\n",
      "Loss after mini-batch    17: 0.061\n",
      "Loss after mini-batch    18: 0.006\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.012\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.048\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.073\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.008\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.023\n",
      "Loss after mini-batch    16: 0.068\n",
      "Loss after mini-batch    17: 0.002\n",
      "Loss after mini-batch    18: 0.004\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.007\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.044\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.076\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.027\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.038\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.005\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.021\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.028\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.022\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.061\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.024\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.028\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.059\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.009\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.054\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.013\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.037\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.028\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.017\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.011\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.026\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.017\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.005\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.012\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.005\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.003\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 89 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.753\n",
      "Loss after mini-batch     2: 0.633\n",
      "Loss after mini-batch     3: 0.317\n",
      "Loss after mini-batch     4: 2.354\n",
      "Loss after mini-batch     5: 0.586\n",
      "Loss after mini-batch     6: 1.283\n",
      "Loss after mini-batch     7: 0.972\n",
      "Loss after mini-batch     8: 0.491\n",
      "Loss after mini-batch     9: 0.920\n",
      "Loss after mini-batch    10: 0.755\n",
      "Loss after mini-batch    11: 0.683\n",
      "Loss after mini-batch    12: 0.643\n",
      "Loss after mini-batch    13: 0.949\n",
      "Loss after mini-batch    14: 0.494\n",
      "Loss after mini-batch    15: 0.773\n",
      "Loss after mini-batch    16: 0.628\n",
      "Loss after mini-batch    17: 0.653\n",
      "Loss after mini-batch    18: 0.641\n",
      "Loss after mini-batch    19: 0.582\n",
      "Loss after mini-batch    20: 0.629\n",
      "Loss after mini-batch    21: 0.593\n",
      "Loss after mini-batch    22: 0.639\n",
      "Loss after mini-batch    23: 0.513\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.555\n",
      "Loss after mini-batch     2: 0.555\n",
      "Loss after mini-batch     3: 0.620\n",
      "Loss after mini-batch     4: 0.442\n",
      "Loss after mini-batch     5: 0.504\n",
      "Loss after mini-batch     6: 0.561\n",
      "Loss after mini-batch     7: 0.500\n",
      "Loss after mini-batch     8: 0.627\n",
      "Loss after mini-batch     9: 0.440\n",
      "Loss after mini-batch    10: 0.564\n",
      "Loss after mini-batch    11: 0.544\n",
      "Loss after mini-batch    12: 0.411\n",
      "Loss after mini-batch    13: 0.563\n",
      "Loss after mini-batch    14: 0.441\n",
      "Loss after mini-batch    15: 0.534\n",
      "Loss after mini-batch    16: 0.484\n",
      "Loss after mini-batch    17: 0.553\n",
      "Loss after mini-batch    18: 0.654\n",
      "Loss after mini-batch    19: 0.465\n",
      "Loss after mini-batch    20: 0.496\n",
      "Loss after mini-batch    21: 0.393\n",
      "Loss after mini-batch    22: 0.678\n",
      "Loss after mini-batch    23: 0.513\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.348\n",
      "Loss after mini-batch     2: 0.240\n",
      "Loss after mini-batch     3: 0.321\n",
      "Loss after mini-batch     4: 0.633\n",
      "Loss after mini-batch     5: 0.435\n",
      "Loss after mini-batch     6: 0.547\n",
      "Loss after mini-batch     7: 0.282\n",
      "Loss after mini-batch     8: 0.476\n",
      "Loss after mini-batch     9: 0.601\n",
      "Loss after mini-batch    10: 0.381\n",
      "Loss after mini-batch    11: 0.541\n",
      "Loss after mini-batch    12: 0.369\n",
      "Loss after mini-batch    13: 0.319\n",
      "Loss after mini-batch    14: 0.377\n",
      "Loss after mini-batch    15: 0.130\n",
      "Loss after mini-batch    16: 0.413\n",
      "Loss after mini-batch    17: 0.303\n",
      "Loss after mini-batch    18: 0.220\n",
      "Loss after mini-batch    19: 0.236\n",
      "Loss after mini-batch    20: 0.300\n",
      "Loss after mini-batch    21: 0.690\n",
      "Loss after mini-batch    22: 0.269\n",
      "Loss after mini-batch    23: 0.342\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.296\n",
      "Loss after mini-batch     2: 0.272\n",
      "Loss after mini-batch     3: 0.339\n",
      "Loss after mini-batch     4: 0.266\n",
      "Loss after mini-batch     5: 0.465\n",
      "Loss after mini-batch     6: 0.156\n",
      "Loss after mini-batch     7: 0.319\n",
      "Loss after mini-batch     8: 0.469\n",
      "Loss after mini-batch     9: 0.194\n",
      "Loss after mini-batch    10: 0.467\n",
      "Loss after mini-batch    11: 0.499\n",
      "Loss after mini-batch    12: 0.253\n",
      "Loss after mini-batch    13: 0.391\n",
      "Loss after mini-batch    14: 0.111\n",
      "Loss after mini-batch    15: 0.334\n",
      "Loss after mini-batch    16: 0.167\n",
      "Loss after mini-batch    17: 0.397\n",
      "Loss after mini-batch    18: 0.236\n",
      "Loss after mini-batch    19: 0.103\n",
      "Loss after mini-batch    20: 0.410\n",
      "Loss after mini-batch    21: 0.281\n",
      "Loss after mini-batch    22: 0.373\n",
      "Loss after mini-batch    23: 0.112\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.140\n",
      "Loss after mini-batch     2: 0.300\n",
      "Loss after mini-batch     3: 0.169\n",
      "Loss after mini-batch     4: 0.156\n",
      "Loss after mini-batch     5: 0.338\n",
      "Loss after mini-batch     6: 0.055\n",
      "Loss after mini-batch     7: 0.124\n",
      "Loss after mini-batch     8: 0.229\n",
      "Loss after mini-batch     9: 0.321\n",
      "Loss after mini-batch    10: 0.138\n",
      "Loss after mini-batch    11: 0.560\n",
      "Loss after mini-batch    12: 0.098\n",
      "Loss after mini-batch    13: 0.199\n",
      "Loss after mini-batch    14: 0.254\n",
      "Loss after mini-batch    15: 0.284\n",
      "Loss after mini-batch    16: 0.042\n",
      "Loss after mini-batch    17: 0.283\n",
      "Loss after mini-batch    18: 0.084\n",
      "Loss after mini-batch    19: 0.506\n",
      "Loss after mini-batch    20: 0.445\n",
      "Loss after mini-batch    21: 0.007\n",
      "Loss after mini-batch    22: 0.194\n",
      "Loss after mini-batch    23: 0.246\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.109\n",
      "Loss after mini-batch     2: 0.110\n",
      "Loss after mini-batch     3: 0.193\n",
      "Loss after mini-batch     4: 0.115\n",
      "Loss after mini-batch     5: 0.144\n",
      "Loss after mini-batch     6: 0.060\n",
      "Loss after mini-batch     7: 0.233\n",
      "Loss after mini-batch     8: 0.124\n",
      "Loss after mini-batch     9: 0.199\n",
      "Loss after mini-batch    10: 0.388\n",
      "Loss after mini-batch    11: 0.293\n",
      "Loss after mini-batch    12: 0.077\n",
      "Loss after mini-batch    13: 0.299\n",
      "Loss after mini-batch    14: 0.238\n",
      "Loss after mini-batch    15: 0.021\n",
      "Loss after mini-batch    16: 0.080\n",
      "Loss after mini-batch    17: 0.330\n",
      "Loss after mini-batch    18: 0.394\n",
      "Loss after mini-batch    19: 0.254\n",
      "Loss after mini-batch    20: 0.087\n",
      "Loss after mini-batch    21: 0.030\n",
      "Loss after mini-batch    22: 0.216\n",
      "Loss after mini-batch    23: 0.062\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.287\n",
      "Loss after mini-batch     2: 0.059\n",
      "Loss after mini-batch     3: 0.227\n",
      "Loss after mini-batch     4: 0.208\n",
      "Loss after mini-batch     5: 0.103\n",
      "Loss after mini-batch     6: 0.173\n",
      "Loss after mini-batch     7: 0.054\n",
      "Loss after mini-batch     8: 0.105\n",
      "Loss after mini-batch     9: 0.229\n",
      "Loss after mini-batch    10: 0.076\n",
      "Loss after mini-batch    11: 0.187\n",
      "Loss after mini-batch    12: 0.086\n",
      "Loss after mini-batch    13: 0.213\n",
      "Loss after mini-batch    14: 0.597\n",
      "Loss after mini-batch    15: 0.151\n",
      "Loss after mini-batch    16: 0.057\n",
      "Loss after mini-batch    17: 0.482\n",
      "Loss after mini-batch    18: 0.137\n",
      "Loss after mini-batch    19: 0.387\n",
      "Loss after mini-batch    20: 0.016\n",
      "Loss after mini-batch    21: 0.045\n",
      "Loss after mini-batch    22: 0.015\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.250\n",
      "Loss after mini-batch     3: 0.055\n",
      "Loss after mini-batch     4: 0.090\n",
      "Loss after mini-batch     5: 0.205\n",
      "Loss after mini-batch     6: 0.140\n",
      "Loss after mini-batch     7: 0.162\n",
      "Loss after mini-batch     8: 0.022\n",
      "Loss after mini-batch     9: 0.063\n",
      "Loss after mini-batch    10: 0.114\n",
      "Loss after mini-batch    11: 0.099\n",
      "Loss after mini-batch    12: 0.026\n",
      "Loss after mini-batch    13: 0.147\n",
      "Loss after mini-batch    14: 0.097\n",
      "Loss after mini-batch    15: 0.052\n",
      "Loss after mini-batch    16: 0.089\n",
      "Loss after mini-batch    17: 0.051\n",
      "Loss after mini-batch    18: 0.046\n",
      "Loss after mini-batch    19: 0.023\n",
      "Loss after mini-batch    20: 0.268\n",
      "Loss after mini-batch    21: 0.025\n",
      "Loss after mini-batch    22: 0.038\n",
      "Loss after mini-batch    23: 0.013\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.078\n",
      "Loss after mini-batch     2: 0.060\n",
      "Loss after mini-batch     3: 0.042\n",
      "Loss after mini-batch     4: 0.147\n",
      "Loss after mini-batch     5: 0.027\n",
      "Loss after mini-batch     6: 0.039\n",
      "Loss after mini-batch     7: 0.027\n",
      "Loss after mini-batch     8: 0.052\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.045\n",
      "Loss after mini-batch    11: 0.071\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.016\n",
      "Loss after mini-batch    14: 0.041\n",
      "Loss after mini-batch    15: 0.169\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.082\n",
      "Loss after mini-batch    18: 0.016\n",
      "Loss after mini-batch    19: 0.023\n",
      "Loss after mini-batch    20: 0.018\n",
      "Loss after mini-batch    21: 0.020\n",
      "Loss after mini-batch    22: 0.031\n",
      "Loss after mini-batch    23: 0.172\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.023\n",
      "Loss after mini-batch     2: 0.042\n",
      "Loss after mini-batch     3: 0.018\n",
      "Loss after mini-batch     4: 0.027\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.022\n",
      "Loss after mini-batch     7: 0.048\n",
      "Loss after mini-batch     8: 0.061\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.037\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.051\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.056\n",
      "Loss after mini-batch    16: 0.035\n",
      "Loss after mini-batch    17: 0.073\n",
      "Loss after mini-batch    18: 0.060\n",
      "Loss after mini-batch    19: 0.006\n",
      "Loss after mini-batch    20: 0.026\n",
      "Loss after mini-batch    21: 0.013\n",
      "Loss after mini-batch    22: 0.025\n",
      "Loss after mini-batch    23: 0.011\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.026\n",
      "Loss after mini-batch     3: 0.018\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.026\n",
      "Loss after mini-batch    11: 0.056\n",
      "Loss after mini-batch    12: 0.057\n",
      "Loss after mini-batch    13: 0.005\n",
      "Loss after mini-batch    14: 0.008\n",
      "Loss after mini-batch    15: 0.055\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.007\n",
      "Loss after mini-batch    18: 0.011\n",
      "Loss after mini-batch    19: 0.023\n",
      "Loss after mini-batch    20: 0.024\n",
      "Loss after mini-batch    21: 0.012\n",
      "Loss after mini-batch    22: 0.066\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.017\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.019\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.095\n",
      "Loss after mini-batch    12: 0.007\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.034\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.044\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.005\n",
      "Loss after mini-batch    19: 0.004\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.014\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.067\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.007\n",
      "Loss after mini-batch    12: 0.033\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.019\n",
      "Loss after mini-batch    16: 0.041\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.012\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.049\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.033\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.021\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.008\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.011\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.021\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.047\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.021\n",
      "Loss after mini-batch    17: 0.004\n",
      "Loss after mini-batch    18: 0.008\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.021\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.007\n",
      "Loss after mini-batch    17: 0.015\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.039\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.018\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.029\n",
      "Loss after mini-batch    18: 0.013\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.018\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.017\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.010\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.003\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.009\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.020\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.008\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.011\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.007\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.010\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.006\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.014\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.007\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.008\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.005\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.007\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.006\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 87 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.710\n",
      "Loss after mini-batch     2: 2.025\n",
      "Loss after mini-batch     3: 0.888\n",
      "Loss after mini-batch     4: 0.707\n",
      "Loss after mini-batch     5: 0.840\n",
      "Loss after mini-batch     6: 0.858\n",
      "Loss after mini-batch     7: 0.833\n",
      "Loss after mini-batch     8: 0.663\n",
      "Loss after mini-batch     9: 0.679\n",
      "Loss after mini-batch    10: 0.710\n",
      "Loss after mini-batch    11: 0.660\n",
      "Loss after mini-batch    12: 0.539\n",
      "Loss after mini-batch    13: 0.814\n",
      "Loss after mini-batch    14: 0.689\n",
      "Loss after mini-batch    15: 0.724\n",
      "Loss after mini-batch    16: 0.791\n",
      "Loss after mini-batch    17: 0.687\n",
      "Loss after mini-batch    18: 0.696\n",
      "Loss after mini-batch    19: 0.589\n",
      "Loss after mini-batch    20: 0.892\n",
      "Loss after mini-batch    21: 0.504\n",
      "Loss after mini-batch    22: 0.561\n",
      "Loss after mini-batch    23: 0.607\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.547\n",
      "Loss after mini-batch     2: 0.652\n",
      "Loss after mini-batch     3: 0.514\n",
      "Loss after mini-batch     4: 0.438\n",
      "Loss after mini-batch     5: 0.503\n",
      "Loss after mini-batch     6: 0.432\n",
      "Loss after mini-batch     7: 0.665\n",
      "Loss after mini-batch     8: 0.431\n",
      "Loss after mini-batch     9: 0.403\n",
      "Loss after mini-batch    10: 0.528\n",
      "Loss after mini-batch    11: 0.701\n",
      "Loss after mini-batch    12: 0.499\n",
      "Loss after mini-batch    13: 0.343\n",
      "Loss after mini-batch    14: 0.425\n",
      "Loss after mini-batch    15: 0.503\n",
      "Loss after mini-batch    16: 0.160\n",
      "Loss after mini-batch    17: 0.952\n",
      "Loss after mini-batch    18: 0.559\n",
      "Loss after mini-batch    19: 0.428\n",
      "Loss after mini-batch    20: 0.767\n",
      "Loss after mini-batch    21: 0.325\n",
      "Loss after mini-batch    22: 0.351\n",
      "Loss after mini-batch    23: 0.144\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.302\n",
      "Loss after mini-batch     2: 0.835\n",
      "Loss after mini-batch     3: 0.498\n",
      "Loss after mini-batch     4: 0.365\n",
      "Loss after mini-batch     5: 0.447\n",
      "Loss after mini-batch     6: 0.381\n",
      "Loss after mini-batch     7: 0.479\n",
      "Loss after mini-batch     8: 0.516\n",
      "Loss after mini-batch     9: 0.092\n",
      "Loss after mini-batch    10: 0.360\n",
      "Loss after mini-batch    11: 0.548\n",
      "Loss after mini-batch    12: 0.425\n",
      "Loss after mini-batch    13: 0.461\n",
      "Loss after mini-batch    14: 0.309\n",
      "Loss after mini-batch    15: 0.228\n",
      "Loss after mini-batch    16: 0.188\n",
      "Loss after mini-batch    17: 0.183\n",
      "Loss after mini-batch    18: 0.210\n",
      "Loss after mini-batch    19: 0.329\n",
      "Loss after mini-batch    20: 0.587\n",
      "Loss after mini-batch    21: 0.120\n",
      "Loss after mini-batch    22: 0.259\n",
      "Loss after mini-batch    23: 0.189\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.066\n",
      "Loss after mini-batch     2: 0.372\n",
      "Loss after mini-batch     3: 0.133\n",
      "Loss after mini-batch     4: 0.272\n",
      "Loss after mini-batch     5: 0.225\n",
      "Loss after mini-batch     6: 0.244\n",
      "Loss after mini-batch     7: 0.173\n",
      "Loss after mini-batch     8: 0.334\n",
      "Loss after mini-batch     9: 0.566\n",
      "Loss after mini-batch    10: 0.049\n",
      "Loss after mini-batch    11: 0.315\n",
      "Loss after mini-batch    12: 0.335\n",
      "Loss after mini-batch    13: 0.417\n",
      "Loss after mini-batch    14: 0.450\n",
      "Loss after mini-batch    15: 0.218\n",
      "Loss after mini-batch    16: 0.384\n",
      "Loss after mini-batch    17: 0.198\n",
      "Loss after mini-batch    18: 0.593\n",
      "Loss after mini-batch    19: 0.271\n",
      "Loss after mini-batch    20: 0.229\n",
      "Loss after mini-batch    21: 0.200\n",
      "Loss after mini-batch    22: 0.344\n",
      "Loss after mini-batch    23: 0.490\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.215\n",
      "Loss after mini-batch     2: 0.171\n",
      "Loss after mini-batch     3: 0.239\n",
      "Loss after mini-batch     4: 0.472\n",
      "Loss after mini-batch     5: 0.438\n",
      "Loss after mini-batch     6: 0.102\n",
      "Loss after mini-batch     7: 0.108\n",
      "Loss after mini-batch     8: 0.108\n",
      "Loss after mini-batch     9: 0.263\n",
      "Loss after mini-batch    10: 0.243\n",
      "Loss after mini-batch    11: 0.082\n",
      "Loss after mini-batch    12: 0.119\n",
      "Loss after mini-batch    13: 0.172\n",
      "Loss after mini-batch    14: 0.338\n",
      "Loss after mini-batch    15: 0.120\n",
      "Loss after mini-batch    16: 0.041\n",
      "Loss after mini-batch    17: 0.215\n",
      "Loss after mini-batch    18: 0.306\n",
      "Loss after mini-batch    19: 0.012\n",
      "Loss after mini-batch    20: 0.406\n",
      "Loss after mini-batch    21: 0.022\n",
      "Loss after mini-batch    22: 0.240\n",
      "Loss after mini-batch    23: 0.096\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.065\n",
      "Loss after mini-batch     2: 0.044\n",
      "Loss after mini-batch     3: 0.122\n",
      "Loss after mini-batch     4: 0.177\n",
      "Loss after mini-batch     5: 0.044\n",
      "Loss after mini-batch     6: 0.149\n",
      "Loss after mini-batch     7: 0.070\n",
      "Loss after mini-batch     8: 0.226\n",
      "Loss after mini-batch     9: 0.118\n",
      "Loss after mini-batch    10: 0.092\n",
      "Loss after mini-batch    11: 0.029\n",
      "Loss after mini-batch    12: 0.317\n",
      "Loss after mini-batch    13: 0.012\n",
      "Loss after mini-batch    14: 0.109\n",
      "Loss after mini-batch    15: 0.352\n",
      "Loss after mini-batch    16: 0.153\n",
      "Loss after mini-batch    17: 0.032\n",
      "Loss after mini-batch    18: 0.119\n",
      "Loss after mini-batch    19: 0.182\n",
      "Loss after mini-batch    20: 0.124\n",
      "Loss after mini-batch    21: 0.170\n",
      "Loss after mini-batch    22: 0.112\n",
      "Loss after mini-batch    23: 0.069\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.046\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.024\n",
      "Loss after mini-batch     4: 0.306\n",
      "Loss after mini-batch     5: 0.303\n",
      "Loss after mini-batch     6: 0.039\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.066\n",
      "Loss after mini-batch     9: 0.034\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.128\n",
      "Loss after mini-batch    12: 0.083\n",
      "Loss after mini-batch    13: 0.027\n",
      "Loss after mini-batch    14: 0.049\n",
      "Loss after mini-batch    15: 0.102\n",
      "Loss after mini-batch    16: 0.098\n",
      "Loss after mini-batch    17: 0.094\n",
      "Loss after mini-batch    18: 0.052\n",
      "Loss after mini-batch    19: 0.053\n",
      "Loss after mini-batch    20: 0.044\n",
      "Loss after mini-batch    21: 0.234\n",
      "Loss after mini-batch    22: 0.048\n",
      "Loss after mini-batch    23: 0.044\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.025\n",
      "Loss after mini-batch     2: 0.215\n",
      "Loss after mini-batch     3: 0.067\n",
      "Loss after mini-batch     4: 0.025\n",
      "Loss after mini-batch     5: 0.128\n",
      "Loss after mini-batch     6: 0.017\n",
      "Loss after mini-batch     7: 0.055\n",
      "Loss after mini-batch     8: 0.064\n",
      "Loss after mini-batch     9: 0.017\n",
      "Loss after mini-batch    10: 0.029\n",
      "Loss after mini-batch    11: 0.030\n",
      "Loss after mini-batch    12: 0.024\n",
      "Loss after mini-batch    13: 0.019\n",
      "Loss after mini-batch    14: 0.029\n",
      "Loss after mini-batch    15: 0.024\n",
      "Loss after mini-batch    16: 0.195\n",
      "Loss after mini-batch    17: 0.066\n",
      "Loss after mini-batch    18: 0.040\n",
      "Loss after mini-batch    19: 0.007\n",
      "Loss after mini-batch    20: 0.014\n",
      "Loss after mini-batch    21: 0.070\n",
      "Loss after mini-batch    22: 0.029\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.013\n",
      "Loss after mini-batch     4: 0.062\n",
      "Loss after mini-batch     5: 0.019\n",
      "Loss after mini-batch     6: 0.043\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.074\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.070\n",
      "Loss after mini-batch    11: 0.019\n",
      "Loss after mini-batch    12: 0.025\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.163\n",
      "Loss after mini-batch    15: 0.007\n",
      "Loss after mini-batch    16: 0.167\n",
      "Loss after mini-batch    17: 0.025\n",
      "Loss after mini-batch    18: 0.025\n",
      "Loss after mini-batch    19: 0.043\n",
      "Loss after mini-batch    20: 0.107\n",
      "Loss after mini-batch    21: 0.011\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.004\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.043\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.026\n",
      "Loss after mini-batch     5: 0.015\n",
      "Loss after mini-batch     6: 0.013\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.063\n",
      "Loss after mini-batch     9: 0.012\n",
      "Loss after mini-batch    10: 0.017\n",
      "Loss after mini-batch    11: 0.182\n",
      "Loss after mini-batch    12: 0.014\n",
      "Loss after mini-batch    13: 0.035\n",
      "Loss after mini-batch    14: 0.007\n",
      "Loss after mini-batch    15: 0.039\n",
      "Loss after mini-batch    16: 0.016\n",
      "Loss after mini-batch    17: 0.044\n",
      "Loss after mini-batch    18: 0.015\n",
      "Loss after mini-batch    19: 0.052\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    21: 0.019\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.017\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.022\n",
      "Loss after mini-batch     2: 0.016\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.017\n",
      "Loss after mini-batch     5: 0.015\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.011\n",
      "Loss after mini-batch    11: 0.042\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.015\n",
      "Loss after mini-batch    14: 0.011\n",
      "Loss after mini-batch    15: 0.032\n",
      "Loss after mini-batch    16: 0.014\n",
      "Loss after mini-batch    17: 0.011\n",
      "Loss after mini-batch    18: 0.009\n",
      "Loss after mini-batch    19: 0.034\n",
      "Loss after mini-batch    20: 0.193\n",
      "Loss after mini-batch    21: 0.010\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.004\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.017\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.123\n",
      "Loss after mini-batch     8: 0.012\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.025\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.016\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.018\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.009\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.014\n",
      "Loss after mini-batch    21: 0.014\n",
      "Loss after mini-batch    22: 0.018\n",
      "Loss after mini-batch    23: 0.015\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.139\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.011\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.005\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.007\n",
      "Loss after mini-batch    18: 0.027\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.015\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.003\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.016\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.004\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.085\n",
      "Loss after mini-batch    19: 0.003\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.013\n",
      "Loss after mini-batch    22: 0.009\n",
      "Loss after mini-batch    23: 0.009\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.057\n",
      "Loss after mini-batch    16: 0.004\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.012\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.007\n",
      "Loss after mini-batch    12: 0.034\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.009\n",
      "Loss after mini-batch    16: 0.008\n",
      "Loss after mini-batch    17: 0.002\n",
      "Loss after mini-batch    18: 0.006\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.010\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.024\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.003\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.012\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.023\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.004\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.004\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.012\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.003\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.004\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.009\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.004\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 83 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 1.894\n",
      "Loss after mini-batch     2: 4.707\n",
      "Loss after mini-batch     3: 3.331\n",
      "Loss after mini-batch     4: 2.660\n",
      "Loss after mini-batch     5: 1.939\n",
      "Loss after mini-batch     6: 1.226\n",
      "Loss after mini-batch     7: 1.318\n",
      "Loss after mini-batch     8: 0.939\n",
      "Loss after mini-batch     9: 0.787\n",
      "Loss after mini-batch    10: 0.646\n",
      "Loss after mini-batch    11: 0.721\n",
      "Loss after mini-batch    12: 0.692\n",
      "Loss after mini-batch    13: 0.725\n",
      "Loss after mini-batch    14: 0.696\n",
      "Loss after mini-batch    15: 0.746\n",
      "Loss after mini-batch    16: 0.692\n",
      "Loss after mini-batch    17: 0.698\n",
      "Loss after mini-batch    18: 0.703\n",
      "Loss after mini-batch    19: 0.740\n",
      "Loss after mini-batch    20: 0.673\n",
      "Loss after mini-batch    21: 0.682\n",
      "Loss after mini-batch    22: 0.712\n",
      "Loss after mini-batch    23: 0.696\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.685\n",
      "Loss after mini-batch     2: 0.682\n",
      "Loss after mini-batch     3: 0.662\n",
      "Loss after mini-batch     4: 0.723\n",
      "Loss after mini-batch     5: 0.685\n",
      "Loss after mini-batch     6: 0.691\n",
      "Loss after mini-batch     7: 0.675\n",
      "Loss after mini-batch     8: 0.800\n",
      "Loss after mini-batch     9: 0.662\n",
      "Loss after mini-batch    10: 0.644\n",
      "Loss after mini-batch    11: 0.660\n",
      "Loss after mini-batch    12: 0.683\n",
      "Loss after mini-batch    13: 0.706\n",
      "Loss after mini-batch    14: 0.625\n",
      "Loss after mini-batch    15: 0.631\n",
      "Loss after mini-batch    16: 0.713\n",
      "Loss after mini-batch    17: 0.677\n",
      "Loss after mini-batch    18: 0.620\n",
      "Loss after mini-batch    19: 0.691\n",
      "Loss after mini-batch    20: 0.674\n",
      "Loss after mini-batch    21: 0.636\n",
      "Loss after mini-batch    22: 0.675\n",
      "Loss after mini-batch    23: 0.832\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.660\n",
      "Loss after mini-batch     2: 0.744\n",
      "Loss after mini-batch     3: 0.659\n",
      "Loss after mini-batch     4: 0.643\n",
      "Loss after mini-batch     5: 0.655\n",
      "Loss after mini-batch     6: 0.719\n",
      "Loss after mini-batch     7: 0.566\n",
      "Loss after mini-batch     8: 0.560\n",
      "Loss after mini-batch     9: 0.563\n",
      "Loss after mini-batch    10: 0.624\n",
      "Loss after mini-batch    11: 0.984\n",
      "Loss after mini-batch    12: 0.604\n",
      "Loss after mini-batch    13: 0.609\n",
      "Loss after mini-batch    14: 0.612\n",
      "Loss after mini-batch    15: 0.695\n",
      "Loss after mini-batch    16: 0.629\n",
      "Loss after mini-batch    17: 0.601\n",
      "Loss after mini-batch    18: 0.615\n",
      "Loss after mini-batch    19: 0.678\n",
      "Loss after mini-batch    20: 0.698\n",
      "Loss after mini-batch    21: 0.767\n",
      "Loss after mini-batch    22: 0.587\n",
      "Loss after mini-batch    23: 0.557\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.671\n",
      "Loss after mini-batch     2: 0.666\n",
      "Loss after mini-batch     3: 0.643\n",
      "Loss after mini-batch     4: 0.568\n",
      "Loss after mini-batch     5: 0.562\n",
      "Loss after mini-batch     6: 0.596\n",
      "Loss after mini-batch     7: 0.577\n",
      "Loss after mini-batch     8: 0.512\n",
      "Loss after mini-batch     9: 0.669\n",
      "Loss after mini-batch    10: 0.516\n",
      "Loss after mini-batch    11: 0.488\n",
      "Loss after mini-batch    12: 0.537\n",
      "Loss after mini-batch    13: 0.590\n",
      "Loss after mini-batch    14: 0.574\n",
      "Loss after mini-batch    15: 0.489\n",
      "Loss after mini-batch    16: 0.493\n",
      "Loss after mini-batch    17: 0.504\n",
      "Loss after mini-batch    18: 0.454\n",
      "Loss after mini-batch    19: 0.505\n",
      "Loss after mini-batch    20: 0.315\n",
      "Loss after mini-batch    21: 0.699\n",
      "Loss after mini-batch    22: 0.551\n",
      "Loss after mini-batch    23: 0.427\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.395\n",
      "Loss after mini-batch     2: 0.331\n",
      "Loss after mini-batch     3: 0.568\n",
      "Loss after mini-batch     4: 0.397\n",
      "Loss after mini-batch     5: 0.392\n",
      "Loss after mini-batch     6: 0.401\n",
      "Loss after mini-batch     7: 0.348\n",
      "Loss after mini-batch     8: 0.501\n",
      "Loss after mini-batch     9: 0.483\n",
      "Loss after mini-batch    10: 0.308\n",
      "Loss after mini-batch    11: 0.447\n",
      "Loss after mini-batch    12: 0.373\n",
      "Loss after mini-batch    13: 0.333\n",
      "Loss after mini-batch    14: 0.426\n",
      "Loss after mini-batch    15: 0.372\n",
      "Loss after mini-batch    16: 0.406\n",
      "Loss after mini-batch    17: 0.426\n",
      "Loss after mini-batch    18: 0.432\n",
      "Loss after mini-batch    19: 0.447\n",
      "Loss after mini-batch    20: 0.341\n",
      "Loss after mini-batch    21: 0.246\n",
      "Loss after mini-batch    22: 0.419\n",
      "Loss after mini-batch    23: 0.112\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.475\n",
      "Loss after mini-batch     2: 0.361\n",
      "Loss after mini-batch     3: 0.278\n",
      "Loss after mini-batch     4: 0.290\n",
      "Loss after mini-batch     5: 0.449\n",
      "Loss after mini-batch     6: 0.521\n",
      "Loss after mini-batch     7: 0.355\n",
      "Loss after mini-batch     8: 0.184\n",
      "Loss after mini-batch     9: 0.413\n",
      "Loss after mini-batch    10: 0.424\n",
      "Loss after mini-batch    11: 0.181\n",
      "Loss after mini-batch    12: 0.153\n",
      "Loss after mini-batch    13: 0.316\n",
      "Loss after mini-batch    14: 0.337\n",
      "Loss after mini-batch    15: 0.130\n",
      "Loss after mini-batch    16: 0.241\n",
      "Loss after mini-batch    17: 0.334\n",
      "Loss after mini-batch    18: 0.245\n",
      "Loss after mini-batch    19: 0.208\n",
      "Loss after mini-batch    20: 0.320\n",
      "Loss after mini-batch    21: 0.174\n",
      "Loss after mini-batch    22: 0.122\n",
      "Loss after mini-batch    23: 0.047\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.308\n",
      "Loss after mini-batch     2: 0.077\n",
      "Loss after mini-batch     3: 0.153\n",
      "Loss after mini-batch     4: 0.247\n",
      "Loss after mini-batch     5: 0.510\n",
      "Loss after mini-batch     6: 0.450\n",
      "Loss after mini-batch     7: 0.155\n",
      "Loss after mini-batch     8: 0.229\n",
      "Loss after mini-batch     9: 0.371\n",
      "Loss after mini-batch    10: 0.199\n",
      "Loss after mini-batch    11: 0.356\n",
      "Loss after mini-batch    12: 0.298\n",
      "Loss after mini-batch    13: 0.202\n",
      "Loss after mini-batch    14: 0.125\n",
      "Loss after mini-batch    15: 0.266\n",
      "Loss after mini-batch    16: 0.258\n",
      "Loss after mini-batch    17: 0.075\n",
      "Loss after mini-batch    18: 0.166\n",
      "Loss after mini-batch    19: 0.268\n",
      "Loss after mini-batch    20: 0.212\n",
      "Loss after mini-batch    21: 0.196\n",
      "Loss after mini-batch    22: 0.241\n",
      "Loss after mini-batch    23: 0.019\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.376\n",
      "Loss after mini-batch     2: 0.374\n",
      "Loss after mini-batch     3: 0.172\n",
      "Loss after mini-batch     4: 0.227\n",
      "Loss after mini-batch     5: 0.190\n",
      "Loss after mini-batch     6: 0.063\n",
      "Loss after mini-batch     7: 0.621\n",
      "Loss after mini-batch     8: 0.229\n",
      "Loss after mini-batch     9: 0.150\n",
      "Loss after mini-batch    10: 0.107\n",
      "Loss after mini-batch    11: 0.180\n",
      "Loss after mini-batch    12: 0.172\n",
      "Loss after mini-batch    13: 0.265\n",
      "Loss after mini-batch    14: 0.142\n",
      "Loss after mini-batch    15: 0.117\n",
      "Loss after mini-batch    16: 0.226\n",
      "Loss after mini-batch    17: 0.108\n",
      "Loss after mini-batch    18: 0.091\n",
      "Loss after mini-batch    19: 0.148\n",
      "Loss after mini-batch    20: 0.097\n",
      "Loss after mini-batch    21: 0.094\n",
      "Loss after mini-batch    22: 0.174\n",
      "Loss after mini-batch    23: 0.050\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.108\n",
      "Loss after mini-batch     2: 0.187\n",
      "Loss after mini-batch     3: 0.221\n",
      "Loss after mini-batch     4: 0.176\n",
      "Loss after mini-batch     5: 0.275\n",
      "Loss after mini-batch     6: 0.104\n",
      "Loss after mini-batch     7: 0.109\n",
      "Loss after mini-batch     8: 0.019\n",
      "Loss after mini-batch     9: 0.222\n",
      "Loss after mini-batch    10: 0.091\n",
      "Loss after mini-batch    11: 0.123\n",
      "Loss after mini-batch    12: 0.191\n",
      "Loss after mini-batch    13: 0.214\n",
      "Loss after mini-batch    14: 0.048\n",
      "Loss after mini-batch    15: 0.019\n",
      "Loss after mini-batch    16: 0.040\n",
      "Loss after mini-batch    17: 0.184\n",
      "Loss after mini-batch    18: 0.434\n",
      "Loss after mini-batch    19: 0.039\n",
      "Loss after mini-batch    20: 0.206\n",
      "Loss after mini-batch    21: 0.070\n",
      "Loss after mini-batch    22: 0.160\n",
      "Loss after mini-batch    23: 0.033\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.139\n",
      "Loss after mini-batch     2: 0.259\n",
      "Loss after mini-batch     3: 0.062\n",
      "Loss after mini-batch     4: 0.170\n",
      "Loss after mini-batch     5: 0.125\n",
      "Loss after mini-batch     6: 0.112\n",
      "Loss after mini-batch     7: 0.042\n",
      "Loss after mini-batch     8: 0.079\n",
      "Loss after mini-batch     9: 0.120\n",
      "Loss after mini-batch    10: 0.123\n",
      "Loss after mini-batch    11: 0.044\n",
      "Loss after mini-batch    12: 0.292\n",
      "Loss after mini-batch    13: 0.165\n",
      "Loss after mini-batch    14: 0.137\n",
      "Loss after mini-batch    15: 0.089\n",
      "Loss after mini-batch    16: 0.133\n",
      "Loss after mini-batch    17: 0.096\n",
      "Loss after mini-batch    18: 0.103\n",
      "Loss after mini-batch    19: 0.032\n",
      "Loss after mini-batch    20: 0.240\n",
      "Loss after mini-batch    21: 0.073\n",
      "Loss after mini-batch    22: 0.300\n",
      "Loss after mini-batch    23: 0.072\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.031\n",
      "Loss after mini-batch     2: 0.106\n",
      "Loss after mini-batch     3: 0.082\n",
      "Loss after mini-batch     4: 0.062\n",
      "Loss after mini-batch     5: 0.230\n",
      "Loss after mini-batch     6: 0.099\n",
      "Loss after mini-batch     7: 0.134\n",
      "Loss after mini-batch     8: 0.048\n",
      "Loss after mini-batch     9: 0.028\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.102\n",
      "Loss after mini-batch    13: 0.032\n",
      "Loss after mini-batch    14: 0.062\n",
      "Loss after mini-batch    15: 0.007\n",
      "Loss after mini-batch    16: 0.020\n",
      "Loss after mini-batch    17: 0.138\n",
      "Loss after mini-batch    18: 0.066\n",
      "Loss after mini-batch    19: 0.075\n",
      "Loss after mini-batch    20: 0.076\n",
      "Loss after mini-batch    21: 0.056\n",
      "Loss after mini-batch    22: 0.084\n",
      "Loss after mini-batch    23: 0.031\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.064\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.038\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.096\n",
      "Loss after mini-batch     6: 0.024\n",
      "Loss after mini-batch     7: 0.053\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.074\n",
      "Loss after mini-batch    11: 0.034\n",
      "Loss after mini-batch    12: 0.079\n",
      "Loss after mini-batch    13: 0.058\n",
      "Loss after mini-batch    14: 0.036\n",
      "Loss after mini-batch    15: 0.049\n",
      "Loss after mini-batch    16: 0.088\n",
      "Loss after mini-batch    17: 0.146\n",
      "Loss after mini-batch    18: 0.007\n",
      "Loss after mini-batch    19: 0.052\n",
      "Loss after mini-batch    20: 0.082\n",
      "Loss after mini-batch    21: 0.027\n",
      "Loss after mini-batch    22: 0.129\n",
      "Loss after mini-batch    23: 0.075\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.028\n",
      "Loss after mini-batch     2: 0.057\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.034\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.042\n",
      "Loss after mini-batch     7: 0.009\n",
      "Loss after mini-batch     8: 0.041\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.016\n",
      "Loss after mini-batch    11: 0.128\n",
      "Loss after mini-batch    12: 0.027\n",
      "Loss after mini-batch    13: 0.036\n",
      "Loss after mini-batch    14: 0.051\n",
      "Loss after mini-batch    15: 0.007\n",
      "Loss after mini-batch    16: 0.145\n",
      "Loss after mini-batch    17: 0.025\n",
      "Loss after mini-batch    18: 0.024\n",
      "Loss after mini-batch    19: 0.012\n",
      "Loss after mini-batch    20: 0.041\n",
      "Loss after mini-batch    21: 0.026\n",
      "Loss after mini-batch    22: 0.019\n",
      "Loss after mini-batch    23: 0.026\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.013\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.020\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.072\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.034\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.042\n",
      "Loss after mini-batch    11: 0.018\n",
      "Loss after mini-batch    12: 0.076\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.043\n",
      "Loss after mini-batch    15: 0.017\n",
      "Loss after mini-batch    16: 0.060\n",
      "Loss after mini-batch    17: 0.015\n",
      "Loss after mini-batch    18: 0.003\n",
      "Loss after mini-batch    19: 0.035\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    21: 0.016\n",
      "Loss after mini-batch    22: 0.035\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.039\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.047\n",
      "Loss after mini-batch     6: 0.016\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.021\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.008\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.008\n",
      "Loss after mini-batch    14: 0.020\n",
      "Loss after mini-batch    15: 0.015\n",
      "Loss after mini-batch    16: 0.009\n",
      "Loss after mini-batch    17: 0.034\n",
      "Loss after mini-batch    18: 0.015\n",
      "Loss after mini-batch    19: 0.013\n",
      "Loss after mini-batch    20: 0.033\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.007\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.025\n",
      "Loss after mini-batch     3: 0.020\n",
      "Loss after mini-batch     4: 0.015\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.011\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.006\n",
      "Loss after mini-batch    13: 0.008\n",
      "Loss after mini-batch    14: 0.015\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.031\n",
      "Loss after mini-batch    17: 0.004\n",
      "Loss after mini-batch    18: 0.009\n",
      "Loss after mini-batch    19: 0.016\n",
      "Loss after mini-batch    20: 0.010\n",
      "Loss after mini-batch    21: 0.033\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.023\n",
      "Loss after mini-batch     6: 0.013\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.010\n",
      "Loss after mini-batch    12: 0.009\n",
      "Loss after mini-batch    13: 0.007\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.025\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.014\n",
      "Loss after mini-batch    18: 0.010\n",
      "Loss after mini-batch    19: 0.010\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.008\n",
      "Loss after mini-batch    23: 0.012\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.013\n",
      "Loss after mini-batch    12: 0.007\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.017\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.004\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    21: 0.008\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.005\n",
      "Loss after mini-batch    13: 0.023\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.003\n",
      "Loss after mini-batch    16: 0.006\n",
      "Loss after mini-batch    17: 0.014\n",
      "Loss after mini-batch    18: 0.006\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.007\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.017\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.006\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.013\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.005\n",
      "Loss after mini-batch    15: 0.011\n",
      "Loss after mini-batch    16: 0.009\n",
      "Loss after mini-batch    17: 0.013\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.007\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.010\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.013\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.003\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.006\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.011\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.012\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.010\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.004\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.003\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.008\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.003\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.010\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.003\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.007\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.004\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.005\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.002\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 85 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.783\n",
      "Loss after mini-batch     2: 0.869\n",
      "Loss after mini-batch     3: 0.847\n",
      "Loss after mini-batch     4: 0.669\n",
      "Loss after mini-batch     5: 0.735\n",
      "Loss after mini-batch     6: 0.740\n",
      "Loss after mini-batch     7: 0.676\n",
      "Loss after mini-batch     8: 0.746\n",
      "Loss after mini-batch     9: 0.723\n",
      "Loss after mini-batch    10: 0.712\n",
      "Loss after mini-batch    11: 0.697\n",
      "Loss after mini-batch    12: 0.694\n",
      "Loss after mini-batch    13: 0.699\n",
      "Loss after mini-batch    14: 0.705\n",
      "Loss after mini-batch    15: 0.675\n",
      "Loss after mini-batch    16: 0.663\n",
      "Loss after mini-batch    17: 0.656\n",
      "Loss after mini-batch    18: 0.655\n",
      "Loss after mini-batch    19: 0.698\n",
      "Loss after mini-batch    20: 0.643\n",
      "Loss after mini-batch    21: 0.661\n",
      "Loss after mini-batch    22: 0.670\n",
      "Loss after mini-batch    23: 0.682\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.663\n",
      "Loss after mini-batch     2: 0.716\n",
      "Loss after mini-batch     3: 0.604\n",
      "Loss after mini-batch     4: 0.611\n",
      "Loss after mini-batch     5: 0.657\n",
      "Loss after mini-batch     6: 0.667\n",
      "Loss after mini-batch     7: 0.649\n",
      "Loss after mini-batch     8: 0.676\n",
      "Loss after mini-batch     9: 0.618\n",
      "Loss after mini-batch    10: 0.612\n",
      "Loss after mini-batch    11: 0.666\n",
      "Loss after mini-batch    12: 0.609\n",
      "Loss after mini-batch    13: 0.621\n",
      "Loss after mini-batch    14: 0.612\n",
      "Loss after mini-batch    15: 0.602\n",
      "Loss after mini-batch    16: 0.622\n",
      "Loss after mini-batch    17: 0.649\n",
      "Loss after mini-batch    18: 0.577\n",
      "Loss after mini-batch    19: 0.525\n",
      "Loss after mini-batch    20: 0.719\n",
      "Loss after mini-batch    21: 0.635\n",
      "Loss after mini-batch    22: 0.568\n",
      "Loss after mini-batch    23: 0.480\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.557\n",
      "Loss after mini-batch     2: 0.565\n",
      "Loss after mini-batch     3: 0.670\n",
      "Loss after mini-batch     4: 0.532\n",
      "Loss after mini-batch     5: 0.526\n",
      "Loss after mini-batch     6: 0.622\n",
      "Loss after mini-batch     7: 0.478\n",
      "Loss after mini-batch     8: 0.522\n",
      "Loss after mini-batch     9: 0.604\n",
      "Loss after mini-batch    10: 0.489\n",
      "Loss after mini-batch    11: 0.531\n",
      "Loss after mini-batch    12: 0.522\n",
      "Loss after mini-batch    13: 0.630\n",
      "Loss after mini-batch    14: 0.453\n",
      "Loss after mini-batch    15: 0.449\n",
      "Loss after mini-batch    16: 0.435\n",
      "Loss after mini-batch    17: 0.399\n",
      "Loss after mini-batch    18: 0.674\n",
      "Loss after mini-batch    19: 0.383\n",
      "Loss after mini-batch    20: 0.423\n",
      "Loss after mini-batch    21: 0.394\n",
      "Loss after mini-batch    22: 0.634\n",
      "Loss after mini-batch    23: 0.634\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.570\n",
      "Loss after mini-batch     2: 0.496\n",
      "Loss after mini-batch     3: 0.392\n",
      "Loss after mini-batch     4: 0.353\n",
      "Loss after mini-batch     5: 0.320\n",
      "Loss after mini-batch     6: 0.466\n",
      "Loss after mini-batch     7: 0.347\n",
      "Loss after mini-batch     8: 0.462\n",
      "Loss after mini-batch     9: 0.447\n",
      "Loss after mini-batch    10: 0.497\n",
      "Loss after mini-batch    11: 0.324\n",
      "Loss after mini-batch    12: 0.338\n",
      "Loss after mini-batch    13: 0.330\n",
      "Loss after mini-batch    14: 0.370\n",
      "Loss after mini-batch    15: 0.821\n",
      "Loss after mini-batch    16: 0.258\n",
      "Loss after mini-batch    17: 0.473\n",
      "Loss after mini-batch    18: 0.397\n",
      "Loss after mini-batch    19: 0.423\n",
      "Loss after mini-batch    20: 0.370\n",
      "Loss after mini-batch    21: 0.424\n",
      "Loss after mini-batch    22: 0.343\n",
      "Loss after mini-batch    23: 0.294\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.530\n",
      "Loss after mini-batch     2: 0.124\n",
      "Loss after mini-batch     3: 0.284\n",
      "Loss after mini-batch     4: 0.532\n",
      "Loss after mini-batch     5: 0.319\n",
      "Loss after mini-batch     6: 0.223\n",
      "Loss after mini-batch     7: 0.423\n",
      "Loss after mini-batch     8: 0.206\n",
      "Loss after mini-batch     9: 0.292\n",
      "Loss after mini-batch    10: 0.191\n",
      "Loss after mini-batch    11: 0.479\n",
      "Loss after mini-batch    12: 0.252\n",
      "Loss after mini-batch    13: 0.357\n",
      "Loss after mini-batch    14: 0.434\n",
      "Loss after mini-batch    15: 0.289\n",
      "Loss after mini-batch    16: 0.232\n",
      "Loss after mini-batch    17: 0.414\n",
      "Loss after mini-batch    18: 0.395\n",
      "Loss after mini-batch    19: 0.273\n",
      "Loss after mini-batch    20: 0.214\n",
      "Loss after mini-batch    21: 0.253\n",
      "Loss after mini-batch    22: 0.188\n",
      "Loss after mini-batch    23: 0.548\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.309\n",
      "Loss after mini-batch     2: 0.203\n",
      "Loss after mini-batch     3: 0.223\n",
      "Loss after mini-batch     4: 0.370\n",
      "Loss after mini-batch     5: 0.285\n",
      "Loss after mini-batch     6: 0.130\n",
      "Loss after mini-batch     7: 0.130\n",
      "Loss after mini-batch     8: 0.224\n",
      "Loss after mini-batch     9: 0.149\n",
      "Loss after mini-batch    10: 0.293\n",
      "Loss after mini-batch    11: 0.506\n",
      "Loss after mini-batch    12: 0.269\n",
      "Loss after mini-batch    13: 0.313\n",
      "Loss after mini-batch    14: 0.216\n",
      "Loss after mini-batch    15: 0.292\n",
      "Loss after mini-batch    16: 0.180\n",
      "Loss after mini-batch    17: 0.300\n",
      "Loss after mini-batch    18: 0.508\n",
      "Loss after mini-batch    19: 0.191\n",
      "Loss after mini-batch    20: 0.272\n",
      "Loss after mini-batch    21: 0.385\n",
      "Loss after mini-batch    22: 0.114\n",
      "Loss after mini-batch    23: 0.465\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.134\n",
      "Loss after mini-batch     2: 0.093\n",
      "Loss after mini-batch     3: 0.149\n",
      "Loss after mini-batch     4: 0.231\n",
      "Loss after mini-batch     5: 0.220\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.348\n",
      "Loss after mini-batch     8: 0.415\n",
      "Loss after mini-batch     9: 0.226\n",
      "Loss after mini-batch    10: 0.328\n",
      "Loss after mini-batch    11: 0.139\n",
      "Loss after mini-batch    12: 0.352\n",
      "Loss after mini-batch    13: 0.150\n",
      "Loss after mini-batch    14: 0.202\n",
      "Loss after mini-batch    15: 0.108\n",
      "Loss after mini-batch    16: 0.205\n",
      "Loss after mini-batch    17: 0.290\n",
      "Loss after mini-batch    18: 0.070\n",
      "Loss after mini-batch    19: 0.332\n",
      "Loss after mini-batch    20: 0.079\n",
      "Loss after mini-batch    21: 0.309\n",
      "Loss after mini-batch    22: 0.165\n",
      "Loss after mini-batch    23: 0.439\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.149\n",
      "Loss after mini-batch     2: 0.234\n",
      "Loss after mini-batch     3: 0.066\n",
      "Loss after mini-batch     4: 0.062\n",
      "Loss after mini-batch     5: 0.086\n",
      "Loss after mini-batch     6: 0.156\n",
      "Loss after mini-batch     7: 0.213\n",
      "Loss after mini-batch     8: 0.189\n",
      "Loss after mini-batch     9: 0.013\n",
      "Loss after mini-batch    10: 0.280\n",
      "Loss after mini-batch    11: 0.179\n",
      "Loss after mini-batch    12: 0.142\n",
      "Loss after mini-batch    13: 0.284\n",
      "Loss after mini-batch    14: 0.154\n",
      "Loss after mini-batch    15: 0.124\n",
      "Loss after mini-batch    16: 0.096\n",
      "Loss after mini-batch    17: 0.094\n",
      "Loss after mini-batch    18: 0.344\n",
      "Loss after mini-batch    19: 0.029\n",
      "Loss after mini-batch    20: 0.276\n",
      "Loss after mini-batch    21: 0.131\n",
      "Loss after mini-batch    22: 0.167\n",
      "Loss after mini-batch    23: 0.012\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.039\n",
      "Loss after mini-batch     2: 0.094\n",
      "Loss after mini-batch     3: 0.453\n",
      "Loss after mini-batch     4: 0.030\n",
      "Loss after mini-batch     5: 0.058\n",
      "Loss after mini-batch     6: 0.035\n",
      "Loss after mini-batch     7: 0.189\n",
      "Loss after mini-batch     8: 0.076\n",
      "Loss after mini-batch     9: 0.036\n",
      "Loss after mini-batch    10: 0.070\n",
      "Loss after mini-batch    11: 0.059\n",
      "Loss after mini-batch    12: 0.023\n",
      "Loss after mini-batch    13: 0.110\n",
      "Loss after mini-batch    14: 0.116\n",
      "Loss after mini-batch    15: 0.039\n",
      "Loss after mini-batch    16: 0.160\n",
      "Loss after mini-batch    17: 0.122\n",
      "Loss after mini-batch    18: 0.036\n",
      "Loss after mini-batch    19: 0.245\n",
      "Loss after mini-batch    20: 0.166\n",
      "Loss after mini-batch    21: 0.063\n",
      "Loss after mini-batch    22: 0.365\n",
      "Loss after mini-batch    23: 0.042\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.035\n",
      "Loss after mini-batch     2: 0.096\n",
      "Loss after mini-batch     3: 0.023\n",
      "Loss after mini-batch     4: 0.108\n",
      "Loss after mini-batch     5: 0.088\n",
      "Loss after mini-batch     6: 0.096\n",
      "Loss after mini-batch     7: 0.045\n",
      "Loss after mini-batch     8: 0.061\n",
      "Loss after mini-batch     9: 0.035\n",
      "Loss after mini-batch    10: 0.091\n",
      "Loss after mini-batch    11: 0.055\n",
      "Loss after mini-batch    12: 0.072\n",
      "Loss after mini-batch    13: 0.086\n",
      "Loss after mini-batch    14: 0.053\n",
      "Loss after mini-batch    15: 0.006\n",
      "Loss after mini-batch    16: 0.117\n",
      "Loss after mini-batch    17: 0.028\n",
      "Loss after mini-batch    18: 0.042\n",
      "Loss after mini-batch    19: 0.173\n",
      "Loss after mini-batch    20: 0.057\n",
      "Loss after mini-batch    21: 0.016\n",
      "Loss after mini-batch    22: 0.070\n",
      "Loss after mini-batch    23: 0.461\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.024\n",
      "Loss after mini-batch     2: 0.115\n",
      "Loss after mini-batch     3: 0.031\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.024\n",
      "Loss after mini-batch     7: 0.109\n",
      "Loss after mini-batch     8: 0.053\n",
      "Loss after mini-batch     9: 0.023\n",
      "Loss after mini-batch    10: 0.034\n",
      "Loss after mini-batch    11: 0.019\n",
      "Loss after mini-batch    12: 0.016\n",
      "Loss after mini-batch    13: 0.012\n",
      "Loss after mini-batch    14: 0.012\n",
      "Loss after mini-batch    15: 0.191\n",
      "Loss after mini-batch    16: 0.024\n",
      "Loss after mini-batch    17: 0.039\n",
      "Loss after mini-batch    18: 0.141\n",
      "Loss after mini-batch    19: 0.034\n",
      "Loss after mini-batch    20: 0.040\n",
      "Loss after mini-batch    21: 0.022\n",
      "Loss after mini-batch    22: 0.104\n",
      "Loss after mini-batch    23: 0.094\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.067\n",
      "Loss after mini-batch     2: 0.052\n",
      "Loss after mini-batch     3: 0.019\n",
      "Loss after mini-batch     4: 0.020\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.150\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.148\n",
      "Loss after mini-batch    10: 0.104\n",
      "Loss after mini-batch    11: 0.004\n",
      "Loss after mini-batch    12: 0.017\n",
      "Loss after mini-batch    13: 0.042\n",
      "Loss after mini-batch    14: 0.060\n",
      "Loss after mini-batch    15: 0.041\n",
      "Loss after mini-batch    16: 0.019\n",
      "Loss after mini-batch    17: 0.019\n",
      "Loss after mini-batch    18: 0.033\n",
      "Loss after mini-batch    19: 0.006\n",
      "Loss after mini-batch    20: 0.025\n",
      "Loss after mini-batch    21: 0.029\n",
      "Loss after mini-batch    22: 0.064\n",
      "Loss after mini-batch    23: 0.008\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.041\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.032\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.013\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.028\n",
      "Loss after mini-batch    12: 0.112\n",
      "Loss after mini-batch    13: 0.029\n",
      "Loss after mini-batch    14: 0.019\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.006\n",
      "Loss after mini-batch    17: 0.008\n",
      "Loss after mini-batch    18: 0.043\n",
      "Loss after mini-batch    19: 0.007\n",
      "Loss after mini-batch    20: 0.031\n",
      "Loss after mini-batch    21: 0.086\n",
      "Loss after mini-batch    22: 0.020\n",
      "Loss after mini-batch    23: 0.009\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.026\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.011\n",
      "Loss after mini-batch    12: 0.013\n",
      "Loss after mini-batch    13: 0.026\n",
      "Loss after mini-batch    14: 0.050\n",
      "Loss after mini-batch    15: 0.005\n",
      "Loss after mini-batch    16: 0.011\n",
      "Loss after mini-batch    17: 0.004\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.027\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.064\n",
      "Loss after mini-batch    22: 0.003\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.017\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.009\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.006\n",
      "Loss after mini-batch    15: 0.055\n",
      "Loss after mini-batch    16: 0.003\n",
      "Loss after mini-batch    17: 0.028\n",
      "Loss after mini-batch    18: 0.016\n",
      "Loss after mini-batch    19: 0.003\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.003\n",
      "Loss after mini-batch    22: 0.006\n",
      "Loss after mini-batch    23: 0.002\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.012\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.007\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.040\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.023\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.007\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.022\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.010\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.011\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.003\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.017\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.026\n",
      "Loss after mini-batch    12: 0.004\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.002\n",
      "Loss after mini-batch    17: 0.003\n",
      "Loss after mini-batch    18: 0.007\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    21: 0.005\n",
      "Loss after mini-batch    22: 0.002\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.013\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.003\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.020\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.002\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.006\n",
      "Loss after mini-batch    17: 0.009\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.024\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.002\n",
      "Loss after mini-batch    13: 0.002\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.013\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.004\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.002\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.005\n",
      "Loss after mini-batch    18: 0.012\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.001\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.015\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.004\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.001\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.002\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.008\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.011\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.001\n",
      "Loss after mini-batch    18: 0.003\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.001\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.001\n",
      "Loss after mini-batch    13: 0.006\n",
      "Loss after mini-batch    14: 0.001\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.001\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.005\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.001\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.001\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.002\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.001\n",
      "Loss after mini-batch    23: 0.001\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.000\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.000\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.000\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.000\n",
      "Loss after mini-batch    12: 0.003\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.002\n",
      "Loss after mini-batch    15: 0.001\n",
      "Loss after mini-batch    16: 0.001\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.000\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.000\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.000\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.000\n",
      "Loss after mini-batch     7: 0.000\n",
      "Loss after mini-batch     8: 0.000\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    11: 0.001\n",
      "Loss after mini-batch    12: 0.000\n",
      "Loss after mini-batch    13: 0.000\n",
      "Loss after mini-batch    14: 0.000\n",
      "Loss after mini-batch    15: 0.000\n",
      "Loss after mini-batch    16: 0.000\n",
      "Loss after mini-batch    17: 0.000\n",
      "Loss after mini-batch    18: 0.000\n",
      "Loss after mini-batch    19: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    21: 0.004\n",
      "Loss after mini-batch    22: 0.000\n",
      "Loss after mini-batch    23: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 87 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 89.28571428571429 %\n",
      "Fold 1: 87.5 %\n",
      "Fold 2: 83.92857142857143 %\n",
      "Fold 3: 85.71428571428571 %\n",
      "Fold 4: 87.5 %\n",
      "Average: 86.78571428571429 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 30\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=10, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.877\n",
      "Loss after mini-batch     2: 0.714\n",
      "Loss after mini-batch     3: 0.904\n",
      "Loss after mini-batch     4: 0.704\n",
      "Loss after mini-batch     5: 0.719\n",
      "Loss after mini-batch     6: 0.857\n",
      "Loss after mini-batch     7: 0.634\n",
      "Loss after mini-batch     8: 0.641\n",
      "Loss after mini-batch     9: 0.569\n",
      "Loss after mini-batch    10: 0.748\n",
      "Loss after mini-batch    11: 0.559\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.571\n",
      "Loss after mini-batch     2: 0.586\n",
      "Loss after mini-batch     3: 0.455\n",
      "Loss after mini-batch     4: 0.575\n",
      "Loss after mini-batch     5: 0.579\n",
      "Loss after mini-batch     6: 0.486\n",
      "Loss after mini-batch     7: 0.515\n",
      "Loss after mini-batch     8: 0.511\n",
      "Loss after mini-batch     9: 0.435\n",
      "Loss after mini-batch    10: 0.458\n",
      "Loss after mini-batch    11: 0.522\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.436\n",
      "Loss after mini-batch     2: 0.382\n",
      "Loss after mini-batch     3: 0.466\n",
      "Loss after mini-batch     4: 0.372\n",
      "Loss after mini-batch     5: 0.291\n",
      "Loss after mini-batch     6: 0.425\n",
      "Loss after mini-batch     7: 0.434\n",
      "Loss after mini-batch     8: 0.568\n",
      "Loss after mini-batch     9: 0.286\n",
      "Loss after mini-batch    10: 0.364\n",
      "Loss after mini-batch    11: 0.363\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.396\n",
      "Loss after mini-batch     2: 0.383\n",
      "Loss after mini-batch     3: 0.400\n",
      "Loss after mini-batch     4: 0.343\n",
      "Loss after mini-batch     5: 0.323\n",
      "Loss after mini-batch     6: 0.295\n",
      "Loss after mini-batch     7: 0.315\n",
      "Loss after mini-batch     8: 0.493\n",
      "Loss after mini-batch     9: 0.356\n",
      "Loss after mini-batch    10: 0.199\n",
      "Loss after mini-batch    11: 0.055\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.304\n",
      "Loss after mini-batch     2: 0.348\n",
      "Loss after mini-batch     3: 0.353\n",
      "Loss after mini-batch     4: 0.254\n",
      "Loss after mini-batch     5: 0.303\n",
      "Loss after mini-batch     6: 0.349\n",
      "Loss after mini-batch     7: 0.192\n",
      "Loss after mini-batch     8: 0.262\n",
      "Loss after mini-batch     9: 0.249\n",
      "Loss after mini-batch    10: 0.248\n",
      "Loss after mini-batch    11: 0.374\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.242\n",
      "Loss after mini-batch     2: 0.314\n",
      "Loss after mini-batch     3: 0.218\n",
      "Loss after mini-batch     4: 0.156\n",
      "Loss after mini-batch     5: 0.332\n",
      "Loss after mini-batch     6: 0.233\n",
      "Loss after mini-batch     7: 0.268\n",
      "Loss after mini-batch     8: 0.202\n",
      "Loss after mini-batch     9: 0.267\n",
      "Loss after mini-batch    10: 0.271\n",
      "Loss after mini-batch    11: 0.371\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.232\n",
      "Loss after mini-batch     2: 0.223\n",
      "Loss after mini-batch     3: 0.245\n",
      "Loss after mini-batch     4: 0.117\n",
      "Loss after mini-batch     5: 0.201\n",
      "Loss after mini-batch     6: 0.338\n",
      "Loss after mini-batch     7: 0.258\n",
      "Loss after mini-batch     8: 0.078\n",
      "Loss after mini-batch     9: 0.229\n",
      "Loss after mini-batch    10: 0.101\n",
      "Loss after mini-batch    11: 0.089\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.153\n",
      "Loss after mini-batch     2: 0.201\n",
      "Loss after mini-batch     3: 0.258\n",
      "Loss after mini-batch     4: 0.085\n",
      "Loss after mini-batch     5: 0.207\n",
      "Loss after mini-batch     6: 0.146\n",
      "Loss after mini-batch     7: 0.217\n",
      "Loss after mini-batch     8: 0.179\n",
      "Loss after mini-batch     9: 0.097\n",
      "Loss after mini-batch    10: 0.052\n",
      "Loss after mini-batch    11: 0.024\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.171\n",
      "Loss after mini-batch     2: 0.057\n",
      "Loss after mini-batch     3: 0.096\n",
      "Loss after mini-batch     4: 0.153\n",
      "Loss after mini-batch     5: 0.125\n",
      "Loss after mini-batch     6: 0.148\n",
      "Loss after mini-batch     7: 0.053\n",
      "Loss after mini-batch     8: 0.201\n",
      "Loss after mini-batch     9: 0.242\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.018\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.089\n",
      "Loss after mini-batch     2: 0.211\n",
      "Loss after mini-batch     3: 0.201\n",
      "Loss after mini-batch     4: 0.095\n",
      "Loss after mini-batch     5: 0.136\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.089\n",
      "Loss after mini-batch     8: 0.071\n",
      "Loss after mini-batch     9: 0.033\n",
      "Loss after mini-batch    10: 0.092\n",
      "Loss after mini-batch    11: 0.034\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.116\n",
      "Loss after mini-batch     2: 0.139\n",
      "Loss after mini-batch     3: 0.080\n",
      "Loss after mini-batch     4: 0.037\n",
      "Loss after mini-batch     5: 0.057\n",
      "Loss after mini-batch     6: 0.053\n",
      "Loss after mini-batch     7: 0.073\n",
      "Loss after mini-batch     8: 0.041\n",
      "Loss after mini-batch     9: 0.096\n",
      "Loss after mini-batch    10: 0.054\n",
      "Loss after mini-batch    11: 0.053\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.094\n",
      "Loss after mini-batch     2: 0.058\n",
      "Loss after mini-batch     3: 0.017\n",
      "Loss after mini-batch     4: 0.113\n",
      "Loss after mini-batch     5: 0.086\n",
      "Loss after mini-batch     6: 0.084\n",
      "Loss after mini-batch     7: 0.044\n",
      "Loss after mini-batch     8: 0.022\n",
      "Loss after mini-batch     9: 0.077\n",
      "Loss after mini-batch    10: 0.119\n",
      "Loss after mini-batch    11: 0.025\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.117\n",
      "Loss after mini-batch     2: 0.063\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.064\n",
      "Loss after mini-batch     5: 0.032\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.057\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.039\n",
      "Loss after mini-batch    10: 0.054\n",
      "Loss after mini-batch    11: 0.032\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.027\n",
      "Loss after mini-batch     2: 0.058\n",
      "Loss after mini-batch     3: 0.015\n",
      "Loss after mini-batch     4: 0.048\n",
      "Loss after mini-batch     5: 0.069\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.009\n",
      "Loss after mini-batch     8: 0.039\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.044\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.075\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.030\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.014\n",
      "Loss after mini-batch     8: 0.012\n",
      "Loss after mini-batch     9: 0.025\n",
      "Loss after mini-batch    10: 0.033\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.041\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.029\n",
      "Loss after mini-batch     4: 0.054\n",
      "Loss after mini-batch     5: 0.008\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.013\n",
      "Loss after mini-batch     3: 0.042\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.017\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.017\n",
      "Loss after mini-batch    11: 0.017\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.013\n",
      "Loss after mini-batch     7: 0.023\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.022\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.008\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.027\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.012\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.030\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 78 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.931\n",
      "Loss after mini-batch     2: 1.463\n",
      "Loss after mini-batch     3: 1.126\n",
      "Loss after mini-batch     4: 0.665\n",
      "Loss after mini-batch     5: 0.781\n",
      "Loss after mini-batch     6: 0.842\n",
      "Loss after mini-batch     7: 0.690\n",
      "Loss after mini-batch     8: 0.679\n",
      "Loss after mini-batch     9: 0.699\n",
      "Loss after mini-batch    10: 0.802\n",
      "Loss after mini-batch    11: 0.737\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.755\n",
      "Loss after mini-batch     2: 0.652\n",
      "Loss after mini-batch     3: 0.655\n",
      "Loss after mini-batch     4: 0.623\n",
      "Loss after mini-batch     5: 0.663\n",
      "Loss after mini-batch     6: 0.592\n",
      "Loss after mini-batch     7: 0.627\n",
      "Loss after mini-batch     8: 0.631\n",
      "Loss after mini-batch     9: 0.612\n",
      "Loss after mini-batch    10: 0.641\n",
      "Loss after mini-batch    11: 0.723\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.600\n",
      "Loss after mini-batch     2: 0.614\n",
      "Loss after mini-batch     3: 0.586\n",
      "Loss after mini-batch     4: 0.544\n",
      "Loss after mini-batch     5: 0.553\n",
      "Loss after mini-batch     6: 0.597\n",
      "Loss after mini-batch     7: 0.475\n",
      "Loss after mini-batch     8: 0.512\n",
      "Loss after mini-batch     9: 0.517\n",
      "Loss after mini-batch    10: 0.518\n",
      "Loss after mini-batch    11: 0.552\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.529\n",
      "Loss after mini-batch     2: 0.469\n",
      "Loss after mini-batch     3: 0.476\n",
      "Loss after mini-batch     4: 0.456\n",
      "Loss after mini-batch     5: 0.380\n",
      "Loss after mini-batch     6: 0.525\n",
      "Loss after mini-batch     7: 0.458\n",
      "Loss after mini-batch     8: 0.419\n",
      "Loss after mini-batch     9: 0.497\n",
      "Loss after mini-batch    10: 0.295\n",
      "Loss after mini-batch    11: 0.225\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.492\n",
      "Loss after mini-batch     2: 0.319\n",
      "Loss after mini-batch     3: 0.331\n",
      "Loss after mini-batch     4: 0.446\n",
      "Loss after mini-batch     5: 0.407\n",
      "Loss after mini-batch     6: 0.443\n",
      "Loss after mini-batch     7: 0.330\n",
      "Loss after mini-batch     8: 0.311\n",
      "Loss after mini-batch     9: 0.356\n",
      "Loss after mini-batch    10: 0.260\n",
      "Loss after mini-batch    11: 0.369\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.320\n",
      "Loss after mini-batch     2: 0.333\n",
      "Loss after mini-batch     3: 0.420\n",
      "Loss after mini-batch     4: 0.222\n",
      "Loss after mini-batch     5: 0.275\n",
      "Loss after mini-batch     6: 0.456\n",
      "Loss after mini-batch     7: 0.363\n",
      "Loss after mini-batch     8: 0.341\n",
      "Loss after mini-batch     9: 0.255\n",
      "Loss after mini-batch    10: 0.095\n",
      "Loss after mini-batch    11: 0.054\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.240\n",
      "Loss after mini-batch     2: 0.205\n",
      "Loss after mini-batch     3: 0.225\n",
      "Loss after mini-batch     4: 0.180\n",
      "Loss after mini-batch     5: 0.255\n",
      "Loss after mini-batch     6: 0.117\n",
      "Loss after mini-batch     7: 0.285\n",
      "Loss after mini-batch     8: 0.373\n",
      "Loss after mini-batch     9: 0.374\n",
      "Loss after mini-batch    10: 0.218\n",
      "Loss after mini-batch    11: 0.189\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.151\n",
      "Loss after mini-batch     2: 0.210\n",
      "Loss after mini-batch     3: 0.180\n",
      "Loss after mini-batch     4: 0.218\n",
      "Loss after mini-batch     5: 0.213\n",
      "Loss after mini-batch     6: 0.294\n",
      "Loss after mini-batch     7: 0.258\n",
      "Loss after mini-batch     8: 0.367\n",
      "Loss after mini-batch     9: 0.216\n",
      "Loss after mini-batch    10: 0.198\n",
      "Loss after mini-batch    11: 0.008\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.290\n",
      "Loss after mini-batch     2: 0.338\n",
      "Loss after mini-batch     3: 0.211\n",
      "Loss after mini-batch     4: 0.162\n",
      "Loss after mini-batch     5: 0.174\n",
      "Loss after mini-batch     6: 0.109\n",
      "Loss after mini-batch     7: 0.152\n",
      "Loss after mini-batch     8: 0.226\n",
      "Loss after mini-batch     9: 0.195\n",
      "Loss after mini-batch    10: 0.211\n",
      "Loss after mini-batch    11: 0.173\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.146\n",
      "Loss after mini-batch     2: 0.163\n",
      "Loss after mini-batch     3: 0.099\n",
      "Loss after mini-batch     4: 0.155\n",
      "Loss after mini-batch     5: 0.118\n",
      "Loss after mini-batch     6: 0.116\n",
      "Loss after mini-batch     7: 0.241\n",
      "Loss after mini-batch     8: 0.300\n",
      "Loss after mini-batch     9: 0.149\n",
      "Loss after mini-batch    10: 0.045\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.135\n",
      "Loss after mini-batch     2: 0.172\n",
      "Loss after mini-batch     3: 0.245\n",
      "Loss after mini-batch     4: 0.092\n",
      "Loss after mini-batch     5: 0.145\n",
      "Loss after mini-batch     6: 0.083\n",
      "Loss after mini-batch     7: 0.047\n",
      "Loss after mini-batch     8: 0.118\n",
      "Loss after mini-batch     9: 0.112\n",
      "Loss after mini-batch    10: 0.092\n",
      "Loss after mini-batch    11: 0.018\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch     2: 0.138\n",
      "Loss after mini-batch     3: 0.119\n",
      "Loss after mini-batch     4: 0.058\n",
      "Loss after mini-batch     5: 0.173\n",
      "Loss after mini-batch     6: 0.056\n",
      "Loss after mini-batch     7: 0.070\n",
      "Loss after mini-batch     8: 0.111\n",
      "Loss after mini-batch     9: 0.071\n",
      "Loss after mini-batch    10: 0.071\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.048\n",
      "Loss after mini-batch     2: 0.051\n",
      "Loss after mini-batch     3: 0.047\n",
      "Loss after mini-batch     4: 0.098\n",
      "Loss after mini-batch     5: 0.087\n",
      "Loss after mini-batch     6: 0.066\n",
      "Loss after mini-batch     7: 0.099\n",
      "Loss after mini-batch     8: 0.056\n",
      "Loss after mini-batch     9: 0.103\n",
      "Loss after mini-batch    10: 0.077\n",
      "Loss after mini-batch    11: 0.126\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.053\n",
      "Loss after mini-batch     2: 0.038\n",
      "Loss after mini-batch     3: 0.074\n",
      "Loss after mini-batch     4: 0.161\n",
      "Loss after mini-batch     5: 0.062\n",
      "Loss after mini-batch     6: 0.028\n",
      "Loss after mini-batch     7: 0.075\n",
      "Loss after mini-batch     8: 0.067\n",
      "Loss after mini-batch     9: 0.059\n",
      "Loss after mini-batch    10: 0.046\n",
      "Loss after mini-batch    11: 0.049\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.082\n",
      "Loss after mini-batch     2: 0.050\n",
      "Loss after mini-batch     3: 0.018\n",
      "Loss after mini-batch     4: 0.041\n",
      "Loss after mini-batch     5: 0.070\n",
      "Loss after mini-batch     6: 0.122\n",
      "Loss after mini-batch     7: 0.044\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.029\n",
      "Loss after mini-batch    10: 0.071\n",
      "Loss after mini-batch    11: 0.098\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.031\n",
      "Loss after mini-batch     2: 0.062\n",
      "Loss after mini-batch     3: 0.055\n",
      "Loss after mini-batch     4: 0.067\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.051\n",
      "Loss after mini-batch     7: 0.054\n",
      "Loss after mini-batch     8: 0.078\n",
      "Loss after mini-batch     9: 0.028\n",
      "Loss after mini-batch    10: 0.042\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.023\n",
      "Loss after mini-batch     2: 0.019\n",
      "Loss after mini-batch     3: 0.028\n",
      "Loss after mini-batch     4: 0.039\n",
      "Loss after mini-batch     5: 0.019\n",
      "Loss after mini-batch     6: 0.101\n",
      "Loss after mini-batch     7: 0.023\n",
      "Loss after mini-batch     8: 0.041\n",
      "Loss after mini-batch     9: 0.034\n",
      "Loss after mini-batch    10: 0.046\n",
      "Loss after mini-batch    11: 0.072\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.020\n",
      "Loss after mini-batch     2: 0.036\n",
      "Loss after mini-batch     3: 0.026\n",
      "Loss after mini-batch     4: 0.085\n",
      "Loss after mini-batch     5: 0.026\n",
      "Loss after mini-batch     6: 0.047\n",
      "Loss after mini-batch     7: 0.088\n",
      "Loss after mini-batch     8: 0.020\n",
      "Loss after mini-batch     9: 0.031\n",
      "Loss after mini-batch    10: 0.041\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.050\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.046\n",
      "Loss after mini-batch     5: 0.032\n",
      "Loss after mini-batch     6: 0.015\n",
      "Loss after mini-batch     7: 0.032\n",
      "Loss after mini-batch     8: 0.036\n",
      "Loss after mini-batch     9: 0.037\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.042\n",
      "Loss after mini-batch     2: 0.027\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.043\n",
      "Loss after mini-batch     5: 0.022\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.013\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.048\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 96 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.746\n",
      "Loss after mini-batch     2: 0.802\n",
      "Loss after mini-batch     3: 0.707\n",
      "Loss after mini-batch     4: 0.704\n",
      "Loss after mini-batch     5: 0.670\n",
      "Loss after mini-batch     6: 0.693\n",
      "Loss after mini-batch     7: 0.633\n",
      "Loss after mini-batch     8: 0.790\n",
      "Loss after mini-batch     9: 0.584\n",
      "Loss after mini-batch    10: 0.698\n",
      "Loss after mini-batch    11: 0.708\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.756\n",
      "Loss after mini-batch     2: 0.571\n",
      "Loss after mini-batch     3: 0.614\n",
      "Loss after mini-batch     4: 0.699\n",
      "Loss after mini-batch     5: 0.635\n",
      "Loss after mini-batch     6: 0.566\n",
      "Loss after mini-batch     7: 0.540\n",
      "Loss after mini-batch     8: 0.540\n",
      "Loss after mini-batch     9: 0.654\n",
      "Loss after mini-batch    10: 0.467\n",
      "Loss after mini-batch    11: 0.393\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.446\n",
      "Loss after mini-batch     2: 0.659\n",
      "Loss after mini-batch     3: 0.488\n",
      "Loss after mini-batch     4: 0.503\n",
      "Loss after mini-batch     5: 0.469\n",
      "Loss after mini-batch     6: 0.298\n",
      "Loss after mini-batch     7: 0.304\n",
      "Loss after mini-batch     8: 0.419\n",
      "Loss after mini-batch     9: 0.472\n",
      "Loss after mini-batch    10: 0.328\n",
      "Loss after mini-batch    11: 0.302\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.191\n",
      "Loss after mini-batch     2: 0.360\n",
      "Loss after mini-batch     3: 0.305\n",
      "Loss after mini-batch     4: 0.500\n",
      "Loss after mini-batch     5: 0.247\n",
      "Loss after mini-batch     6: 0.572\n",
      "Loss after mini-batch     7: 0.277\n",
      "Loss after mini-batch     8: 0.325\n",
      "Loss after mini-batch     9: 0.218\n",
      "Loss after mini-batch    10: 0.288\n",
      "Loss after mini-batch    11: 0.055\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.356\n",
      "Loss after mini-batch     2: 0.121\n",
      "Loss after mini-batch     3: 0.161\n",
      "Loss after mini-batch     4: 0.237\n",
      "Loss after mini-batch     5: 0.347\n",
      "Loss after mini-batch     6: 0.227\n",
      "Loss after mini-batch     7: 0.538\n",
      "Loss after mini-batch     8: 0.158\n",
      "Loss after mini-batch     9: 0.462\n",
      "Loss after mini-batch    10: 0.332\n",
      "Loss after mini-batch    11: 0.549\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.307\n",
      "Loss after mini-batch     2: 0.130\n",
      "Loss after mini-batch     3: 0.296\n",
      "Loss after mini-batch     4: 0.381\n",
      "Loss after mini-batch     5: 0.284\n",
      "Loss after mini-batch     6: 0.230\n",
      "Loss after mini-batch     7: 0.304\n",
      "Loss after mini-batch     8: 0.167\n",
      "Loss after mini-batch     9: 0.205\n",
      "Loss after mini-batch    10: 0.207\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.186\n",
      "Loss after mini-batch     2: 0.222\n",
      "Loss after mini-batch     3: 0.167\n",
      "Loss after mini-batch     4: 0.251\n",
      "Loss after mini-batch     5: 0.182\n",
      "Loss after mini-batch     6: 0.290\n",
      "Loss after mini-batch     7: 0.202\n",
      "Loss after mini-batch     8: 0.210\n",
      "Loss after mini-batch     9: 0.156\n",
      "Loss after mini-batch    10: 0.234\n",
      "Loss after mini-batch    11: 0.386\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.206\n",
      "Loss after mini-batch     2: 0.089\n",
      "Loss after mini-batch     3: 0.190\n",
      "Loss after mini-batch     4: 0.206\n",
      "Loss after mini-batch     5: 0.107\n",
      "Loss after mini-batch     6: 0.043\n",
      "Loss after mini-batch     7: 0.301\n",
      "Loss after mini-batch     8: 0.230\n",
      "Loss after mini-batch     9: 0.130\n",
      "Loss after mini-batch    10: 0.260\n",
      "Loss after mini-batch    11: 0.101\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.260\n",
      "Loss after mini-batch     2: 0.138\n",
      "Loss after mini-batch     3: 0.217\n",
      "Loss after mini-batch     4: 0.153\n",
      "Loss after mini-batch     5: 0.129\n",
      "Loss after mini-batch     6: 0.131\n",
      "Loss after mini-batch     7: 0.109\n",
      "Loss after mini-batch     8: 0.099\n",
      "Loss after mini-batch     9: 0.077\n",
      "Loss after mini-batch    10: 0.151\n",
      "Loss after mini-batch    11: 0.564\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.087\n",
      "Loss after mini-batch     2: 0.144\n",
      "Loss after mini-batch     3: 0.126\n",
      "Loss after mini-batch     4: 0.164\n",
      "Loss after mini-batch     5: 0.148\n",
      "Loss after mini-batch     6: 0.152\n",
      "Loss after mini-batch     7: 0.123\n",
      "Loss after mini-batch     8: 0.119\n",
      "Loss after mini-batch     9: 0.128\n",
      "Loss after mini-batch    10: 0.065\n",
      "Loss after mini-batch    11: 0.013\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.114\n",
      "Loss after mini-batch     2: 0.081\n",
      "Loss after mini-batch     3: 0.098\n",
      "Loss after mini-batch     4: 0.043\n",
      "Loss after mini-batch     5: 0.055\n",
      "Loss after mini-batch     6: 0.141\n",
      "Loss after mini-batch     7: 0.136\n",
      "Loss after mini-batch     8: 0.045\n",
      "Loss after mini-batch     9: 0.137\n",
      "Loss after mini-batch    10: 0.122\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.131\n",
      "Loss after mini-batch     2: 0.046\n",
      "Loss after mini-batch     3: 0.082\n",
      "Loss after mini-batch     4: 0.055\n",
      "Loss after mini-batch     5: 0.033\n",
      "Loss after mini-batch     6: 0.101\n",
      "Loss after mini-batch     7: 0.064\n",
      "Loss after mini-batch     8: 0.059\n",
      "Loss after mini-batch     9: 0.124\n",
      "Loss after mini-batch    10: 0.029\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.037\n",
      "Loss after mini-batch     2: 0.080\n",
      "Loss after mini-batch     3: 0.031\n",
      "Loss after mini-batch     4: 0.020\n",
      "Loss after mini-batch     5: 0.076\n",
      "Loss after mini-batch     6: 0.031\n",
      "Loss after mini-batch     7: 0.079\n",
      "Loss after mini-batch     8: 0.055\n",
      "Loss after mini-batch     9: 0.073\n",
      "Loss after mini-batch    10: 0.051\n",
      "Loss after mini-batch    11: 0.111\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.061\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.048\n",
      "Loss after mini-batch     4: 0.028\n",
      "Loss after mini-batch     5: 0.054\n",
      "Loss after mini-batch     6: 0.077\n",
      "Loss after mini-batch     7: 0.040\n",
      "Loss after mini-batch     8: 0.010\n",
      "Loss after mini-batch     9: 0.041\n",
      "Loss after mini-batch    10: 0.109\n",
      "Loss after mini-batch    11: 0.012\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.029\n",
      "Loss after mini-batch     2: 0.024\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.016\n",
      "Loss after mini-batch     5: 0.063\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.028\n",
      "Loss after mini-batch     8: 0.082\n",
      "Loss after mini-batch     9: 0.076\n",
      "Loss after mini-batch    10: 0.062\n",
      "Loss after mini-batch    11: 0.017\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.024\n",
      "Loss after mini-batch     2: 0.019\n",
      "Loss after mini-batch     3: 0.024\n",
      "Loss after mini-batch     4: 0.040\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.054\n",
      "Loss after mini-batch     7: 0.035\n",
      "Loss after mini-batch     8: 0.043\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.042\n",
      "Loss after mini-batch    11: 0.009\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.022\n",
      "Loss after mini-batch     2: 0.021\n",
      "Loss after mini-batch     3: 0.036\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.055\n",
      "Loss after mini-batch     7: 0.026\n",
      "Loss after mini-batch     8: 0.028\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.031\n",
      "Loss after mini-batch    11: 0.009\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.012\n",
      "Loss after mini-batch     3: 0.017\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.033\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.024\n",
      "Loss after mini-batch    10: 0.026\n",
      "Loss after mini-batch    11: 0.009\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.008\n",
      "Loss after mini-batch     2: 0.017\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.016\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.043\n",
      "Loss after mini-batch     7: 0.011\n",
      "Loss after mini-batch     8: 0.024\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.023\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.017\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.008\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.042\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 85 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.665\n",
      "Loss after mini-batch     2: 0.813\n",
      "Loss after mini-batch     3: 0.649\n",
      "Loss after mini-batch     4: 0.711\n",
      "Loss after mini-batch     5: 0.804\n",
      "Loss after mini-batch     6: 0.728\n",
      "Loss after mini-batch     7: 0.516\n",
      "Loss after mini-batch     8: 0.648\n",
      "Loss after mini-batch     9: 0.578\n",
      "Loss after mini-batch    10: 0.495\n",
      "Loss after mini-batch    11: 0.801\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.719\n",
      "Loss after mini-batch     2: 0.475\n",
      "Loss after mini-batch     3: 0.411\n",
      "Loss after mini-batch     4: 0.425\n",
      "Loss after mini-batch     5: 0.528\n",
      "Loss after mini-batch     6: 0.465\n",
      "Loss after mini-batch     7: 0.617\n",
      "Loss after mini-batch     8: 0.405\n",
      "Loss after mini-batch     9: 0.446\n",
      "Loss after mini-batch    10: 0.434\n",
      "Loss after mini-batch    11: 1.100\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.350\n",
      "Loss after mini-batch     2: 0.325\n",
      "Loss after mini-batch     3: 0.297\n",
      "Loss after mini-batch     4: 0.365\n",
      "Loss after mini-batch     5: 0.455\n",
      "Loss after mini-batch     6: 0.332\n",
      "Loss after mini-batch     7: 0.707\n",
      "Loss after mini-batch     8: 0.303\n",
      "Loss after mini-batch     9: 0.240\n",
      "Loss after mini-batch    10: 0.326\n",
      "Loss after mini-batch    11: 0.232\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.191\n",
      "Loss after mini-batch     2: 0.238\n",
      "Loss after mini-batch     3: 0.260\n",
      "Loss after mini-batch     4: 0.191\n",
      "Loss after mini-batch     5: 0.255\n",
      "Loss after mini-batch     6: 0.395\n",
      "Loss after mini-batch     7: 0.219\n",
      "Loss after mini-batch     8: 0.488\n",
      "Loss after mini-batch     9: 0.259\n",
      "Loss after mini-batch    10: 0.323\n",
      "Loss after mini-batch    11: 0.336\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.203\n",
      "Loss after mini-batch     2: 0.284\n",
      "Loss after mini-batch     3: 0.260\n",
      "Loss after mini-batch     4: 0.223\n",
      "Loss after mini-batch     5: 0.258\n",
      "Loss after mini-batch     6: 0.279\n",
      "Loss after mini-batch     7: 0.182\n",
      "Loss after mini-batch     8: 0.377\n",
      "Loss after mini-batch     9: 0.154\n",
      "Loss after mini-batch    10: 0.274\n",
      "Loss after mini-batch    11: 0.349\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.147\n",
      "Loss after mini-batch     2: 0.139\n",
      "Loss after mini-batch     3: 0.233\n",
      "Loss after mini-batch     4: 0.142\n",
      "Loss after mini-batch     5: 0.153\n",
      "Loss after mini-batch     6: 0.186\n",
      "Loss after mini-batch     7: 0.151\n",
      "Loss after mini-batch     8: 0.310\n",
      "Loss after mini-batch     9: 0.139\n",
      "Loss after mini-batch    10: 0.341\n",
      "Loss after mini-batch    11: 0.012\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.244\n",
      "Loss after mini-batch     2: 0.224\n",
      "Loss after mini-batch     3: 0.110\n",
      "Loss after mini-batch     4: 0.151\n",
      "Loss after mini-batch     5: 0.040\n",
      "Loss after mini-batch     6: 0.125\n",
      "Loss after mini-batch     7: 0.195\n",
      "Loss after mini-batch     8: 0.202\n",
      "Loss after mini-batch     9: 0.135\n",
      "Loss after mini-batch    10: 0.191\n",
      "Loss after mini-batch    11: 0.163\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.100\n",
      "Loss after mini-batch     2: 0.129\n",
      "Loss after mini-batch     3: 0.121\n",
      "Loss after mini-batch     4: 0.141\n",
      "Loss after mini-batch     5: 0.062\n",
      "Loss after mini-batch     6: 0.042\n",
      "Loss after mini-batch     7: 0.093\n",
      "Loss after mini-batch     8: 0.073\n",
      "Loss after mini-batch     9: 0.161\n",
      "Loss after mini-batch    10: 0.114\n",
      "Loss after mini-batch    11: 0.477\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch     2: 0.110\n",
      "Loss after mini-batch     3: 0.136\n",
      "Loss after mini-batch     4: 0.116\n",
      "Loss after mini-batch     5: 0.155\n",
      "Loss after mini-batch     6: 0.217\n",
      "Loss after mini-batch     7: 0.250\n",
      "Loss after mini-batch     8: 0.065\n",
      "Loss after mini-batch     9: 0.058\n",
      "Loss after mini-batch    10: 0.065\n",
      "Loss after mini-batch    11: 0.011\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.171\n",
      "Loss after mini-batch     2: 0.107\n",
      "Loss after mini-batch     3: 0.094\n",
      "Loss after mini-batch     4: 0.105\n",
      "Loss after mini-batch     5: 0.087\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.066\n",
      "Loss after mini-batch     8: 0.070\n",
      "Loss after mini-batch     9: 0.090\n",
      "Loss after mini-batch    10: 0.044\n",
      "Loss after mini-batch    11: 0.017\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.070\n",
      "Loss after mini-batch     2: 0.079\n",
      "Loss after mini-batch     3: 0.062\n",
      "Loss after mini-batch     4: 0.078\n",
      "Loss after mini-batch     5: 0.055\n",
      "Loss after mini-batch     6: 0.075\n",
      "Loss after mini-batch     7: 0.046\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.040\n",
      "Loss after mini-batch    10: 0.037\n",
      "Loss after mini-batch    11: 0.006\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.055\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.029\n",
      "Loss after mini-batch     4: 0.033\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.030\n",
      "Loss after mini-batch     7: 0.079\n",
      "Loss after mini-batch     8: 0.038\n",
      "Loss after mini-batch     9: 0.034\n",
      "Loss after mini-batch    10: 0.056\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.056\n",
      "Loss after mini-batch     2: 0.011\n",
      "Loss after mini-batch     3: 0.038\n",
      "Loss after mini-batch     4: 0.050\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.046\n",
      "Loss after mini-batch     7: 0.033\n",
      "Loss after mini-batch     8: 0.030\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    11: 0.129\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.008\n",
      "Loss after mini-batch     2: 0.058\n",
      "Loss after mini-batch     3: 0.016\n",
      "Loss after mini-batch     4: 0.015\n",
      "Loss after mini-batch     5: 0.059\n",
      "Loss after mini-batch     6: 0.016\n",
      "Loss after mini-batch     7: 0.025\n",
      "Loss after mini-batch     8: 0.021\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.006\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.030\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.011\n",
      "Loss after mini-batch     6: 0.055\n",
      "Loss after mini-batch     7: 0.026\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.024\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.016\n",
      "Loss after mini-batch     7: 0.011\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.077\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.031\n",
      "Loss after mini-batch     7: 0.020\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.016\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    11: 0.012\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.012\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.023\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.013\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.025\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.012\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.020\n",
      "Loss after mini-batch     3: 0.001\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.003\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 82 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.680\n",
      "Loss after mini-batch     2: 0.676\n",
      "Loss after mini-batch     3: 0.906\n",
      "Loss after mini-batch     4: 0.664\n",
      "Loss after mini-batch     5: 0.622\n",
      "Loss after mini-batch     6: 0.686\n",
      "Loss after mini-batch     7: 0.594\n",
      "Loss after mini-batch     8: 0.585\n",
      "Loss after mini-batch     9: 0.637\n",
      "Loss after mini-batch    10: 0.563\n",
      "Loss after mini-batch    11: 0.526\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.531\n",
      "Loss after mini-batch     2: 0.485\n",
      "Loss after mini-batch     3: 0.404\n",
      "Loss after mini-batch     4: 0.517\n",
      "Loss after mini-batch     5: 0.492\n",
      "Loss after mini-batch     6: 0.498\n",
      "Loss after mini-batch     7: 0.375\n",
      "Loss after mini-batch     8: 0.390\n",
      "Loss after mini-batch     9: 0.422\n",
      "Loss after mini-batch    10: 0.294\n",
      "Loss after mini-batch    11: 0.497\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.331\n",
      "Loss after mini-batch     2: 0.469\n",
      "Loss after mini-batch     3: 0.304\n",
      "Loss after mini-batch     4: 0.230\n",
      "Loss after mini-batch     5: 0.323\n",
      "Loss after mini-batch     6: 0.309\n",
      "Loss after mini-batch     7: 0.359\n",
      "Loss after mini-batch     8: 0.255\n",
      "Loss after mini-batch     9: 0.426\n",
      "Loss after mini-batch    10: 0.477\n",
      "Loss after mini-batch    11: 0.050\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.225\n",
      "Loss after mini-batch     2: 0.331\n",
      "Loss after mini-batch     3: 0.440\n",
      "Loss after mini-batch     4: 0.393\n",
      "Loss after mini-batch     5: 0.205\n",
      "Loss after mini-batch     6: 0.297\n",
      "Loss after mini-batch     7: 0.230\n",
      "Loss after mini-batch     8: 0.281\n",
      "Loss after mini-batch     9: 0.172\n",
      "Loss after mini-batch    10: 0.297\n",
      "Loss after mini-batch    11: 0.210\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.255\n",
      "Loss after mini-batch     2: 0.148\n",
      "Loss after mini-batch     3: 0.330\n",
      "Loss after mini-batch     4: 0.247\n",
      "Loss after mini-batch     5: 0.169\n",
      "Loss after mini-batch     6: 0.183\n",
      "Loss after mini-batch     7: 0.267\n",
      "Loss after mini-batch     8: 0.191\n",
      "Loss after mini-batch     9: 0.221\n",
      "Loss after mini-batch    10: 0.177\n",
      "Loss after mini-batch    11: 0.315\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.203\n",
      "Loss after mini-batch     2: 0.166\n",
      "Loss after mini-batch     3: 0.110\n",
      "Loss after mini-batch     4: 0.242\n",
      "Loss after mini-batch     5: 0.162\n",
      "Loss after mini-batch     6: 0.191\n",
      "Loss after mini-batch     7: 0.156\n",
      "Loss after mini-batch     8: 0.153\n",
      "Loss after mini-batch     9: 0.115\n",
      "Loss after mini-batch    10: 0.179\n",
      "Loss after mini-batch    11: 0.031\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.118\n",
      "Loss after mini-batch     2: 0.146\n",
      "Loss after mini-batch     3: 0.164\n",
      "Loss after mini-batch     4: 0.131\n",
      "Loss after mini-batch     5: 0.103\n",
      "Loss after mini-batch     6: 0.086\n",
      "Loss after mini-batch     7: 0.247\n",
      "Loss after mini-batch     8: 0.101\n",
      "Loss after mini-batch     9: 0.124\n",
      "Loss after mini-batch    10: 0.103\n",
      "Loss after mini-batch    11: 0.094\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.118\n",
      "Loss after mini-batch     2: 0.215\n",
      "Loss after mini-batch     3: 0.075\n",
      "Loss after mini-batch     4: 0.103\n",
      "Loss after mini-batch     5: 0.065\n",
      "Loss after mini-batch     6: 0.047\n",
      "Loss after mini-batch     7: 0.073\n",
      "Loss after mini-batch     8: 0.048\n",
      "Loss after mini-batch     9: 0.123\n",
      "Loss after mini-batch    10: 0.087\n",
      "Loss after mini-batch    11: 0.002\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.097\n",
      "Loss after mini-batch     2: 0.156\n",
      "Loss after mini-batch     3: 0.111\n",
      "Loss after mini-batch     4: 0.126\n",
      "Loss after mini-batch     5: 0.058\n",
      "Loss after mini-batch     6: 0.045\n",
      "Loss after mini-batch     7: 0.035\n",
      "Loss after mini-batch     8: 0.043\n",
      "Loss after mini-batch     9: 0.033\n",
      "Loss after mini-batch    10: 0.021\n",
      "Loss after mini-batch    11: 0.069\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch     2: 0.114\n",
      "Loss after mini-batch     3: 0.028\n",
      "Loss after mini-batch     4: 0.062\n",
      "Loss after mini-batch     5: 0.050\n",
      "Loss after mini-batch     6: 0.081\n",
      "Loss after mini-batch     7: 0.024\n",
      "Loss after mini-batch     8: 0.035\n",
      "Loss after mini-batch     9: 0.079\n",
      "Loss after mini-batch    10: 0.024\n",
      "Loss after mini-batch    11: 0.005\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.059\n",
      "Loss after mini-batch     2: 0.050\n",
      "Loss after mini-batch     3: 0.042\n",
      "Loss after mini-batch     4: 0.044\n",
      "Loss after mini-batch     5: 0.033\n",
      "Loss after mini-batch     6: 0.029\n",
      "Loss after mini-batch     7: 0.011\n",
      "Loss after mini-batch     8: 0.052\n",
      "Loss after mini-batch     9: 0.029\n",
      "Loss after mini-batch    10: 0.010\n",
      "Loss after mini-batch    11: 0.066\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.012\n",
      "Loss after mini-batch     3: 0.053\n",
      "Loss after mini-batch     4: 0.078\n",
      "Loss after mini-batch     5: 0.103\n",
      "Loss after mini-batch     6: 0.026\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.019\n",
      "Loss after mini-batch     9: 0.070\n",
      "Loss after mini-batch    10: 0.048\n",
      "Loss after mini-batch    11: 0.006\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.113\n",
      "Loss after mini-batch     2: 0.027\n",
      "Loss after mini-batch     3: 0.025\n",
      "Loss after mini-batch     4: 0.022\n",
      "Loss after mini-batch     5: 0.023\n",
      "Loss after mini-batch     6: 0.023\n",
      "Loss after mini-batch     7: 0.013\n",
      "Loss after mini-batch     8: 0.027\n",
      "Loss after mini-batch     9: 0.031\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.095\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.068\n",
      "Loss after mini-batch     3: 0.025\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.032\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.014\n",
      "Loss after mini-batch     8: 0.029\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.011\n",
      "Loss after mini-batch    11: 0.008\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.027\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.035\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.024\n",
      "Loss after mini-batch     7: 0.019\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.367\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.017\n",
      "Loss after mini-batch     2: 0.028\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.117\n",
      "Loss after mini-batch     5: 0.084\n",
      "Loss after mini-batch     6: 0.023\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.015\n",
      "Loss after mini-batch    11: 0.029\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.053\n",
      "Loss after mini-batch     2: 0.013\n",
      "Loss after mini-batch     3: 0.044\n",
      "Loss after mini-batch     4: 0.007\n",
      "Loss after mini-batch     5: 0.009\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.012\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.015\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.039\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.011\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.007\n",
      "Loss after mini-batch     6: 0.022\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.004\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.011\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.023\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 85 %\n",
      "--------------------------------\n",
      "FOLD 5\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.709\n",
      "Loss after mini-batch     2: 0.772\n",
      "Loss after mini-batch     3: 0.770\n",
      "Loss after mini-batch     4: 0.717\n",
      "Loss after mini-batch     5: 0.654\n",
      "Loss after mini-batch     6: 0.639\n",
      "Loss after mini-batch     7: 0.576\n",
      "Loss after mini-batch     8: 0.641\n",
      "Loss after mini-batch     9: 0.595\n",
      "Loss after mini-batch    10: 0.592\n",
      "Loss after mini-batch    11: 0.302\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.748\n",
      "Loss after mini-batch     2: 0.616\n",
      "Loss after mini-batch     3: 0.466\n",
      "Loss after mini-batch     4: 0.548\n",
      "Loss after mini-batch     5: 0.458\n",
      "Loss after mini-batch     6: 0.389\n",
      "Loss after mini-batch     7: 0.432\n",
      "Loss after mini-batch     8: 0.431\n",
      "Loss after mini-batch     9: 0.420\n",
      "Loss after mini-batch    10: 0.570\n",
      "Loss after mini-batch    11: 0.567\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.327\n",
      "Loss after mini-batch     2: 0.532\n",
      "Loss after mini-batch     3: 0.420\n",
      "Loss after mini-batch     4: 0.582\n",
      "Loss after mini-batch     5: 0.413\n",
      "Loss after mini-batch     6: 0.364\n",
      "Loss after mini-batch     7: 0.416\n",
      "Loss after mini-batch     8: 0.298\n",
      "Loss after mini-batch     9: 0.357\n",
      "Loss after mini-batch    10: 0.458\n",
      "Loss after mini-batch    11: 0.306\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.335\n",
      "Loss after mini-batch     2: 0.287\n",
      "Loss after mini-batch     3: 0.375\n",
      "Loss after mini-batch     4: 0.260\n",
      "Loss after mini-batch     5: 0.490\n",
      "Loss after mini-batch     6: 0.361\n",
      "Loss after mini-batch     7: 0.311\n",
      "Loss after mini-batch     8: 0.289\n",
      "Loss after mini-batch     9: 0.301\n",
      "Loss after mini-batch    10: 0.473\n",
      "Loss after mini-batch    11: 0.927\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.312\n",
      "Loss after mini-batch     2: 0.262\n",
      "Loss after mini-batch     3: 0.307\n",
      "Loss after mini-batch     4: 0.417\n",
      "Loss after mini-batch     5: 0.307\n",
      "Loss after mini-batch     6: 0.177\n",
      "Loss after mini-batch     7: 0.296\n",
      "Loss after mini-batch     8: 0.317\n",
      "Loss after mini-batch     9: 0.198\n",
      "Loss after mini-batch    10: 0.290\n",
      "Loss after mini-batch    11: 0.132\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.359\n",
      "Loss after mini-batch     2: 0.219\n",
      "Loss after mini-batch     3: 0.318\n",
      "Loss after mini-batch     4: 0.204\n",
      "Loss after mini-batch     5: 0.153\n",
      "Loss after mini-batch     6: 0.174\n",
      "Loss after mini-batch     7: 0.162\n",
      "Loss after mini-batch     8: 0.226\n",
      "Loss after mini-batch     9: 0.367\n",
      "Loss after mini-batch    10: 0.167\n",
      "Loss after mini-batch    11: 0.030\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.167\n",
      "Loss after mini-batch     2: 0.303\n",
      "Loss after mini-batch     3: 0.300\n",
      "Loss after mini-batch     4: 0.133\n",
      "Loss after mini-batch     5: 0.104\n",
      "Loss after mini-batch     6: 0.104\n",
      "Loss after mini-batch     7: 0.183\n",
      "Loss after mini-batch     8: 0.181\n",
      "Loss after mini-batch     9: 0.172\n",
      "Loss after mini-batch    10: 0.183\n",
      "Loss after mini-batch    11: 0.082\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.148\n",
      "Loss after mini-batch     2: 0.136\n",
      "Loss after mini-batch     3: 0.196\n",
      "Loss after mini-batch     4: 0.157\n",
      "Loss after mini-batch     5: 0.137\n",
      "Loss after mini-batch     6: 0.106\n",
      "Loss after mini-batch     7: 0.071\n",
      "Loss after mini-batch     8: 0.194\n",
      "Loss after mini-batch     9: 0.077\n",
      "Loss after mini-batch    10: 0.152\n",
      "Loss after mini-batch    11: 0.018\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.107\n",
      "Loss after mini-batch     2: 0.123\n",
      "Loss after mini-batch     3: 0.083\n",
      "Loss after mini-batch     4: 0.057\n",
      "Loss after mini-batch     5: 0.070\n",
      "Loss after mini-batch     6: 0.117\n",
      "Loss after mini-batch     7: 0.091\n",
      "Loss after mini-batch     8: 0.167\n",
      "Loss after mini-batch     9: 0.114\n",
      "Loss after mini-batch    10: 0.079\n",
      "Loss after mini-batch    11: 0.042\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.054\n",
      "Loss after mini-batch     2: 0.071\n",
      "Loss after mini-batch     3: 0.075\n",
      "Loss after mini-batch     4: 0.071\n",
      "Loss after mini-batch     5: 0.039\n",
      "Loss after mini-batch     6: 0.097\n",
      "Loss after mini-batch     7: 0.094\n",
      "Loss after mini-batch     8: 0.077\n",
      "Loss after mini-batch     9: 0.065\n",
      "Loss after mini-batch    10: 0.056\n",
      "Loss after mini-batch    11: 0.014\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.108\n",
      "Loss after mini-batch     2: 0.048\n",
      "Loss after mini-batch     3: 0.096\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.064\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.027\n",
      "Loss after mini-batch     8: 0.077\n",
      "Loss after mini-batch     9: 0.047\n",
      "Loss after mini-batch    10: 0.021\n",
      "Loss after mini-batch    11: 0.006\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.035\n",
      "Loss after mini-batch     2: 0.047\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.021\n",
      "Loss after mini-batch     5: 0.031\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.026\n",
      "Loss after mini-batch     8: 0.045\n",
      "Loss after mini-batch     9: 0.039\n",
      "Loss after mini-batch    10: 0.031\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.009\n",
      "Loss after mini-batch     3: 0.010\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.052\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.031\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.028\n",
      "Loss after mini-batch    10: 0.035\n",
      "Loss after mini-batch    11: 0.041\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.015\n",
      "Loss after mini-batch     2: 0.051\n",
      "Loss after mini-batch     3: 0.019\n",
      "Loss after mini-batch     4: 0.020\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.014\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.007\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.030\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.016\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.034\n",
      "Loss after mini-batch     9: 0.008\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.024\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.030\n",
      "Loss after mini-batch     4: 0.029\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.001\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.015\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.002\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.008\n",
      "Loss after mini-batch     3: 0.031\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.005\n",
      "Loss after mini-batch     3: 0.014\n",
      "Loss after mini-batch     4: 0.000\n",
      "Loss after mini-batch     5: 0.015\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.002\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.002\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.011\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.002\n",
      "Loss after mini-batch     5: 0.001\n",
      "Loss after mini-batch     6: 0.002\n",
      "Loss after mini-batch     7: 0.001\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.001\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 5: 89 %\n",
      "--------------------------------\n",
      "FOLD 6\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.704\n",
      "Loss after mini-batch     2: 2.377\n",
      "Loss after mini-batch     3: 0.744\n",
      "Loss after mini-batch     4: 1.370\n",
      "Loss after mini-batch     5: 1.226\n",
      "Loss after mini-batch     6: 1.407\n",
      "Loss after mini-batch     7: 0.699\n",
      "Loss after mini-batch     8: 0.693\n",
      "Loss after mini-batch     9: 0.975\n",
      "Loss after mini-batch    10: 1.105\n",
      "Loss after mini-batch    11: 0.778\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.670\n",
      "Loss after mini-batch     2: 0.594\n",
      "Loss after mini-batch     3: 0.573\n",
      "Loss after mini-batch     4: 0.601\n",
      "Loss after mini-batch     5: 0.778\n",
      "Loss after mini-batch     6: 0.587\n",
      "Loss after mini-batch     7: 0.613\n",
      "Loss after mini-batch     8: 0.561\n",
      "Loss after mini-batch     9: 0.610\n",
      "Loss after mini-batch    10: 0.586\n",
      "Loss after mini-batch    11: 0.561\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.551\n",
      "Loss after mini-batch     2: 0.552\n",
      "Loss after mini-batch     3: 0.490\n",
      "Loss after mini-batch     4: 0.564\n",
      "Loss after mini-batch     5: 0.448\n",
      "Loss after mini-batch     6: 0.505\n",
      "Loss after mini-batch     7: 0.458\n",
      "Loss after mini-batch     8: 0.480\n",
      "Loss after mini-batch     9: 0.472\n",
      "Loss after mini-batch    10: 0.480\n",
      "Loss after mini-batch    11: 0.602\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.395\n",
      "Loss after mini-batch     2: 0.399\n",
      "Loss after mini-batch     3: 0.431\n",
      "Loss after mini-batch     4: 0.409\n",
      "Loss after mini-batch     5: 0.374\n",
      "Loss after mini-batch     6: 0.389\n",
      "Loss after mini-batch     7: 0.429\n",
      "Loss after mini-batch     8: 0.366\n",
      "Loss after mini-batch     9: 0.412\n",
      "Loss after mini-batch    10: 0.488\n",
      "Loss after mini-batch    11: 0.586\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.226\n",
      "Loss after mini-batch     2: 0.391\n",
      "Loss after mini-batch     3: 0.435\n",
      "Loss after mini-batch     4: 0.411\n",
      "Loss after mini-batch     5: 0.344\n",
      "Loss after mini-batch     6: 0.388\n",
      "Loss after mini-batch     7: 0.351\n",
      "Loss after mini-batch     8: 0.351\n",
      "Loss after mini-batch     9: 0.350\n",
      "Loss after mini-batch    10: 0.243\n",
      "Loss after mini-batch    11: 0.076\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.328\n",
      "Loss after mini-batch     2: 0.229\n",
      "Loss after mini-batch     3: 0.299\n",
      "Loss after mini-batch     4: 0.273\n",
      "Loss after mini-batch     5: 0.526\n",
      "Loss after mini-batch     6: 0.288\n",
      "Loss after mini-batch     7: 0.264\n",
      "Loss after mini-batch     8: 0.339\n",
      "Loss after mini-batch     9: 0.444\n",
      "Loss after mini-batch    10: 0.404\n",
      "Loss after mini-batch    11: 0.187\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.219\n",
      "Loss after mini-batch     2: 0.328\n",
      "Loss after mini-batch     3: 0.304\n",
      "Loss after mini-batch     4: 0.218\n",
      "Loss after mini-batch     5: 0.216\n",
      "Loss after mini-batch     6: 0.353\n",
      "Loss after mini-batch     7: 0.280\n",
      "Loss after mini-batch     8: 0.218\n",
      "Loss after mini-batch     9: 0.360\n",
      "Loss after mini-batch    10: 0.132\n",
      "Loss after mini-batch    11: 0.050\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.168\n",
      "Loss after mini-batch     2: 0.221\n",
      "Loss after mini-batch     3: 0.208\n",
      "Loss after mini-batch     4: 0.210\n",
      "Loss after mini-batch     5: 0.181\n",
      "Loss after mini-batch     6: 0.320\n",
      "Loss after mini-batch     7: 0.282\n",
      "Loss after mini-batch     8: 0.217\n",
      "Loss after mini-batch     9: 0.222\n",
      "Loss after mini-batch    10: 0.393\n",
      "Loss after mini-batch    11: 0.119\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.248\n",
      "Loss after mini-batch     2: 0.095\n",
      "Loss after mini-batch     3: 0.324\n",
      "Loss after mini-batch     4: 0.167\n",
      "Loss after mini-batch     5: 0.191\n",
      "Loss after mini-batch     6: 0.295\n",
      "Loss after mini-batch     7: 0.251\n",
      "Loss after mini-batch     8: 0.106\n",
      "Loss after mini-batch     9: 0.240\n",
      "Loss after mini-batch    10: 0.197\n",
      "Loss after mini-batch    11: 0.027\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.283\n",
      "Loss after mini-batch     2: 0.153\n",
      "Loss after mini-batch     3: 0.398\n",
      "Loss after mini-batch     4: 0.146\n",
      "Loss after mini-batch     5: 0.251\n",
      "Loss after mini-batch     6: 0.261\n",
      "Loss after mini-batch     7: 0.230\n",
      "Loss after mini-batch     8: 0.181\n",
      "Loss after mini-batch     9: 0.088\n",
      "Loss after mini-batch    10: 0.128\n",
      "Loss after mini-batch    11: 0.108\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.226\n",
      "Loss after mini-batch     2: 0.207\n",
      "Loss after mini-batch     3: 0.109\n",
      "Loss after mini-batch     4: 0.240\n",
      "Loss after mini-batch     5: 0.218\n",
      "Loss after mini-batch     6: 0.113\n",
      "Loss after mini-batch     7: 0.072\n",
      "Loss after mini-batch     8: 0.246\n",
      "Loss after mini-batch     9: 0.136\n",
      "Loss after mini-batch    10: 0.086\n",
      "Loss after mini-batch    11: 0.255\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.165\n",
      "Loss after mini-batch     2: 0.278\n",
      "Loss after mini-batch     3: 0.121\n",
      "Loss after mini-batch     4: 0.118\n",
      "Loss after mini-batch     5: 0.134\n",
      "Loss after mini-batch     6: 0.165\n",
      "Loss after mini-batch     7: 0.220\n",
      "Loss after mini-batch     8: 0.075\n",
      "Loss after mini-batch     9: 0.069\n",
      "Loss after mini-batch    10: 0.169\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.128\n",
      "Loss after mini-batch     2: 0.193\n",
      "Loss after mini-batch     3: 0.135\n",
      "Loss after mini-batch     4: 0.145\n",
      "Loss after mini-batch     5: 0.099\n",
      "Loss after mini-batch     6: 0.109\n",
      "Loss after mini-batch     7: 0.115\n",
      "Loss after mini-batch     8: 0.125\n",
      "Loss after mini-batch     9: 0.147\n",
      "Loss after mini-batch    10: 0.079\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.087\n",
      "Loss after mini-batch     2: 0.213\n",
      "Loss after mini-batch     3: 0.135\n",
      "Loss after mini-batch     4: 0.075\n",
      "Loss after mini-batch     5: 0.084\n",
      "Loss after mini-batch     6: 0.076\n",
      "Loss after mini-batch     7: 0.158\n",
      "Loss after mini-batch     8: 0.080\n",
      "Loss after mini-batch     9: 0.070\n",
      "Loss after mini-batch    10: 0.172\n",
      "Loss after mini-batch    11: 0.102\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.065\n",
      "Loss after mini-batch     2: 0.081\n",
      "Loss after mini-batch     3: 0.158\n",
      "Loss after mini-batch     4: 0.132\n",
      "Loss after mini-batch     5: 0.077\n",
      "Loss after mini-batch     6: 0.055\n",
      "Loss after mini-batch     7: 0.087\n",
      "Loss after mini-batch     8: 0.075\n",
      "Loss after mini-batch     9: 0.015\n",
      "Loss after mini-batch    10: 0.112\n",
      "Loss after mini-batch    11: 0.240\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.069\n",
      "Loss after mini-batch     2: 0.104\n",
      "Loss after mini-batch     3: 0.235\n",
      "Loss after mini-batch     4: 0.112\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.045\n",
      "Loss after mini-batch     7: 0.029\n",
      "Loss after mini-batch     8: 0.138\n",
      "Loss after mini-batch     9: 0.057\n",
      "Loss after mini-batch    10: 0.058\n",
      "Loss after mini-batch    11: 0.104\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.036\n",
      "Loss after mini-batch     2: 0.092\n",
      "Loss after mini-batch     3: 0.052\n",
      "Loss after mini-batch     4: 0.079\n",
      "Loss after mini-batch     5: 0.065\n",
      "Loss after mini-batch     6: 0.057\n",
      "Loss after mini-batch     7: 0.127\n",
      "Loss after mini-batch     8: 0.098\n",
      "Loss after mini-batch     9: 0.043\n",
      "Loss after mini-batch    10: 0.041\n",
      "Loss after mini-batch    11: 0.010\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.044\n",
      "Loss after mini-batch     2: 0.028\n",
      "Loss after mini-batch     3: 0.115\n",
      "Loss after mini-batch     4: 0.021\n",
      "Loss after mini-batch     5: 0.039\n",
      "Loss after mini-batch     6: 0.079\n",
      "Loss after mini-batch     7: 0.077\n",
      "Loss after mini-batch     8: 0.026\n",
      "Loss after mini-batch     9: 0.057\n",
      "Loss after mini-batch    10: 0.028\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.036\n",
      "Loss after mini-batch     2: 0.022\n",
      "Loss after mini-batch     3: 0.055\n",
      "Loss after mini-batch     4: 0.039\n",
      "Loss after mini-batch     5: 0.058\n",
      "Loss after mini-batch     6: 0.093\n",
      "Loss after mini-batch     7: 0.045\n",
      "Loss after mini-batch     8: 0.021\n",
      "Loss after mini-batch     9: 0.037\n",
      "Loss after mini-batch    10: 0.026\n",
      "Loss after mini-batch    11: 0.022\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.119\n",
      "Loss after mini-batch     2: 0.029\n",
      "Loss after mini-batch     3: 0.040\n",
      "Loss after mini-batch     4: 0.011\n",
      "Loss after mini-batch     5: 0.025\n",
      "Loss after mini-batch     6: 0.013\n",
      "Loss after mini-batch     7: 0.032\n",
      "Loss after mini-batch     8: 0.015\n",
      "Loss after mini-batch     9: 0.018\n",
      "Loss after mini-batch    10: 0.044\n",
      "Loss after mini-batch    11: 0.032\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 6: 92 %\n",
      "--------------------------------\n",
      "FOLD 7\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.799\n",
      "Loss after mini-batch     2: 1.114\n",
      "Loss after mini-batch     3: 0.783\n",
      "Loss after mini-batch     4: 0.750\n",
      "Loss after mini-batch     5: 0.687\n",
      "Loss after mini-batch     6: 0.696\n",
      "Loss after mini-batch     7: 0.772\n",
      "Loss after mini-batch     8: 0.690\n",
      "Loss after mini-batch     9: 0.669\n",
      "Loss after mini-batch    10: 0.610\n",
      "Loss after mini-batch    11: 0.347\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.788\n",
      "Loss after mini-batch     2: 0.739\n",
      "Loss after mini-batch     3: 0.629\n",
      "Loss after mini-batch     4: 0.581\n",
      "Loss after mini-batch     5: 0.698\n",
      "Loss after mini-batch     6: 0.549\n",
      "Loss after mini-batch     7: 0.517\n",
      "Loss after mini-batch     8: 0.507\n",
      "Loss after mini-batch     9: 0.535\n",
      "Loss after mini-batch    10: 0.480\n",
      "Loss after mini-batch    11: 0.221\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.518\n",
      "Loss after mini-batch     2: 0.633\n",
      "Loss after mini-batch     3: 0.520\n",
      "Loss after mini-batch     4: 0.370\n",
      "Loss after mini-batch     5: 0.289\n",
      "Loss after mini-batch     6: 0.388\n",
      "Loss after mini-batch     7: 0.496\n",
      "Loss after mini-batch     8: 0.391\n",
      "Loss after mini-batch     9: 0.294\n",
      "Loss after mini-batch    10: 0.458\n",
      "Loss after mini-batch    11: 0.282\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.226\n",
      "Loss after mini-batch     2: 0.413\n",
      "Loss after mini-batch     3: 0.349\n",
      "Loss after mini-batch     4: 0.202\n",
      "Loss after mini-batch     5: 0.363\n",
      "Loss after mini-batch     6: 0.367\n",
      "Loss after mini-batch     7: 0.492\n",
      "Loss after mini-batch     8: 0.325\n",
      "Loss after mini-batch     9: 0.091\n",
      "Loss after mini-batch    10: 0.413\n",
      "Loss after mini-batch    11: 0.396\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.271\n",
      "Loss after mini-batch     2: 0.126\n",
      "Loss after mini-batch     3: 0.241\n",
      "Loss after mini-batch     4: 0.456\n",
      "Loss after mini-batch     5: 0.183\n",
      "Loss after mini-batch     6: 0.395\n",
      "Loss after mini-batch     7: 0.205\n",
      "Loss after mini-batch     8: 0.268\n",
      "Loss after mini-batch     9: 0.409\n",
      "Loss after mini-batch    10: 0.079\n",
      "Loss after mini-batch    11: 0.470\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.202\n",
      "Loss after mini-batch     2: 0.280\n",
      "Loss after mini-batch     3: 0.179\n",
      "Loss after mini-batch     4: 0.222\n",
      "Loss after mini-batch     5: 0.250\n",
      "Loss after mini-batch     6: 0.199\n",
      "Loss after mini-batch     7: 0.211\n",
      "Loss after mini-batch     8: 0.252\n",
      "Loss after mini-batch     9: 0.206\n",
      "Loss after mini-batch    10: 0.173\n",
      "Loss after mini-batch    11: 0.144\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.234\n",
      "Loss after mini-batch     2: 0.174\n",
      "Loss after mini-batch     3: 0.200\n",
      "Loss after mini-batch     4: 0.214\n",
      "Loss after mini-batch     5: 0.248\n",
      "Loss after mini-batch     6: 0.082\n",
      "Loss after mini-batch     7: 0.177\n",
      "Loss after mini-batch     8: 0.098\n",
      "Loss after mini-batch     9: 0.119\n",
      "Loss after mini-batch    10: 0.128\n",
      "Loss after mini-batch    11: 0.836\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.076\n",
      "Loss after mini-batch     2: 0.131\n",
      "Loss after mini-batch     3: 0.093\n",
      "Loss after mini-batch     4: 0.229\n",
      "Loss after mini-batch     5: 0.106\n",
      "Loss after mini-batch     6: 0.096\n",
      "Loss after mini-batch     7: 0.119\n",
      "Loss after mini-batch     8: 0.105\n",
      "Loss after mini-batch     9: 0.134\n",
      "Loss after mini-batch    10: 0.145\n",
      "Loss after mini-batch    11: 0.002\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.171\n",
      "Loss after mini-batch     2: 0.069\n",
      "Loss after mini-batch     3: 0.104\n",
      "Loss after mini-batch     4: 0.120\n",
      "Loss after mini-batch     5: 0.041\n",
      "Loss after mini-batch     6: 0.098\n",
      "Loss after mini-batch     7: 0.177\n",
      "Loss after mini-batch     8: 0.048\n",
      "Loss after mini-batch     9: 0.124\n",
      "Loss after mini-batch    10: 0.079\n",
      "Loss after mini-batch    11: 0.177\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.121\n",
      "Loss after mini-batch     2: 0.086\n",
      "Loss after mini-batch     3: 0.062\n",
      "Loss after mini-batch     4: 0.067\n",
      "Loss after mini-batch     5: 0.062\n",
      "Loss after mini-batch     6: 0.071\n",
      "Loss after mini-batch     7: 0.062\n",
      "Loss after mini-batch     8: 0.018\n",
      "Loss after mini-batch     9: 0.108\n",
      "Loss after mini-batch    10: 0.102\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.070\n",
      "Loss after mini-batch     2: 0.058\n",
      "Loss after mini-batch     3: 0.090\n",
      "Loss after mini-batch     4: 0.055\n",
      "Loss after mini-batch     5: 0.058\n",
      "Loss after mini-batch     6: 0.064\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.055\n",
      "Loss after mini-batch     9: 0.084\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.014\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.028\n",
      "Loss after mini-batch     2: 0.092\n",
      "Loss after mini-batch     3: 0.035\n",
      "Loss after mini-batch     4: 0.025\n",
      "Loss after mini-batch     5: 0.052\n",
      "Loss after mini-batch     6: 0.021\n",
      "Loss after mini-batch     7: 0.039\n",
      "Loss after mini-batch     8: 0.025\n",
      "Loss after mini-batch     9: 0.032\n",
      "Loss after mini-batch    10: 0.035\n",
      "Loss after mini-batch    11: 0.002\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.055\n",
      "Loss after mini-batch     2: 0.042\n",
      "Loss after mini-batch     3: 0.009\n",
      "Loss after mini-batch     4: 0.026\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.034\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.032\n",
      "Loss after mini-batch    10: 0.045\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.030\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.027\n",
      "Loss after mini-batch     5: 0.014\n",
      "Loss after mini-batch     6: 0.012\n",
      "Loss after mini-batch     7: 0.035\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.023\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.037\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.018\n",
      "Loss after mini-batch     4: 0.013\n",
      "Loss after mini-batch     5: 0.013\n",
      "Loss after mini-batch     6: 0.014\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.018\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.059\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.016\n",
      "Loss after mini-batch     2: 0.021\n",
      "Loss after mini-batch     3: 0.031\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.019\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.009\n",
      "Loss after mini-batch     9: 0.011\n",
      "Loss after mini-batch    10: 0.012\n",
      "Loss after mini-batch    11: 0.050\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.004\n",
      "Loss after mini-batch     3: 0.007\n",
      "Loss after mini-batch     4: 0.016\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.033\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.011\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.019\n",
      "Loss after mini-batch    11: 0.020\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.014\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.023\n",
      "Loss after mini-batch     7: 0.018\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.010\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.007\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.008\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.016\n",
      "Loss after mini-batch     6: 0.005\n",
      "Loss after mini-batch     7: 0.010\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.004\n",
      "Loss after mini-batch     8: 0.010\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.010\n",
      "Loss after mini-batch    11: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 7: 89 %\n",
      "--------------------------------\n",
      "FOLD 8\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.722\n",
      "Loss after mini-batch     2: 0.856\n",
      "Loss after mini-batch     3: 0.616\n",
      "Loss after mini-batch     4: 0.488\n",
      "Loss after mini-batch     5: 0.842\n",
      "Loss after mini-batch     6: 0.766\n",
      "Loss after mini-batch     7: 0.602\n",
      "Loss after mini-batch     8: 0.901\n",
      "Loss after mini-batch     9: 0.443\n",
      "Loss after mini-batch    10: 0.712\n",
      "Loss after mini-batch    11: 0.505\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.574\n",
      "Loss after mini-batch     2: 0.600\n",
      "Loss after mini-batch     3: 0.502\n",
      "Loss after mini-batch     4: 0.532\n",
      "Loss after mini-batch     5: 0.514\n",
      "Loss after mini-batch     6: 0.512\n",
      "Loss after mini-batch     7: 0.405\n",
      "Loss after mini-batch     8: 0.459\n",
      "Loss after mini-batch     9: 0.429\n",
      "Loss after mini-batch    10: 0.432\n",
      "Loss after mini-batch    11: 0.490\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.316\n",
      "Loss after mini-batch     2: 0.414\n",
      "Loss after mini-batch     3: 0.344\n",
      "Loss after mini-batch     4: 0.482\n",
      "Loss after mini-batch     5: 0.319\n",
      "Loss after mini-batch     6: 0.347\n",
      "Loss after mini-batch     7: 0.471\n",
      "Loss after mini-batch     8: 0.394\n",
      "Loss after mini-batch     9: 0.521\n",
      "Loss after mini-batch    10: 0.434\n",
      "Loss after mini-batch    11: 0.112\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.396\n",
      "Loss after mini-batch     2: 0.243\n",
      "Loss after mini-batch     3: 0.126\n",
      "Loss after mini-batch     4: 0.173\n",
      "Loss after mini-batch     5: 0.300\n",
      "Loss after mini-batch     6: 0.417\n",
      "Loss after mini-batch     7: 0.174\n",
      "Loss after mini-batch     8: 0.324\n",
      "Loss after mini-batch     9: 0.459\n",
      "Loss after mini-batch    10: 0.366\n",
      "Loss after mini-batch    11: 0.028\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.187\n",
      "Loss after mini-batch     2: 0.295\n",
      "Loss after mini-batch     3: 0.140\n",
      "Loss after mini-batch     4: 0.320\n",
      "Loss after mini-batch     5: 0.300\n",
      "Loss after mini-batch     6: 0.127\n",
      "Loss after mini-batch     7: 0.216\n",
      "Loss after mini-batch     8: 0.294\n",
      "Loss after mini-batch     9: 0.163\n",
      "Loss after mini-batch    10: 0.169\n",
      "Loss after mini-batch    11: 0.232\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.212\n",
      "Loss after mini-batch     2: 0.157\n",
      "Loss after mini-batch     3: 0.193\n",
      "Loss after mini-batch     4: 0.296\n",
      "Loss after mini-batch     5: 0.180\n",
      "Loss after mini-batch     6: 0.094\n",
      "Loss after mini-batch     7: 0.088\n",
      "Loss after mini-batch     8: 0.230\n",
      "Loss after mini-batch     9: 0.290\n",
      "Loss after mini-batch    10: 0.136\n",
      "Loss after mini-batch    11: 0.042\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.190\n",
      "Loss after mini-batch     2: 0.139\n",
      "Loss after mini-batch     3: 0.070\n",
      "Loss after mini-batch     4: 0.127\n",
      "Loss after mini-batch     5: 0.077\n",
      "Loss after mini-batch     6: 0.089\n",
      "Loss after mini-batch     7: 0.162\n",
      "Loss after mini-batch     8: 0.207\n",
      "Loss after mini-batch     9: 0.105\n",
      "Loss after mini-batch    10: 0.133\n",
      "Loss after mini-batch    11: 0.119\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.041\n",
      "Loss after mini-batch     2: 0.118\n",
      "Loss after mini-batch     3: 0.112\n",
      "Loss after mini-batch     4: 0.158\n",
      "Loss after mini-batch     5: 0.118\n",
      "Loss after mini-batch     6: 0.089\n",
      "Loss after mini-batch     7: 0.116\n",
      "Loss after mini-batch     8: 0.046\n",
      "Loss after mini-batch     9: 0.067\n",
      "Loss after mini-batch    10: 0.044\n",
      "Loss after mini-batch    11: 0.160\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.098\n",
      "Loss after mini-batch     2: 0.047\n",
      "Loss after mini-batch     3: 0.129\n",
      "Loss after mini-batch     4: 0.101\n",
      "Loss after mini-batch     5: 0.101\n",
      "Loss after mini-batch     6: 0.064\n",
      "Loss after mini-batch     7: 0.040\n",
      "Loss after mini-batch     8: 0.094\n",
      "Loss after mini-batch     9: 0.069\n",
      "Loss after mini-batch    10: 0.061\n",
      "Loss after mini-batch    11: 0.036\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.123\n",
      "Loss after mini-batch     2: 0.018\n",
      "Loss after mini-batch     3: 0.047\n",
      "Loss after mini-batch     4: 0.055\n",
      "Loss after mini-batch     5: 0.080\n",
      "Loss after mini-batch     6: 0.048\n",
      "Loss after mini-batch     7: 0.035\n",
      "Loss after mini-batch     8: 0.035\n",
      "Loss after mini-batch     9: 0.068\n",
      "Loss after mini-batch    10: 0.024\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.041\n",
      "Loss after mini-batch     2: 0.027\n",
      "Loss after mini-batch     3: 0.044\n",
      "Loss after mini-batch     4: 0.010\n",
      "Loss after mini-batch     5: 0.020\n",
      "Loss after mini-batch     6: 0.026\n",
      "Loss after mini-batch     7: 0.015\n",
      "Loss after mini-batch     8: 0.089\n",
      "Loss after mini-batch     9: 0.020\n",
      "Loss after mini-batch    10: 0.023\n",
      "Loss after mini-batch    11: 0.087\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.020\n",
      "Loss after mini-batch     2: 0.036\n",
      "Loss after mini-batch     3: 0.012\n",
      "Loss after mini-batch     4: 0.032\n",
      "Loss after mini-batch     5: 0.012\n",
      "Loss after mini-batch     6: 0.019\n",
      "Loss after mini-batch     7: 0.033\n",
      "Loss after mini-batch     8: 0.031\n",
      "Loss after mini-batch     9: 0.023\n",
      "Loss after mini-batch    10: 0.081\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.009\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.095\n",
      "Loss after mini-batch     5: 0.024\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.037\n",
      "Loss after mini-batch     8: 0.015\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    11: 0.023\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.013\n",
      "Loss after mini-batch     2: 0.006\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.012\n",
      "Loss after mini-batch     5: 0.002\n",
      "Loss after mini-batch     6: 0.009\n",
      "Loss after mini-batch     7: 0.047\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.014\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.007\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.040\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.023\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.007\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    11: 0.015\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.008\n",
      "Loss after mini-batch     2: 0.035\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.004\n",
      "Loss after mini-batch     7: 0.007\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.021\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.013\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.032\n",
      "Loss after mini-batch     2: 0.003\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.012\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.008\n",
      "Loss after mini-batch     8: 0.008\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.005\n",
      "Loss after mini-batch     2: 0.029\n",
      "Loss after mini-batch     3: 0.003\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.006\n",
      "Loss after mini-batch     8: 0.019\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.022\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.006\n",
      "Loss after mini-batch     4: 0.001\n",
      "Loss after mini-batch     5: 0.004\n",
      "Loss after mini-batch     6: 0.013\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.010\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.005\n",
      "Loss after mini-batch     4: 0.024\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.003\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.002\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 8: 82 %\n",
      "--------------------------------\n",
      "FOLD 9\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 0.702\n",
      "Loss after mini-batch     2: 0.963\n",
      "Loss after mini-batch     3: 0.720\n",
      "Loss after mini-batch     4: 0.684\n",
      "Loss after mini-batch     5: 1.064\n",
      "Loss after mini-batch     6: 0.997\n",
      "Loss after mini-batch     7: 0.644\n",
      "Loss after mini-batch     8: 0.670\n",
      "Loss after mini-batch     9: 0.642\n",
      "Loss after mini-batch    10: 0.714\n",
      "Loss after mini-batch    11: 0.439\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.747\n",
      "Loss after mini-batch     2: 0.732\n",
      "Loss after mini-batch     3: 0.686\n",
      "Loss after mini-batch     4: 0.854\n",
      "Loss after mini-batch     5: 0.684\n",
      "Loss after mini-batch     6: 0.686\n",
      "Loss after mini-batch     7: 0.719\n",
      "Loss after mini-batch     8: 0.694\n",
      "Loss after mini-batch     9: 0.690\n",
      "Loss after mini-batch    10: 0.653\n",
      "Loss after mini-batch    11: 0.627\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.641\n",
      "Loss after mini-batch     2: 0.603\n",
      "Loss after mini-batch     3: 0.548\n",
      "Loss after mini-batch     4: 0.634\n",
      "Loss after mini-batch     5: 0.541\n",
      "Loss after mini-batch     6: 0.640\n",
      "Loss after mini-batch     7: 0.695\n",
      "Loss after mini-batch     8: 0.599\n",
      "Loss after mini-batch     9: 0.581\n",
      "Loss after mini-batch    10: 0.536\n",
      "Loss after mini-batch    11: 0.847\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 0.529\n",
      "Loss after mini-batch     2: 0.513\n",
      "Loss after mini-batch     3: 0.530\n",
      "Loss after mini-batch     4: 0.632\n",
      "Loss after mini-batch     5: 0.490\n",
      "Loss after mini-batch     6: 0.422\n",
      "Loss after mini-batch     7: 0.392\n",
      "Loss after mini-batch     8: 0.478\n",
      "Loss after mini-batch     9: 0.503\n",
      "Loss after mini-batch    10: 0.523\n",
      "Loss after mini-batch    11: 0.300\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 0.460\n",
      "Loss after mini-batch     2: 0.350\n",
      "Loss after mini-batch     3: 0.315\n",
      "Loss after mini-batch     4: 0.332\n",
      "Loss after mini-batch     5: 0.489\n",
      "Loss after mini-batch     6: 0.485\n",
      "Loss after mini-batch     7: 0.503\n",
      "Loss after mini-batch     8: 0.354\n",
      "Loss after mini-batch     9: 0.238\n",
      "Loss after mini-batch    10: 0.461\n",
      "Loss after mini-batch    11: 0.322\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.356\n",
      "Loss after mini-batch     2: 0.353\n",
      "Loss after mini-batch     3: 0.288\n",
      "Loss after mini-batch     4: 0.347\n",
      "Loss after mini-batch     5: 0.231\n",
      "Loss after mini-batch     6: 0.391\n",
      "Loss after mini-batch     7: 0.252\n",
      "Loss after mini-batch     8: 0.378\n",
      "Loss after mini-batch     9: 0.134\n",
      "Loss after mini-batch    10: 0.341\n",
      "Loss after mini-batch    11: 0.272\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.415\n",
      "Loss after mini-batch     2: 0.409\n",
      "Loss after mini-batch     3: 0.261\n",
      "Loss after mini-batch     4: 0.322\n",
      "Loss after mini-batch     5: 0.307\n",
      "Loss after mini-batch     6: 0.308\n",
      "Loss after mini-batch     7: 0.095\n",
      "Loss after mini-batch     8: 0.297\n",
      "Loss after mini-batch     9: 0.289\n",
      "Loss after mini-batch    10: 0.228\n",
      "Loss after mini-batch    11: 0.004\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 0.184\n",
      "Loss after mini-batch     2: 0.349\n",
      "Loss after mini-batch     3: 0.143\n",
      "Loss after mini-batch     4: 0.102\n",
      "Loss after mini-batch     5: 0.183\n",
      "Loss after mini-batch     6: 0.181\n",
      "Loss after mini-batch     7: 0.210\n",
      "Loss after mini-batch     8: 0.129\n",
      "Loss after mini-batch     9: 0.278\n",
      "Loss after mini-batch    10: 0.095\n",
      "Loss after mini-batch    11: 0.085\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 0.055\n",
      "Loss after mini-batch     2: 0.071\n",
      "Loss after mini-batch     3: 0.241\n",
      "Loss after mini-batch     4: 0.160\n",
      "Loss after mini-batch     5: 0.067\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.126\n",
      "Loss after mini-batch     8: 0.108\n",
      "Loss after mini-batch     9: 0.190\n",
      "Loss after mini-batch    10: 0.150\n",
      "Loss after mini-batch    11: 0.077\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.121\n",
      "Loss after mini-batch     2: 0.030\n",
      "Loss after mini-batch     3: 0.188\n",
      "Loss after mini-batch     4: 0.114\n",
      "Loss after mini-batch     5: 0.067\n",
      "Loss after mini-batch     6: 0.149\n",
      "Loss after mini-batch     7: 0.108\n",
      "Loss after mini-batch     8: 0.070\n",
      "Loss after mini-batch     9: 0.081\n",
      "Loss after mini-batch    10: 0.119\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 0.057\n",
      "Loss after mini-batch     2: 0.096\n",
      "Loss after mini-batch     3: 0.098\n",
      "Loss after mini-batch     4: 0.036\n",
      "Loss after mini-batch     5: 0.073\n",
      "Loss after mini-batch     6: 0.066\n",
      "Loss after mini-batch     7: 0.102\n",
      "Loss after mini-batch     8: 0.059\n",
      "Loss after mini-batch     9: 0.078\n",
      "Loss after mini-batch    10: 0.040\n",
      "Loss after mini-batch    11: 0.024\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.090\n",
      "Loss after mini-batch     2: 0.037\n",
      "Loss after mini-batch     3: 0.021\n",
      "Loss after mini-batch     4: 0.032\n",
      "Loss after mini-batch     5: 0.015\n",
      "Loss after mini-batch     6: 0.052\n",
      "Loss after mini-batch     7: 0.075\n",
      "Loss after mini-batch     8: 0.101\n",
      "Loss after mini-batch     9: 0.029\n",
      "Loss after mini-batch    10: 0.030\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.046\n",
      "Loss after mini-batch     2: 0.036\n",
      "Loss after mini-batch     3: 0.022\n",
      "Loss after mini-batch     4: 0.038\n",
      "Loss after mini-batch     5: 0.050\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.016\n",
      "Loss after mini-batch     8: 0.017\n",
      "Loss after mini-batch     9: 0.048\n",
      "Loss after mini-batch    10: 0.046\n",
      "Loss after mini-batch    11: 0.014\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.013\n",
      "Loss after mini-batch     4: 0.024\n",
      "Loss after mini-batch     5: 0.035\n",
      "Loss after mini-batch     6: 0.025\n",
      "Loss after mini-batch     7: 0.022\n",
      "Loss after mini-batch     8: 0.023\n",
      "Loss after mini-batch     9: 0.007\n",
      "Loss after mini-batch    10: 0.018\n",
      "Loss after mini-batch    11: 0.013\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.012\n",
      "Loss after mini-batch     2: 0.010\n",
      "Loss after mini-batch     3: 0.023\n",
      "Loss after mini-batch     4: 0.009\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.041\n",
      "Loss after mini-batch     7: 0.017\n",
      "Loss after mini-batch     8: 0.006\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.009\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.013\n",
      "Loss after mini-batch     2: 0.011\n",
      "Loss after mini-batch     3: 0.037\n",
      "Loss after mini-batch     4: 0.006\n",
      "Loss after mini-batch     5: 0.005\n",
      "Loss after mini-batch     6: 0.007\n",
      "Loss after mini-batch     7: 0.005\n",
      "Loss after mini-batch     8: 0.014\n",
      "Loss after mini-batch     9: 0.006\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.001\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.011\n",
      "Loss after mini-batch     2: 0.014\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.005\n",
      "Loss after mini-batch     5: 0.009\n",
      "Loss after mini-batch     6: 0.010\n",
      "Loss after mini-batch     7: 0.021\n",
      "Loss after mini-batch     8: 0.003\n",
      "Loss after mini-batch     9: 0.004\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    11: 0.003\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.006\n",
      "Loss after mini-batch     2: 0.023\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.004\n",
      "Loss after mini-batch     5: 0.006\n",
      "Loss after mini-batch     6: 0.020\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.002\n",
      "Loss after mini-batch     9: 0.009\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.005\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 0.014\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.002\n",
      "Loss after mini-batch     4: 0.008\n",
      "Loss after mini-batch     5: 0.003\n",
      "Loss after mini-batch     6: 0.016\n",
      "Loss after mini-batch     7: 0.003\n",
      "Loss after mini-batch     8: 0.005\n",
      "Loss after mini-batch     9: 0.005\n",
      "Loss after mini-batch    10: 0.006\n",
      "Loss after mini-batch    11: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 0.003\n",
      "Loss after mini-batch     2: 0.002\n",
      "Loss after mini-batch     3: 0.004\n",
      "Loss after mini-batch     4: 0.003\n",
      "Loss after mini-batch     5: 0.010\n",
      "Loss after mini-batch     6: 0.006\n",
      "Loss after mini-batch     7: 0.002\n",
      "Loss after mini-batch     8: 0.015\n",
      "Loss after mini-batch     9: 0.003\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    11: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 9: 82 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 10 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 78.57142857142857 %\n",
      "Fold 1: 96.42857142857143 %\n",
      "Fold 2: 85.71428571428571 %\n",
      "Fold 3: 82.14285714285714 %\n",
      "Fold 4: 85.71428571428571 %\n",
      "Fold 5: 89.28571428571429 %\n",
      "Fold 6: 92.85714285714286 %\n",
      "Fold 7: 89.28571428571429 %\n",
      "Fold 8: 82.14285714285714 %\n",
      "Fold 9: 82.14285714285714 %\n",
      "Average: 86.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 10\n",
    "  num_epochs = 20\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=25, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=25, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    30: 0.045\n",
      "Loss after mini-batch    40: 0.005\n",
      "Loss after mini-batch    50: 0.069\n",
      "Loss after mini-batch    60: 0.013\n",
      "Loss after mini-batch    70: 0.013\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.005\n",
      "Loss after mini-batch   100: 0.012\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.006\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 87 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.002\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.010\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.169\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.010\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.066\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.003\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.004\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 87 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.205\n",
      "Loss after mini-batch    20: 0.057\n",
      "Loss after mini-batch    30: 0.017\n",
      "Loss after mini-batch    40: 0.044\n",
      "Loss after mini-batch    50: 0.022\n",
      "Loss after mini-batch    60: 0.020\n",
      "Loss after mini-batch    70: 0.025\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.002\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.008\n",
      "Loss after mini-batch   120: 0.009\n",
      "Loss after mini-batch   130: 0.003\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.006\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.062\n",
      "Loss after mini-batch   180: 0.007\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.004\n",
      "Loss after mini-batch   220: 0.017\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.009\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.002\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.002\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 87 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    30: 0.125\n",
      "Loss after mini-batch    40: 0.358\n",
      "Loss after mini-batch    50: 0.028\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.116\n",
      "Loss after mini-batch    80: 0.113\n",
      "Loss after mini-batch    90: 0.539\n",
      "Loss after mini-batch   100: 0.017\n",
      "Loss after mini-batch   110: 0.133\n",
      "Loss after mini-batch   120: 0.016\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.042\n",
      "Loss after mini-batch   150: 0.009\n",
      "Loss after mini-batch   160: 0.219\n",
      "Loss after mini-batch   170: 0.013\n",
      "Loss after mini-batch   180: 0.005\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.007\n",
      "Loss after mini-batch   220: 0.010\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.006\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.004\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.006\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 87 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 10\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.068\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.002\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.005\n",
      "Loss after mini-batch   140: 0.003\n",
      "Loss after mini-batch   150: 0.038\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.002\n",
      "Loss after mini-batch   180: 0.023\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.002\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 20\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.002\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.004\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 30\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 40\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 80 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 87.5 %\n",
      "Fold 1: 87.5 %\n",
      "Fold 2: 87.5 %\n",
      "Fold 3: 87.5 %\n",
      "Fold 4: 80.35714285714286 %\n",
      "Average: 86.07142857142858 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 40\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch % 10 ==9:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch % 10 ==9:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.225\n",
      "Loss after mini-batch    20: 0.077\n",
      "Loss after mini-batch    30: 2.602\n",
      "Loss after mini-batch    40: 2.168\n",
      "Loss after mini-batch    50: 0.330\n",
      "Loss after mini-batch    60: 0.875\n",
      "Loss after mini-batch    70: 1.741\n",
      "Loss after mini-batch    80: 2.421\n",
      "Loss after mini-batch    90: 2.457\n",
      "Loss after mini-batch   100: 1.753\n",
      "Loss after mini-batch   110: 0.615\n",
      "Loss after mini-batch   120: 0.442\n",
      "Loss after mini-batch   130: 2.736\n",
      "Loss after mini-batch   140: 0.269\n",
      "Loss after mini-batch   150: 0.822\n",
      "Loss after mini-batch   160: 0.984\n",
      "Loss after mini-batch   170: 0.749\n",
      "Loss after mini-batch   180: 2.489\n",
      "Loss after mini-batch   190: 1.214\n",
      "Loss after mini-batch   200: 2.678\n",
      "Loss after mini-batch   210: 0.687\n",
      "Loss after mini-batch   220: 0.802\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.216\n",
      "Loss after mini-batch    20: 1.969\n",
      "Loss after mini-batch    30: 0.376\n",
      "Loss after mini-batch    40: 0.043\n",
      "Loss after mini-batch    50: 1.356\n",
      "Loss after mini-batch    60: 0.468\n",
      "Loss after mini-batch    70: 0.054\n",
      "Loss after mini-batch    80: 0.106\n",
      "Loss after mini-batch    90: 0.007\n",
      "Loss after mini-batch   100: 0.283\n",
      "Loss after mini-batch   110: 0.120\n",
      "Loss after mini-batch   120: 0.189\n",
      "Loss after mini-batch   130: 0.199\n",
      "Loss after mini-batch   140: 0.002\n",
      "Loss after mini-batch   150: 0.043\n",
      "Loss after mini-batch   160: 0.076\n",
      "Loss after mini-batch   170: 0.022\n",
      "Loss after mini-batch   180: 0.017\n",
      "Loss after mini-batch   190: 0.237\n",
      "Loss after mini-batch   200: 0.449\n",
      "Loss after mini-batch   210: 0.039\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.008\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.010\n",
      "Loss after mini-batch    50: 0.004\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.009\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.004\n",
      "Loss after mini-batch   110: 0.003\n",
      "Loss after mini-batch   120: 0.012\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.234\n",
      "Loss after mini-batch   160: 0.003\n",
      "Loss after mini-batch   170: 0.130\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.005\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 1.120\n",
      "Loss after mini-batch   220: 0.003\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.008\n",
      "Loss after mini-batch    20: 0.153\n",
      "Loss after mini-batch    30: 0.127\n",
      "Loss after mini-batch    40: 0.021\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.002\n",
      "Loss after mini-batch    70: 0.365\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.037\n",
      "Loss after mini-batch   100: 0.024\n",
      "Loss after mini-batch   110: 0.008\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.056\n",
      "Loss after mini-batch   140: 0.002\n",
      "Loss after mini-batch   150: 0.023\n",
      "Loss after mini-batch   160: 0.060\n",
      "Loss after mini-batch   170: 0.046\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.404\n",
      "Loss after mini-batch   200: 0.002\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.715\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.010\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.001\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.183\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.125\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.059\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.016\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.017\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.031\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.036\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 87 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 2.024\n",
      "Loss after mini-batch    20: 0.268\n",
      "Loss after mini-batch    30: 1.106\n",
      "Loss after mini-batch    40: 1.694\n",
      "Loss after mini-batch    50: 1.569\n",
      "Loss after mini-batch    60: 0.492\n",
      "Loss after mini-batch    70: 0.521\n",
      "Loss after mini-batch    80: 0.479\n",
      "Loss after mini-batch    90: 2.684\n",
      "Loss after mini-batch   100: 3.012\n",
      "Loss after mini-batch   110: 1.785\n",
      "Loss after mini-batch   120: 2.217\n",
      "Loss after mini-batch   130: 2.127\n",
      "Loss after mini-batch   140: 1.031\n",
      "Loss after mini-batch   150: 0.372\n",
      "Loss after mini-batch   160: 3.770\n",
      "Loss after mini-batch   170: 0.438\n",
      "Loss after mini-batch   180: 1.738\n",
      "Loss after mini-batch   190: 0.594\n",
      "Loss after mini-batch   200: 0.538\n",
      "Loss after mini-batch   210: 0.334\n",
      "Loss after mini-batch   220: 0.680\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.007\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    30: 0.011\n",
      "Loss after mini-batch    40: 0.054\n",
      "Loss after mini-batch    50: 0.008\n",
      "Loss after mini-batch    60: 0.047\n",
      "Loss after mini-batch    70: 0.088\n",
      "Loss after mini-batch    80: 0.022\n",
      "Loss after mini-batch    90: 0.017\n",
      "Loss after mini-batch   100: 0.011\n",
      "Loss after mini-batch   110: 0.063\n",
      "Loss after mini-batch   120: 0.007\n",
      "Loss after mini-batch   130: 0.077\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.006\n",
      "Loss after mini-batch   160: 0.035\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.003\n",
      "Loss after mini-batch   190: 0.312\n",
      "Loss after mini-batch   200: 0.018\n",
      "Loss after mini-batch   210: 0.341\n",
      "Loss after mini-batch   220: 0.100\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.003\n",
      "Loss after mini-batch    40: 0.009\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.007\n",
      "Loss after mini-batch    70: 0.011\n",
      "Loss after mini-batch    80: 0.004\n",
      "Loss after mini-batch    90: 0.032\n",
      "Loss after mini-batch   100: 0.003\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.012\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.049\n",
      "Loss after mini-batch   220: 0.001\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.002\n",
      "Loss after mini-batch    90: 0.015\n",
      "Loss after mini-batch   100: 0.002\n",
      "Loss after mini-batch   110: 0.005\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.005\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.011\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.002\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.009\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.004\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.002\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.004\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.002\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 83 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.702\n",
      "Loss after mini-batch    20: 5.959\n",
      "Loss after mini-batch    30: 1.309\n",
      "Loss after mini-batch    40: 0.102\n",
      "Loss after mini-batch    50: 0.695\n",
      "Loss after mini-batch    60: 1.126\n",
      "Loss after mini-batch    70: 1.401\n",
      "Loss after mini-batch    80: 1.299\n",
      "Loss after mini-batch    90: 0.606\n",
      "Loss after mini-batch   100: 2.343\n",
      "Loss after mini-batch   110: 0.525\n",
      "Loss after mini-batch   120: 0.711\n",
      "Loss after mini-batch   130: 0.194\n",
      "Loss after mini-batch   140: 0.114\n",
      "Loss after mini-batch   150: 0.206\n",
      "Loss after mini-batch   160: 0.404\n",
      "Loss after mini-batch   170: 1.155\n",
      "Loss after mini-batch   180: 2.787\n",
      "Loss after mini-batch   190: 1.382\n",
      "Loss after mini-batch   200: 0.593\n",
      "Loss after mini-batch   210: 0.889\n",
      "Loss after mini-batch   220: 0.623\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.034\n",
      "Loss after mini-batch    20: 0.176\n",
      "Loss after mini-batch    30: 0.070\n",
      "Loss after mini-batch    40: 0.008\n",
      "Loss after mini-batch    50: 0.003\n",
      "Loss after mini-batch    60: 0.010\n",
      "Loss after mini-batch    70: 0.056\n",
      "Loss after mini-batch    80: 0.013\n",
      "Loss after mini-batch    90: 0.566\n",
      "Loss after mini-batch   100: 0.060\n",
      "Loss after mini-batch   110: 0.007\n",
      "Loss after mini-batch   120: 0.016\n",
      "Loss after mini-batch   130: 0.277\n",
      "Loss after mini-batch   140: 0.209\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.047\n",
      "Loss after mini-batch   170: 0.047\n",
      "Loss after mini-batch   180: 0.046\n",
      "Loss after mini-batch   190: 0.048\n",
      "Loss after mini-batch   200: 0.046\n",
      "Loss after mini-batch   210: 0.351\n",
      "Loss after mini-batch   220: 1.633\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.007\n",
      "Loss after mini-batch    30: 0.007\n",
      "Loss after mini-batch    40: 0.006\n",
      "Loss after mini-batch    50: 0.005\n",
      "Loss after mini-batch    60: 0.003\n",
      "Loss after mini-batch    70: 0.002\n",
      "Loss after mini-batch    80: 0.275\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.010\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.063\n",
      "Loss after mini-batch   140: 0.008\n",
      "Loss after mini-batch   150: 0.013\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.163\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.006\n",
      "Loss after mini-batch   220: 0.004\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.047\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.005\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.036\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.012\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.020\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.004\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.014\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 80 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.649\n",
      "Loss after mini-batch    20: 2.344\n",
      "Loss after mini-batch    30: 1.540\n",
      "Loss after mini-batch    40: 2.161\n",
      "Loss after mini-batch    50: 1.220\n",
      "Loss after mini-batch    60: 4.171\n",
      "Loss after mini-batch    70: 2.005\n",
      "Loss after mini-batch    80: 1.980\n",
      "Loss after mini-batch    90: 1.279\n",
      "Loss after mini-batch   100: 1.619\n",
      "Loss after mini-batch   110: 3.732\n",
      "Loss after mini-batch   120: 0.313\n",
      "Loss after mini-batch   130: 1.455\n",
      "Loss after mini-batch   140: 4.089\n",
      "Loss after mini-batch   150: 0.973\n",
      "Loss after mini-batch   160: 0.742\n",
      "Loss after mini-batch   170: 0.919\n",
      "Loss after mini-batch   180: 0.149\n",
      "Loss after mini-batch   190: 3.611\n",
      "Loss after mini-batch   200: 1.646\n",
      "Loss after mini-batch   210: 2.768\n",
      "Loss after mini-batch   220: 1.055\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.263\n",
      "Loss after mini-batch    20: 0.118\n",
      "Loss after mini-batch    30: 0.654\n",
      "Loss after mini-batch    40: 0.060\n",
      "Loss after mini-batch    50: 0.059\n",
      "Loss after mini-batch    60: 1.110\n",
      "Loss after mini-batch    70: 0.110\n",
      "Loss after mini-batch    80: 0.761\n",
      "Loss after mini-batch    90: 0.027\n",
      "Loss after mini-batch   100: 0.109\n",
      "Loss after mini-batch   110: 0.690\n",
      "Loss after mini-batch   120: 0.120\n",
      "Loss after mini-batch   130: 0.084\n",
      "Loss after mini-batch   140: 0.022\n",
      "Loss after mini-batch   150: 0.101\n",
      "Loss after mini-batch   160: 1.058\n",
      "Loss after mini-batch   170: 0.026\n",
      "Loss after mini-batch   180: 0.423\n",
      "Loss after mini-batch   190: 0.262\n",
      "Loss after mini-batch   200: 0.286\n",
      "Loss after mini-batch   210: 0.016\n",
      "Loss after mini-batch   220: 0.346\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    30: 0.017\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 0.007\n",
      "Loss after mini-batch    60: 0.006\n",
      "Loss after mini-batch    70: 0.094\n",
      "Loss after mini-batch    80: 0.011\n",
      "Loss after mini-batch    90: 0.858\n",
      "Loss after mini-batch   100: 0.029\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.011\n",
      "Loss after mini-batch   130: 0.003\n",
      "Loss after mini-batch   140: 0.039\n",
      "Loss after mini-batch   150: 0.678\n",
      "Loss after mini-batch   160: 0.463\n",
      "Loss after mini-batch   170: 0.008\n",
      "Loss after mini-batch   180: 0.002\n",
      "Loss after mini-batch   190: 0.020\n",
      "Loss after mini-batch   200: 0.004\n",
      "Loss after mini-batch   210: 0.006\n",
      "Loss after mini-batch   220: 0.004\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.063\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    30: 0.005\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.529\n",
      "Loss after mini-batch    60: 0.157\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.359\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 3.027\n",
      "Loss after mini-batch   130: 1.212\n",
      "Loss after mini-batch   140: 0.005\n",
      "Loss after mini-batch   150: 0.231\n",
      "Loss after mini-batch   160: 0.003\n",
      "Loss after mini-batch   170: 0.003\n",
      "Loss after mini-batch   180: 0.014\n",
      "Loss after mini-batch   190: 4.098\n",
      "Loss after mini-batch   200: 0.681\n",
      "Loss after mini-batch   210: 12.778\n",
      "Loss after mini-batch   220: 0.667\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.203\n",
      "Loss after mini-batch    20: 0.002\n",
      "Loss after mini-batch    30: 0.011\n",
      "Loss after mini-batch    40: 0.644\n",
      "Loss after mini-batch    50: 0.021\n",
      "Loss after mini-batch    60: 0.020\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.060\n",
      "Loss after mini-batch    90: 0.020\n",
      "Loss after mini-batch   100: 0.018\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.010\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.045\n",
      "Loss after mini-batch   170: 0.002\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.372\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.043\n",
      "Loss after mini-batch   220: 1.081\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.005\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.003\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.002\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.001\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.034\n",
      "Loss after mini-batch   170: 0.023\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.002\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 85 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 2.817\n",
      "Loss after mini-batch    20: 2.882\n",
      "Loss after mini-batch    30: 2.032\n",
      "Loss after mini-batch    40: 2.269\n",
      "Loss after mini-batch    50: 3.122\n",
      "Loss after mini-batch    60: 0.351\n",
      "Loss after mini-batch    70: 1.216\n",
      "Loss after mini-batch    80: 0.697\n",
      "Loss after mini-batch    90: 0.305\n",
      "Loss after mini-batch   100: 3.306\n",
      "Loss after mini-batch   110: 0.421\n",
      "Loss after mini-batch   120: 4.786\n",
      "Loss after mini-batch   130: 2.894\n",
      "Loss after mini-batch   140: 0.387\n",
      "Loss after mini-batch   150: 0.965\n",
      "Loss after mini-batch   160: 0.693\n",
      "Loss after mini-batch   170: 0.904\n",
      "Loss after mini-batch   180: 2.186\n",
      "Loss after mini-batch   190: 0.234\n",
      "Loss after mini-batch   200: 1.243\n",
      "Loss after mini-batch   210: 4.626\n",
      "Loss after mini-batch   220: 1.526\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.129\n",
      "Loss after mini-batch    20: 1.204\n",
      "Loss after mini-batch    30: 0.060\n",
      "Loss after mini-batch    40: 0.386\n",
      "Loss after mini-batch    50: 0.859\n",
      "Loss after mini-batch    60: 0.076\n",
      "Loss after mini-batch    70: 0.022\n",
      "Loss after mini-batch    80: 0.161\n",
      "Loss after mini-batch    90: 0.838\n",
      "Loss after mini-batch   100: 0.342\n",
      "Loss after mini-batch   110: 0.054\n",
      "Loss after mini-batch   120: 1.361\n",
      "Loss after mini-batch   130: 0.075\n",
      "Loss after mini-batch   140: 0.103\n",
      "Loss after mini-batch   150: 0.036\n",
      "Loss after mini-batch   160: 0.822\n",
      "Loss after mini-batch   170: 1.437\n",
      "Loss after mini-batch   180: 0.892\n",
      "Loss after mini-batch   190: 0.041\n",
      "Loss after mini-batch   200: 0.644\n",
      "Loss after mini-batch   210: 1.300\n",
      "Loss after mini-batch   220: 0.496\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.015\n",
      "Loss after mini-batch    30: 0.003\n",
      "Loss after mini-batch    40: 0.136\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.006\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.001\n",
      "Loss after mini-batch    90: 0.004\n",
      "Loss after mini-batch   100: 0.010\n",
      "Loss after mini-batch   110: 0.007\n",
      "Loss after mini-batch   120: 0.527\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.063\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.007\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.004\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.122\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 1.520\n",
      "Loss after mini-batch    30: 7.078\n",
      "Loss after mini-batch    40: 0.005\n",
      "Loss after mini-batch    50: 0.669\n",
      "Loss after mini-batch    60: 0.080\n",
      "Loss after mini-batch    70: 0.059\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.352\n",
      "Loss after mini-batch   100: 0.066\n",
      "Loss after mini-batch   110: 0.103\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.369\n",
      "Loss after mini-batch   150: 0.189\n",
      "Loss after mini-batch   160: 0.029\n",
      "Loss after mini-batch   170: 0.267\n",
      "Loss after mini-batch   180: 0.026\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.007\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.142\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.026\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.003\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.278\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.007\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.028\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.002\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.001\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 96 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 87.5 %\n",
      "Fold 1: 83.92857142857143 %\n",
      "Fold 2: 80.35714285714286 %\n",
      "Fold 3: 85.71428571428571 %\n",
      "Fold 4: 96.42857142857143 %\n",
      "Average: 86.78571428571429 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 18\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch % 3 ==2:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch % 3 == 2:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 3.132\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 1.293\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.323\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.147\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.030\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.023\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 94 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 3.120\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.759\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.152\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.082\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.013\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.015\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 80 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 5.732\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 3.409\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 1.577\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.681\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.356\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.181\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 87 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 3.635\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 1.942\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.948\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.264\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.095\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.037\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 76 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.000\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 1.908\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.811\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.271\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.039\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.074\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 85 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 94.64285714285714 %\n",
      "Fold 1: 80.35714285714286 %\n",
      "Fold 2: 87.5 %\n",
      "Fold 3: 76.78571428571429 %\n",
      "Fold 4: 85.71428571428571 %\n",
      "Average: 85.0 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 18\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=15, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=15, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch % 3 ==2:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch % 3 == 2:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.158\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 1.760\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.366\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.120\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.079\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.023\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    10: 0.014\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    10: 0.011\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    10: 0.009\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 87 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.469\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 2.541\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 1.337\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.718\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.163\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.116\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    10: 0.069\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    10: 0.029\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    10: 0.018\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 87 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 3.694\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 2.310\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.712\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.179\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.059\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.027\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    10: 0.010\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    10: 0.009\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    10: 0.004\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 82 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.260\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 2.027\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 1.043\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.336\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.135\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.055\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    10: 0.026\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    10: 0.008\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    10: 0.014\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 87 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=50, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=50, out_features=20, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=20, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 4.281\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 2.349\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 1.265\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.496\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.180\n",
      "Starting epoch 18\n",
      "Loss after mini-batch    10: 0.124\n",
      "Starting epoch 21\n",
      "Loss after mini-batch    10: 0.075\n",
      "Starting epoch 24\n",
      "Loss after mini-batch    10: 0.015\n",
      "Starting epoch 27\n",
      "Loss after mini-batch    10: 0.022\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 82 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 87.5 %\n",
      "Fold 1: 87.5 %\n",
      "Fold 2: 82.14285714285714 %\n",
      "Fold 3: 87.5 %\n",
      "Fold 4: 82.14285714285714 %\n",
      "Average: 85.35714285714285 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 50),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(50, 20),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(20, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 27\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=15, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=15, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch % 3 ==2:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch % 3 == 2:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "FOLD 0\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.103\n",
      "Loss after mini-batch    20: 5.597\n",
      "Loss after mini-batch    30: 2.717\n",
      "Loss after mini-batch    40: 0.773\n",
      "Loss after mini-batch    50: 0.859\n",
      "Loss after mini-batch    60: 2.168\n",
      "Loss after mini-batch    70: 1.998\n",
      "Loss after mini-batch    80: 1.618\n",
      "Loss after mini-batch    90: 0.927\n",
      "Loss after mini-batch   100: 0.053\n",
      "Loss after mini-batch   110: 2.174\n",
      "Loss after mini-batch   120: 0.675\n",
      "Loss after mini-batch   130: 4.036\n",
      "Loss after mini-batch   140: 2.962\n",
      "Loss after mini-batch   150: 0.812\n",
      "Loss after mini-batch   160: 1.379\n",
      "Loss after mini-batch   170: 1.401\n",
      "Loss after mini-batch   180: 0.730\n",
      "Loss after mini-batch   190: 2.612\n",
      "Loss after mini-batch   200: 1.062\n",
      "Loss after mini-batch   210: 1.589\n",
      "Loss after mini-batch   220: 0.768\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.589\n",
      "Loss after mini-batch    20: 0.313\n",
      "Loss after mini-batch    30: 0.048\n",
      "Loss after mini-batch    40: 0.010\n",
      "Loss after mini-batch    50: 0.002\n",
      "Loss after mini-batch    60: 0.006\n",
      "Loss after mini-batch    70: 0.125\n",
      "Loss after mini-batch    80: 0.024\n",
      "Loss after mini-batch    90: 0.004\n",
      "Loss after mini-batch   100: 0.175\n",
      "Loss after mini-batch   110: 0.024\n",
      "Loss after mini-batch   120: 0.071\n",
      "Loss after mini-batch   130: 0.216\n",
      "Loss after mini-batch   140: 0.035\n",
      "Loss after mini-batch   150: 0.003\n",
      "Loss after mini-batch   160: 0.181\n",
      "Loss after mini-batch   170: 0.420\n",
      "Loss after mini-batch   180: 0.027\n",
      "Loss after mini-batch   190: 0.008\n",
      "Loss after mini-batch   200: 0.032\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.047\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.003\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.001\n",
      "Loss after mini-batch    90: 0.001\n",
      "Loss after mini-batch   100: 0.018\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.003\n",
      "Loss after mini-batch   130: 0.034\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.069\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.186\n",
      "Loss after mini-batch   180: 0.032\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.308\n",
      "Loss after mini-batch    50: 0.262\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.270\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.006\n",
      "Loss after mini-batch   140: 0.002\n",
      "Loss after mini-batch   150: 0.007\n",
      "Loss after mini-batch   160: 0.227\n",
      "Loss after mini-batch   170: 0.574\n",
      "Loss after mini-batch   180: 0.006\n",
      "Loss after mini-batch   190: 0.001\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.006\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.004\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.002\n",
      "Loss after mini-batch   130: 0.004\n",
      "Loss after mini-batch   140: 0.018\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.003\n",
      "Loss after mini-batch   170: 0.031\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 0: 85 %\n",
      "--------------------------------\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.975\n",
      "Loss after mini-batch    20: 1.474\n",
      "Loss after mini-batch    30: 0.433\n",
      "Loss after mini-batch    40: 0.366\n",
      "Loss after mini-batch    50: 0.388\n",
      "Loss after mini-batch    60: 2.438\n",
      "Loss after mini-batch    70: 0.507\n",
      "Loss after mini-batch    80: 0.929\n",
      "Loss after mini-batch    90: 0.990\n",
      "Loss after mini-batch   100: 1.318\n",
      "Loss after mini-batch   110: 2.888\n",
      "Loss after mini-batch   120: 1.726\n",
      "Loss after mini-batch   130: 1.360\n",
      "Loss after mini-batch   140: 1.060\n",
      "Loss after mini-batch   150: 2.936\n",
      "Loss after mini-batch   160: 0.987\n",
      "Loss after mini-batch   170: 0.072\n",
      "Loss after mini-batch   180: 0.181\n",
      "Loss after mini-batch   190: 0.513\n",
      "Loss after mini-batch   200: 0.036\n",
      "Loss after mini-batch   210: 0.195\n",
      "Loss after mini-batch   220: 0.270\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.029\n",
      "Loss after mini-batch    20: 0.003\n",
      "Loss after mini-batch    30: 0.007\n",
      "Loss after mini-batch    40: 0.033\n",
      "Loss after mini-batch    50: 0.159\n",
      "Loss after mini-batch    60: 0.012\n",
      "Loss after mini-batch    70: 0.005\n",
      "Loss after mini-batch    80: 0.050\n",
      "Loss after mini-batch    90: 0.067\n",
      "Loss after mini-batch   100: 0.018\n",
      "Loss after mini-batch   110: 0.001\n",
      "Loss after mini-batch   120: 0.105\n",
      "Loss after mini-batch   130: 0.022\n",
      "Loss after mini-batch   140: 0.929\n",
      "Loss after mini-batch   150: 0.726\n",
      "Loss after mini-batch   160: 0.004\n",
      "Loss after mini-batch   170: 0.674\n",
      "Loss after mini-batch   180: 0.074\n",
      "Loss after mini-batch   190: 0.021\n",
      "Loss after mini-batch   200: 0.051\n",
      "Loss after mini-batch   210: 0.054\n",
      "Loss after mini-batch   220: 0.011\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.166\n",
      "Loss after mini-batch    30: 0.006\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.176\n",
      "Loss after mini-batch    60: 0.011\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.063\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.029\n",
      "Loss after mini-batch   110: 6.789\n",
      "Loss after mini-batch   120: 3.716\n",
      "Loss after mini-batch   130: 0.076\n",
      "Loss after mini-batch   140: 0.006\n",
      "Loss after mini-batch   150: 1.243\n",
      "Loss after mini-batch   160: 0.012\n",
      "Loss after mini-batch   170: 0.277\n",
      "Loss after mini-batch   180: 1.792\n",
      "Loss after mini-batch   190: 0.045\n",
      "Loss after mini-batch   200: 0.032\n",
      "Loss after mini-batch   210: 0.015\n",
      "Loss after mini-batch   220: 0.147\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.001\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.175\n",
      "Loss after mini-batch    70: 0.012\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.191\n",
      "Loss after mini-batch   100: 0.002\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.947\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.010\n",
      "Loss after mini-batch   190: 0.002\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.002\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.005\n",
      "Loss after mini-batch   180: 0.004\n",
      "Loss after mini-batch   190: 0.109\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 1: 82 %\n",
      "--------------------------------\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.541\n",
      "Loss after mini-batch    20: 0.236\n",
      "Loss after mini-batch    30: 2.100\n",
      "Loss after mini-batch    40: 0.655\n",
      "Loss after mini-batch    50: 0.455\n",
      "Loss after mini-batch    60: 1.724\n",
      "Loss after mini-batch    70: 2.882\n",
      "Loss after mini-batch    80: 0.832\n",
      "Loss after mini-batch    90: 0.097\n",
      "Loss after mini-batch   100: 0.659\n",
      "Loss after mini-batch   110: 0.836\n",
      "Loss after mini-batch   120: 1.167\n",
      "Loss after mini-batch   130: 0.612\n",
      "Loss after mini-batch   140: 5.737\n",
      "Loss after mini-batch   150: 1.665\n",
      "Loss after mini-batch   160: 1.158\n",
      "Loss after mini-batch   170: 0.375\n",
      "Loss after mini-batch   180: 0.333\n",
      "Loss after mini-batch   190: 1.367\n",
      "Loss after mini-batch   200: 0.199\n",
      "Loss after mini-batch   210: 0.059\n",
      "Loss after mini-batch   220: 0.600\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.003\n",
      "Loss after mini-batch    20: 0.210\n",
      "Loss after mini-batch    30: 0.006\n",
      "Loss after mini-batch    40: 0.022\n",
      "Loss after mini-batch    50: 0.008\n",
      "Loss after mini-batch    60: 0.005\n",
      "Loss after mini-batch    70: 0.004\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.012\n",
      "Loss after mini-batch   100: 0.004\n",
      "Loss after mini-batch   110: 0.005\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.007\n",
      "Loss after mini-batch   140: 0.002\n",
      "Loss after mini-batch   150: 0.182\n",
      "Loss after mini-batch   160: 0.001\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.001\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.002\n",
      "Loss after mini-batch   210: 0.017\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.005\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.004\n",
      "Loss after mini-batch   200: 0.001\n",
      "Loss after mini-batch   210: 0.002\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.000\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 2: 87 %\n",
      "--------------------------------\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 0.332\n",
      "Loss after mini-batch    20: 1.147\n",
      "Loss after mini-batch    30: 0.104\n",
      "Loss after mini-batch    40: 0.520\n",
      "Loss after mini-batch    50: 2.722\n",
      "Loss after mini-batch    60: 0.757\n",
      "Loss after mini-batch    70: 0.920\n",
      "Loss after mini-batch    80: 2.903\n",
      "Loss after mini-batch    90: 1.455\n",
      "Loss after mini-batch   100: 0.315\n",
      "Loss after mini-batch   110: 3.449\n",
      "Loss after mini-batch   120: 1.557\n",
      "Loss after mini-batch   130: 0.317\n",
      "Loss after mini-batch   140: 2.835\n",
      "Loss after mini-batch   150: 0.062\n",
      "Loss after mini-batch   160: 0.306\n",
      "Loss after mini-batch   170: 0.232\n",
      "Loss after mini-batch   180: 0.524\n",
      "Loss after mini-batch   190: 1.183\n",
      "Loss after mini-batch   200: 4.896\n",
      "Loss after mini-batch   210: 2.039\n",
      "Loss after mini-batch   220: 1.147\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.031\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.155\n",
      "Loss after mini-batch    40: 0.002\n",
      "Loss after mini-batch    50: 1.053\n",
      "Loss after mini-batch    60: 0.001\n",
      "Loss after mini-batch    70: 0.032\n",
      "Loss after mini-batch    80: 0.004\n",
      "Loss after mini-batch    90: 0.012\n",
      "Loss after mini-batch   100: 0.028\n",
      "Loss after mini-batch   110: 0.528\n",
      "Loss after mini-batch   120: 0.448\n",
      "Loss after mini-batch   130: 0.005\n",
      "Loss after mini-batch   140: 0.001\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.330\n",
      "Loss after mini-batch   170: 0.515\n",
      "Loss after mini-batch   180: 0.009\n",
      "Loss after mini-batch   190: 0.010\n",
      "Loss after mini-batch   200: 0.007\n",
      "Loss after mini-batch   210: 0.008\n",
      "Loss after mini-batch   220: 0.008\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.648\n",
      "Loss after mini-batch    20: 0.012\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.029\n",
      "Loss after mini-batch    50: 0.003\n",
      "Loss after mini-batch    60: 0.002\n",
      "Loss after mini-batch    70: 0.020\n",
      "Loss after mini-batch    80: 0.006\n",
      "Loss after mini-batch    90: 0.006\n",
      "Loss after mini-batch   100: 0.003\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.217\n",
      "Loss after mini-batch   130: 0.006\n",
      "Loss after mini-batch   140: 0.006\n",
      "Loss after mini-batch   150: 0.018\n",
      "Loss after mini-batch   160: 0.002\n",
      "Loss after mini-batch   170: 0.005\n",
      "Loss after mini-batch   180: 0.060\n",
      "Loss after mini-batch   190: 0.011\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 6.540\n",
      "Loss after mini-batch   220: 0.041\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.002\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.006\n",
      "Loss after mini-batch    80: 0.025\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.208\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.071\n",
      "Loss after mini-batch   150: 0.001\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.004\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.006\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.000\n",
      "Loss after mini-batch   170: 0.013\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.000\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 3: 91 %\n",
      "--------------------------------\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Reset trainable parameters of layer = Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1))\n",
      "Reset trainable parameters of layer = Linear(in_features=20480, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=200, bias=True)\n",
      "Reset trainable parameters of layer = Linear(in_features=200, out_features=2, bias=True)\n",
      "Starting epoch 3\n",
      "Loss after mini-batch    10: 1.382\n",
      "Loss after mini-batch    20: 1.275\n",
      "Loss after mini-batch    30: 1.608\n",
      "Loss after mini-batch    40: 0.321\n",
      "Loss after mini-batch    50: 7.371\n",
      "Loss after mini-batch    60: 2.257\n",
      "Loss after mini-batch    70: 1.791\n",
      "Loss after mini-batch    80: 3.435\n",
      "Loss after mini-batch    90: 0.380\n",
      "Loss after mini-batch   100: 0.724\n",
      "Loss after mini-batch   110: 0.542\n",
      "Loss after mini-batch   120: 0.755\n",
      "Loss after mini-batch   130: 0.959\n",
      "Loss after mini-batch   140: 0.596\n",
      "Loss after mini-batch   150: 1.878\n",
      "Loss after mini-batch   160: 6.226\n",
      "Loss after mini-batch   170: 0.926\n",
      "Loss after mini-batch   180: 2.040\n",
      "Loss after mini-batch   190: 1.644\n",
      "Loss after mini-batch   200: 1.058\n",
      "Loss after mini-batch   210: 1.263\n",
      "Loss after mini-batch   220: 1.053\n",
      "Starting epoch 6\n",
      "Loss after mini-batch    10: 0.244\n",
      "Loss after mini-batch    20: 0.028\n",
      "Loss after mini-batch    30: 0.021\n",
      "Loss after mini-batch    40: 0.039\n",
      "Loss after mini-batch    50: 0.001\n",
      "Loss after mini-batch    60: 0.030\n",
      "Loss after mini-batch    70: 0.003\n",
      "Loss after mini-batch    80: 0.022\n",
      "Loss after mini-batch    90: 0.002\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.247\n",
      "Loss after mini-batch   120: 0.678\n",
      "Loss after mini-batch   130: 0.001\n",
      "Loss after mini-batch   140: 0.034\n",
      "Loss after mini-batch   150: 0.003\n",
      "Loss after mini-batch   160: 0.099\n",
      "Loss after mini-batch   170: 0.024\n",
      "Loss after mini-batch   180: 0.086\n",
      "Loss after mini-batch   190: 0.006\n",
      "Loss after mini-batch   200: 0.057\n",
      "Loss after mini-batch   210: 1.653\n",
      "Loss after mini-batch   220: 0.004\n",
      "Starting epoch 9\n",
      "Loss after mini-batch    10: 0.005\n",
      "Loss after mini-batch    20: 0.012\n",
      "Loss after mini-batch    30: 0.001\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.006\n",
      "Loss after mini-batch    60: 0.039\n",
      "Loss after mini-batch    70: 0.138\n",
      "Loss after mini-batch    80: 0.005\n",
      "Loss after mini-batch    90: 0.006\n",
      "Loss after mini-batch   100: 0.000\n",
      "Loss after mini-batch   110: 0.002\n",
      "Loss after mini-batch   120: 0.357\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.006\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.608\n",
      "Loss after mini-batch   170: 0.001\n",
      "Loss after mini-batch   180: 0.000\n",
      "Loss after mini-batch   190: 0.007\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.000\n",
      "Loss after mini-batch   220: 0.003\n",
      "Starting epoch 12\n",
      "Loss after mini-batch    10: 0.020\n",
      "Loss after mini-batch    20: 0.000\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.000\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.001\n",
      "Loss after mini-batch    80: 0.000\n",
      "Loss after mini-batch    90: 0.003\n",
      "Loss after mini-batch   100: 0.002\n",
      "Loss after mini-batch   110: 0.000\n",
      "Loss after mini-batch   120: 0.007\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.004\n",
      "Loss after mini-batch   150: 0.000\n",
      "Loss after mini-batch   160: 0.112\n",
      "Loss after mini-batch   170: 0.450\n",
      "Loss after mini-batch   180: 2.857\n",
      "Loss after mini-batch   190: 2.970\n",
      "Loss after mini-batch   200: 6.279\n",
      "Loss after mini-batch   210: 0.442\n",
      "Loss after mini-batch   220: 2.061\n",
      "Starting epoch 15\n",
      "Loss after mini-batch    10: 0.001\n",
      "Loss after mini-batch    20: 0.006\n",
      "Loss after mini-batch    30: 0.000\n",
      "Loss after mini-batch    40: 0.001\n",
      "Loss after mini-batch    50: 0.000\n",
      "Loss after mini-batch    60: 0.000\n",
      "Loss after mini-batch    70: 0.000\n",
      "Loss after mini-batch    80: 0.004\n",
      "Loss after mini-batch    90: 0.000\n",
      "Loss after mini-batch   100: 0.072\n",
      "Loss after mini-batch   110: 0.007\n",
      "Loss after mini-batch   120: 0.000\n",
      "Loss after mini-batch   130: 0.000\n",
      "Loss after mini-batch   140: 0.000\n",
      "Loss after mini-batch   150: 0.002\n",
      "Loss after mini-batch   160: 0.237\n",
      "Loss after mini-batch   170: 0.000\n",
      "Loss after mini-batch   180: 0.517\n",
      "Loss after mini-batch   190: 0.000\n",
      "Loss after mini-batch   200: 0.000\n",
      "Loss after mini-batch   210: 0.001\n",
      "Loss after mini-batch   220: 0.001\n",
      "Training process has finished. Saving trained model.\n",
      "Starting testing\n",
      "Accuracy for fold 4: 89 %\n",
      "--------------------------------\n",
      "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
      "--------------------------------\n",
      "Fold 0: 85.71428571428571 %\n",
      "Fold 1: 82.14285714285714 %\n",
      "Fold 2: 87.5 %\n",
      "Fold 3: 91.07142857142857 %\n",
      "Fold 4: 89.28571428571429 %\n",
      "Average: 87.14285714285714 %\n"
     ]
    }
   ],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()\n",
    "class SimpleConvNet(nn.Module):\n",
    "  '''\n",
    "    Simple Convolutional Neural Network\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Conv2d(1, 10, kernel_size=3), # 1*300*300 -> 10*298*298\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #10*298*298 -> 10*149*149\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(10, 20, kernel_size=3), #10*149*149 -> 20*147*147\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #20*147*147 -> 20*73*73\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(20, 40, kernel_size=3), #20*73*73->40*71*71\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #40*71*71->40*35,35\n",
    "      #풀링 추가\n",
    "      nn.Conv2d(40, 80, kernel_size=3), #40*35*35 -> 80*33*33\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d((2,2)), #80*33*33->80*16*16\n",
    "      #풀링 추가\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16 * 16 * 80, 200),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(200, 200),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(200, 2)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  # Configuration options\n",
    "  k_folds = 5\n",
    "  num_epochs = 15\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  # For fold results\n",
    "  results = {}\n",
    "\n",
    "  # Set fixed random number seed\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  # Define the K-fold Cross Validator\n",
    "  kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "  # Start print\n",
    "  print('--------------------------------')\n",
    "\n",
    "  # K-fold Cross Validation model evaluation\n",
    "  for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "\n",
    "    # Print\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=train_subsampler,num_workers=4)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=1, sampler=test_subsampler,num_workers=4)\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SimpleConvNet()\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    for epoch in range(0, num_epochs):\n",
    "\n",
    "      # Print epoch\n",
    "      if epoch % 3 ==2:\n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "\n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch % 3 == 2:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "                  (i + 1, current_loss / 1))\n",
    "            current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "    # Print about testing\n",
    "    print('Starting testing')\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "      # Iterate over the test data and generate predictions\n",
    "      for i, data in enumerate(testloader, 0):\n",
    "\n",
    "        # Get inputs\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Generate outputs\n",
    "        outputs = network(inputs)\n",
    "\n",
    "        # Set total and correct\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "      # Print accuracy\n",
    "      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "      print('--------------------------------')\n",
    "      results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "  # Print fold results\n",
    "  print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "  print('--------------------------------')\n",
    "  sum = 0.0\n",
    "  for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "  print(f'Average: {sum/len(results.items())} %')\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGYtckbt+Dm9dXa7sQ0+zP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
