{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7LnPB3l34MJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ4vuJyw4DfV",
        "outputId": "916e7296-70aa-4e1f-e49e-e07001bada2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 설정\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "f32DeAsj4HNc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터세트 경로 설정\n",
        "dataset_path = '/content/drive/MyDrive/Dataset/Dataset/'\n",
        "\n",
        "# 이미지 파일 목록과 라벨 생성\n",
        "image_files = []\n",
        "labels = []\n",
        "for filename in os.listdir(dataset_path):\n",
        "  if filename.endswith(('.png','.jpg')):    #filename 중 .png, .jpg로 끝나는 것 찾기\n",
        "    image_files.append(os.path.join(dataset_path, filename))\n",
        "    if 'o' in filename:    # filename = o라면 0\n",
        "      labels.append(0)\n",
        "    elif 'x' in filename:  # filename = x라면 1\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(2)     # o, x 둘다 아니라면 2\n",
        "\n",
        "# 이미지 데이터셋 생성 tf.data.Dataset 사용\n",
        "image_size = (300, 300)\n",
        "BATCH_SIZE = 30   # batch size : 하나의 소그룹에 속하는 데이터\n",
        "BUFFER_SIZE = tf.data.AUTOTUNE\n",
        "\n",
        "# 이미지 전처리\n",
        "def preprocess_image(image_path, target_size = (300, 300)):\n",
        "  img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size) #이미지 불러오기\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)  #이미지 배열 변환\n",
        "  img = img / 255.0 #픽셀 값 정규화\n",
        "  return img  #결과 반환"
      ],
      "metadata": {
        "id": "RN0NSisV45dk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터와 라벨을 Numpy 배열로 변환\n",
        "images = np.array([preprocess_image(image_file) for image_file in image_files])\n",
        "labels = np.array(labels)\n",
        "\n",
        "#image_files : 리스트에 저장된 각 이미지 파일경로에 대해 preprocess_image 함수를 적용하는 이미지 데이터 전처리\n",
        "# preprocess_image : 이미지 파일을 읽어들여 크기 조정 후 픽셀 값을 0과 1 사이로 정규화 하는 전처리 작업 수행\n",
        "# images = np.array ~ : 전처리 된 이미지 데이터들을 리스트로 모아서 np.array 함수로 사용하여 numpy 배열 images로 변환\n",
        "# labels = np.array(labels) : labels 리스트에 저장된 이미지 라벨들을 np.array 함수를 사용하여 numpy 배열로 변환"
      ],
      "metadata": {
        "id": "blWGxCRhL-MW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터셋, 테스트 데이터셋으로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=22)\n",
        "# random_state 값은 데이터 분할시 셔플이 이루어지는데 이를 위한 시드 -> 숫자 아무거나 상관 x"
      ],
      "metadata": {
        "id": "rErsAAD1OAtj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(30, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(60, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# layers.Conv2D : 합성곱 레이어 -> 30 : 30개의 필터 사용(다른 숫자 사용가능) / 필터 크기 3x3 / 픽셀크기 300x300 + 3개의 채널(빨,파,초)\n",
        "# layers.MaxPooling2D : 최대 풀링 레이어 -> 이미지 크기 줄이고 중요한 특징 강조\n",
        "# layers.Conv2D : 합성곱 레이어 -> 60개의 필터를 사용하여 더 많은 특징 추출\n",
        "# layers.MaxPooling2D : 최대 풀링 레이어 -> 이미지 크기를 더 줄임\n",
        "# layers.Flatten : 플래튼 레이어 -> 다차원 데이터를 1차원으로 변환\n",
        "# layers.Dense : 완전 연결 레이어 -> 모든 입력 노드가 모든 출력 노드에 연결됨(120개의 노드를 가지고 있음)\n",
        "# layers.Dense : 완전 연결 레이어 -> 최종 출력 레이어 -> 3개의 클래스 분류"
      ],
      "metadata": {
        "id": "bUHtDq4oPAFX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# optimizer='adam' : 학습 중 오차를 줄이기 위해 모델이 가중치를 업데이트하는 방법 제어\n",
        "# sparse_categorical_crossentropy : 정수형 -> 모델의 예측과 실제 목표 값 사이 차이를 정량화하는 함수\n",
        "# metrics=['accuracy'] : 학습 중 모델의 성능을 평가하는데 사용\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs = 10, validation_data=(x_test, y_test))\n",
        "# model.fit : 저장된 모델을 학습시키는 함수\n",
        "# 훈련 데이터 : x_train(이미지 데이터), y_train(o, x 구분)\n",
        "# epochs : 모든 데이터셋을 학습하는 횟수\n",
        "# validation_data : 모델의 성능 검증\n",
        "# x_test : 검증용 이미지 데이터, y_test : 검증용 이미지에 대한 정답"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXSjk0xvUhRj",
        "outputId": "e3b42eeb-a17c-44e1-85fa-80a66f0ec62a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.5277 - loss: 16.6006 - val_accuracy: 0.5000 - val_loss: 10.8526\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.6641 - loss: 4.3772 - val_accuracy: 0.7361 - val_loss: 0.4723\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 7s/step - accuracy: 0.8931 - loss: 0.2434 - val_accuracy: 0.8750 - val_loss: 0.3258\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 6s/step - accuracy: 0.9754 - loss: 0.0748 - val_accuracy: 0.8472 - val_loss: 0.3746\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.9811 - loss: 0.0384 - val_accuracy: 0.7778 - val_loss: 0.4992\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 0.9939 - loss: 0.0167 - val_accuracy: 0.8333 - val_loss: 0.4668\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.9939 - loss: 0.0097 - val_accuracy: 0.8194 - val_loss: 0.5196\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8611 - val_loss: 0.3921\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.8194 - val_loss: 0.5501\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 6s/step - accuracy: 0.9914 - loss: 0.0118 - val_accuracy: 0.7639 - val_loss: 0.9188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e62bf366790>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 확인\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'accuracy: {accuracy}')\n",
        "print(f'k-fold 미적용 정확도 : {accuracy*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIBA63p5FTuX",
        "outputId": "e2163d8e-a50f-4349-b12e-7e4fccbf098a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.7609 - loss: 0.8272\n",
            "accuracy: 0.7638888955116272\n",
            "k-fold 미적용 정확도 : 76.38888955116272%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold 적용 후 정확도 산출_기본 설정\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 5겹 교차 검증\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=22)\n",
        "\n",
        "# 정확도 저장 리스트 초기화\n",
        "accuracy_scores = []"
      ],
      "metadata": {
        "id": "qOoX8G_GK11F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-fold 수행\n",
        "for train_index, test_index in kfold.split(images, labels):\n",
        "  x_train, x_test = images[train_index], images[test_index]\n",
        "  y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "  # 모델 생성 및 학습\n",
        "  model = keras.Sequential([\n",
        "    layers.Conv2D(30, (3, 3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(60, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  # 모델 컴파일\n",
        "  model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # 모델 학습\n",
        "  model.fit(x_train, y_train, epochs = 10, validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "  # 예측\n",
        "  y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "\n",
        "  # 정확도 계산 후 저장\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  accuracy_scores.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94AQay7cLP1J",
        "outputId": "6ab7a13c-17e3-406f-9f05-7df7ba016673"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - accuracy: 0.5208 - loss: 5.9769 - val_accuracy: 0.6250 - val_loss: 0.7025\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 6s/step - accuracy: 0.8045 - loss: 0.4094 - val_accuracy: 0.7361 - val_loss: 0.5787\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 0.9209 - loss: 0.1548 - val_accuracy: 0.8750 - val_loss: 0.3616\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9879 - loss: 0.0374 - val_accuracy: 0.8472 - val_loss: 0.4069\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 7s/step - accuracy: 0.9908 - loss: 0.0189 - val_accuracy: 0.8889 - val_loss: 0.3573\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8889 - val_loss: 0.3884\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8611 - val_loss: 0.4513\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 5.7679e-04 - val_accuracy: 0.8750 - val_loss: 0.4652\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 4.1742e-04 - val_accuracy: 0.8750 - val_loss: 0.4681\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 3.7328e-04 - val_accuracy: 0.8750 - val_loss: 0.5022\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 876ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.4712 - loss: 25.8687 - val_accuracy: 0.5833 - val_loss: 7.1396\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.5627 - loss: 3.5807 - val_accuracy: 0.7222 - val_loss: 0.7991\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 0.8646 - loss: 0.3299 - val_accuracy: 0.7917 - val_loss: 0.4453\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.9697 - loss: 0.1160 - val_accuracy: 0.8611 - val_loss: 0.4735\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.9908 - loss: 0.0548 - val_accuracy: 0.8333 - val_loss: 0.3434\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 7s/step - accuracy: 0.9962 - loss: 0.0239 - val_accuracy: 0.7778 - val_loss: 0.5420\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.9818 - loss: 0.0250 - val_accuracy: 0.8472 - val_loss: 0.4108\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8750 - val_loss: 0.3687\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8750 - val_loss: 0.4962\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 4.8469e-04 - val_accuracy: 0.8056 - val_loss: 0.5049\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 937ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.3418 - loss: 15.4543 - val_accuracy: 0.4722 - val_loss: 3.4133\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 6s/step - accuracy: 0.6748 - loss: 1.6616 - val_accuracy: 0.7500 - val_loss: 0.6192\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9246 - loss: 0.1640 - val_accuracy: 0.7917 - val_loss: 0.4518\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 7s/step - accuracy: 0.9680 - loss: 0.1132 - val_accuracy: 0.8333 - val_loss: 0.4146\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 6s/step - accuracy: 0.9820 - loss: 0.0366 - val_accuracy: 0.8333 - val_loss: 0.4420\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 0.9908 - loss: 0.0257 - val_accuracy: 0.8194 - val_loss: 0.5091\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8333 - val_loss: 0.6240\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.9973 - loss: 0.0051 - val_accuracy: 0.8611 - val_loss: 0.7084\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8333 - val_loss: 0.5237\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8194 - val_loss: 0.5943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e62d814fd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e62d814fd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 894ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 6s/step - accuracy: 0.4995 - loss: 14.7368 - val_accuracy: 0.7083 - val_loss: 0.4800\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.8441 - loss: 0.3553 - val_accuracy: 0.8611 - val_loss: 0.3125\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 6s/step - accuracy: 0.9444 - loss: 0.1429 - val_accuracy: 0.8194 - val_loss: 0.4782\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.9843 - loss: 0.0590 - val_accuracy: 0.8611 - val_loss: 0.3358\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9908 - loss: 0.0186 - val_accuracy: 0.8611 - val_loss: 0.4133\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.9939 - loss: 0.0080 - val_accuracy: 0.8472 - val_loss: 0.4609\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8472 - val_loss: 0.6423\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 6s/step - accuracy: 0.9818 - loss: 0.0481 - val_accuracy: 0.8472 - val_loss: 0.5685\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 6s/step - accuracy: 0.9955 - loss: 0.0040 - val_accuracy: 0.8611 - val_loss: 0.5362\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 6.9037e-04 - val_accuracy: 0.8750 - val_loss: 0.5032\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 877ms/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 7s/step - accuracy: 0.5240 - loss: 24.7223 - val_accuracy: 0.6806 - val_loss: 1.1369\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.7499 - loss: 0.8797 - val_accuracy: 0.7778 - val_loss: 0.5106\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.9005 - loss: 0.1749 - val_accuracy: 0.8472 - val_loss: 0.4454\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 6s/step - accuracy: 0.9857 - loss: 0.0723 - val_accuracy: 0.8611 - val_loss: 0.3895\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 0.9955 - loss: 0.0305 - val_accuracy: 0.8333 - val_loss: 0.4126\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8611 - val_loss: 0.4775\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8333 - val_loss: 0.7171\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 0.9955 - loss: 0.0074 - val_accuracy: 0.8611 - val_loss: 0.5688\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8472 - val_loss: 0.6032\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8333 - val_loss: 0.6925\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 875ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평균 정확도 출력\n",
        "print(f'accuracy : {np.mean(accuracy_scores)}')\n",
        "print(f'k-fold 적용 정확도 : {np.mean(accuracy_scores)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E28jEUq2M3oL",
        "outputId": "274e339e-604b-49f6-cfa5-5bf822ef6b27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.8416666666666666\n",
            "k-fold 적용 정확도 : 84.16666666666666%\n"
          ]
        }
      ]
    }
  ]
}