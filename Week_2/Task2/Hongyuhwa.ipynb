{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lzCiT0MtfKAt"
      },
      "outputs": [],
      "source": [
        "# Dataset 압축 해제\n",
        "#!mkdir -p /content/OX_Dataset\n",
        "!unzip -qq /content/Dataset.zip -d /content/OX_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset # Import the Dataset class\n",
        "from PIL import Image\n",
        "import random"
      ],
      "metadata": {
        "id": "6kg7p_OOfXQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rppxOe7kDgkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "7oOdHVigxbDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 데이터 전처리\n",
        "mean = 0.5\n",
        "sigma = 0.5\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Normalize(mean=[mean], std=[sigma])\n",
        "])\n",
        "trainset = datasets.ImageFolder(root='./OX_Dataset/Dataset', transform=trans)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, test_data = train_test_split(trainset, test_size=0.2, shuffle=True)\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "testloader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# 모델 정의\n",
        "class Classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classification, self).__init__()\n",
        "        self.fc1 = nn.Linear(300*300, 512)  # 300x300 크기의 이미지가 입력\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 2)  # 2개의 클래스 (OX)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 300*300)  # 입력을 1D 텐서로 변환\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = Classification()\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 훈련 루프\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veEBkXWIGfrX",
        "outputId": "927bddc9-bdc5-43c9-9d55-78d71e139b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 21.5253\n",
            "Epoch [2/10], Loss: 3.2013\n",
            "Epoch [3/10], Loss: 3.2655\n",
            "Epoch [4/10], Loss: 5.1724\n",
            "Epoch [5/10], Loss: 4.4348\n",
            "Epoch [6/10], Loss: 2.2466\n",
            "Epoch [7/10], Loss: 1.0923\n",
            "Epoch [8/10], Loss: 0.9772\n",
            "Epoch [9/10], Loss: 0.5421\n",
            "Epoch [10/10], Loss: 0.5535\n",
            "Accuracy: 85.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP(K-fold 적용)"
      ],
      "metadata": {
        "id": "O2kKjnZjjnoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 데이터 전처리\n",
        "mean = 0.5\n",
        "sigma = 0.5\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Normalize(mean=[mean], std=[sigma])\n",
        "])\n",
        "dataset = datasets.ImageFolder(root='./OX_Dataset/Dataset', transform=trans)\n",
        "\n",
        "# K-Fold 설정\n",
        "k_folds = 5\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# 모델 정의\n",
        "class Classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classification, self).__init__()\n",
        "        self.fc1 = nn.Linear(300*300, 512)  # 300x300 크기의 이미지가 입력\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 2)  # 2개의 클래스 (OX)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 300*300)  # 입력을 1D 텐서로 변환\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 손실 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# K-Fold 교차 검증 수행\n",
        "results = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # 샘플 인덱스 가져오기\n",
        "    train_subsampler = Subset(dataset, train_idx)\n",
        "    test_subsampler = Subset(dataset, test_idx)\n",
        "\n",
        "    trainloader = DataLoader(train_subsampler, batch_size=32, shuffle=True)\n",
        "    testloader = DataLoader(test_subsampler, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = Classification()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 훈련 루프\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}')\n",
        "\n",
        "    # 모델 평가\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy for fold {fold}: {accuracy:.2f}%')\n",
        "    results.append(accuracy)\n",
        "\n",
        "# 전체 결과 출력\n",
        "print(f'K-Fold Cross Validation Results for {k_folds} Folds')\n",
        "print('--------------------------------')\n",
        "for i in range(k_folds):\n",
        "    print(f'Fold {i}: {results[i]:.2f}%')\n",
        "print(f'Average: {np.mean(results):.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHNgNeLUGJWY",
        "outputId": "c3d69046-be69-444b-b20e-5ee633401983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 25.7076\n",
            "Epoch [2/10], Loss: 14.2995\n",
            "Epoch [3/10], Loss: 6.3132\n",
            "Epoch [4/10], Loss: 1.0830\n",
            "Epoch [5/10], Loss: 1.5152\n",
            "Epoch [6/10], Loss: 1.0961\n",
            "Epoch [7/10], Loss: 0.6483\n",
            "Epoch [8/10], Loss: 0.4609\n",
            "Epoch [9/10], Loss: 0.4467\n",
            "Epoch [10/10], Loss: 0.4487\n",
            "Accuracy for fold 0: 57.14%\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 18.1662\n",
            "Epoch [2/10], Loss: 5.5060\n",
            "Epoch [3/10], Loss: 3.4412\n",
            "Epoch [4/10], Loss: 1.7142\n",
            "Epoch [5/10], Loss: 2.0353\n",
            "Epoch [6/10], Loss: 1.0814\n",
            "Epoch [7/10], Loss: 0.7246\n",
            "Epoch [8/10], Loss: 0.5662\n",
            "Epoch [9/10], Loss: 0.3990\n",
            "Epoch [10/10], Loss: 0.4677\n",
            "Accuracy for fold 1: 55.36%\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 20.0028\n",
            "Epoch [2/10], Loss: 5.9150\n",
            "Epoch [3/10], Loss: 5.2474\n",
            "Epoch [4/10], Loss: 6.3897\n",
            "Epoch [5/10], Loss: 2.3308\n",
            "Epoch [6/10], Loss: 1.4330\n",
            "Epoch [7/10], Loss: 1.0610\n",
            "Epoch [8/10], Loss: 0.6554\n",
            "Epoch [9/10], Loss: 0.5137\n",
            "Epoch [10/10], Loss: 0.5110\n",
            "Accuracy for fold 2: 82.14%\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 16.1687\n",
            "Epoch [2/10], Loss: 6.6652\n",
            "Epoch [3/10], Loss: 2.7952\n",
            "Epoch [4/10], Loss: 2.3063\n",
            "Epoch [5/10], Loss: 2.8756\n",
            "Epoch [6/10], Loss: 2.1762\n",
            "Epoch [7/10], Loss: 1.0074\n",
            "Epoch [8/10], Loss: 0.6044\n",
            "Epoch [9/10], Loss: 0.3914\n",
            "Epoch [10/10], Loss: 0.3887\n",
            "Accuracy for fold 3: 78.57%\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 18.6240\n",
            "Epoch [2/10], Loss: 6.2189\n",
            "Epoch [3/10], Loss: 4.9779\n",
            "Epoch [4/10], Loss: 2.4085\n",
            "Epoch [5/10], Loss: 0.9984\n",
            "Epoch [6/10], Loss: 0.6433\n",
            "Epoch [7/10], Loss: 0.4586\n",
            "Epoch [8/10], Loss: 0.4841\n",
            "Epoch [9/10], Loss: 0.5377\n",
            "Epoch [10/10], Loss: 0.3862\n",
            "Accuracy for fold 4: 62.50%\n",
            "K-Fold Cross Validation Results for 5 Folds\n",
            "--------------------------------\n",
            "Fold 0: 57.14%\n",
            "Fold 1: 55.36%\n",
            "Fold 2: 82.14%\n",
            "Fold 3: 78.57%\n",
            "Fold 4: 62.50%\n",
            "Average: 67.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN(K-fold 적용)"
      ],
      "metadata": {
        "id": "OmNkIZspxUOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 데이터 전처리\n",
        "mean = 0.5\n",
        "sigma = 0.5\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Normalize(mean=[mean], std=[sigma])\n",
        "])\n",
        "dataset = datasets.ImageFolder(root='./OX_Dataset/Dataset', transform=trans)\n",
        "\n",
        "# K-Fold 설정\n",
        "k_folds = 4\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "\n",
        "# 모델 정의\n",
        "class Classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classification, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 75 * 75, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 75 * 75)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 손실 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# K-Fold 교차 검증 수행\n",
        "results = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "\n",
        "    # 샘플 인덱스 가져오기\n",
        "    train_subsampler = Subset(dataset, train_idx)\n",
        "    test_subsampler = Subset(dataset, test_idx)\n",
        "\n",
        "    trainloader = DataLoader(train_subsampler, batch_size=32, shuffle=True)\n",
        "    testloader = DataLoader(test_subsampler, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 모델 초기화\n",
        "    model = Classification()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # 훈련 루프\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}')\n",
        "\n",
        "    # 모델 평가\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy for fold {fold}: {accuracy:.2f}%')\n",
        "    results.append(accuracy)\n",
        "\n",
        "# 전체 결과 출력\n",
        "print(f'K-Fold Cross Validation Results for {k_folds} Folds')\n",
        "print('--------------------------------')\n",
        "for i in range(k_folds):\n",
        "    print(f'Fold {i}: {results[i]:.2f}%')\n",
        "print(f'Average: {np.mean(results):.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWrYmnDLj1Jj",
        "outputId": "ea263d38-08f8-4490-e3ab-8d479d52ea68"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 2.7655\n",
            "Epoch [2/10], Loss: 0.3301\n",
            "Epoch [3/10], Loss: 0.1017\n",
            "Epoch [4/10], Loss: 0.0210\n",
            "Epoch [5/10], Loss: 0.0127\n",
            "Epoch [6/10], Loss: 0.0036\n",
            "Epoch [7/10], Loss: 0.0006\n",
            "Epoch [8/10], Loss: 0.0005\n",
            "Epoch [9/10], Loss: 0.0001\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Accuracy for fold 0: 78.57%\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 3.7479\n",
            "Epoch [2/10], Loss: 0.3744\n",
            "Epoch [3/10], Loss: 0.1224\n",
            "Epoch [4/10], Loss: 0.0409\n",
            "Epoch [5/10], Loss: 0.0115\n",
            "Epoch [6/10], Loss: 0.0042\n",
            "Epoch [7/10], Loss: 0.0026\n",
            "Epoch [8/10], Loss: 0.0012\n",
            "Epoch [9/10], Loss: 0.0003\n",
            "Epoch [10/10], Loss: 0.0001\n",
            "Accuracy for fold 1: 80.00%\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 5.0014\n",
            "Epoch [2/10], Loss: 0.4919\n",
            "Epoch [3/10], Loss: 0.2520\n",
            "Epoch [4/10], Loss: 0.0658\n",
            "Epoch [5/10], Loss: 0.0097\n",
            "Epoch [6/10], Loss: 0.0016\n",
            "Epoch [7/10], Loss: 0.0528\n",
            "Epoch [8/10], Loss: 0.0018\n",
            "Epoch [9/10], Loss: 0.0750\n",
            "Epoch [10/10], Loss: 0.0220\n",
            "Accuracy for fold 2: 81.43%\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Epoch [1/10], Loss: 7.2471\n",
            "Epoch [2/10], Loss: 0.6821\n",
            "Epoch [3/10], Loss: 0.2737\n",
            "Epoch [4/10], Loss: 0.1379\n",
            "Epoch [5/10], Loss: 0.0376\n",
            "Epoch [6/10], Loss: 0.0085\n",
            "Epoch [7/10], Loss: 0.0031\n",
            "Epoch [8/10], Loss: 0.0003\n",
            "Epoch [9/10], Loss: 0.0001\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Accuracy for fold 3: 84.29%\n",
            "K-Fold Cross Validation Results for 4 Folds\n",
            "--------------------------------\n",
            "Fold 0: 78.57%\n",
            "Fold 1: 80.00%\n",
            "Fold 2: 81.43%\n",
            "Fold 3: 84.29%\n",
            "Average: 81.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN(K-fold 미적용)"
      ],
      "metadata": {
        "id": "7KuEIs9_xNBU"
      }
    },
    {
      "source": [
        "# 라이브러리 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 데이터 전처리\n",
        "mean = 0.5\n",
        "sigma = 0.5\n",
        "trans = transforms.Compose([\n",
        "    transforms.Resize((300, 300)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Normalize(mean=[mean], std=[sigma])\n",
        "])\n",
        "trainset = datasets.ImageFolder(root='./OX_Dataset/Dataset', transform=trans)\n",
        "\n",
        "# 데이터 분할\n",
        "train_data, test_data = train_test_split(trainset, test_size=0.2, shuffle=True)\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "testloader = DataLoader(test_data, batch_size=10, shuffle=True)\n",
        "\n",
        "# 모델 정의\n",
        "class Classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classification, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 75 * 75, 512)  # Calculate the correct flattened size\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 2)  # 2개의 클래스 (OX)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 75 * 75)  # Flatten to the correct size\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = Classification()\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 훈련 루프\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy: {accuracy:.2f}%')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhtG-XgCtVeN",
        "outputId": "ee33cd7b-7415-4adf-f5aa-9ee3270ed664"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.0516\n",
            "Epoch [2/10], Loss: 0.2316\n",
            "Epoch [3/10], Loss: 0.0382\n",
            "Epoch [4/10], Loss: 0.0022\n",
            "Epoch [5/10], Loss: 0.0004\n",
            "Epoch [6/10], Loss: 0.0001\n",
            "Epoch [7/10], Loss: 0.0001\n",
            "Epoch [8/10], Loss: 0.0000\n",
            "Epoch [9/10], Loss: 0.0000\n",
            "Epoch [10/10], Loss: 0.0000\n",
            "Accuracy: 87.50%\n"
          ]
        }
      ]
    }
  ]
}