{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldoqi2AtViMy",
        "outputId": "86ca85d1-f988-43de-afd7-542e15e0b3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "!pip install torchsummary\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 불러오기\n",
        "path_dir=(\"/content/drive/MyDrive/인공지능 실습/IMS_인공지능스터디/DataSet/Dataset\")\n",
        "\n",
        "# 파일 조회\n",
        "all_files = os.listdir(path_dir)\n",
        "\n",
        "# 파일 이름에 'o'와 'x'로 나누기\n",
        "o_images = [file for file in all_files if 'o' in file]\n",
        "x_images = [file for file in all_files if 'x' in file]\n",
        "\n",
        "print('o_images:', len(o_images)) # 왜 너만 141이야 분명 140맞는데!\n",
        "print('x_images:', len(x_images))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4amh6En0YUKg",
        "outputId": "9ed39a66-1299-4104-fd94-8b5ac5869d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o_images: 141\n",
            "x_images: 140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지 전처리\n",
        "def preprocess_image(path_dir):\n",
        "  images=[]\n",
        "  labels=[]\n",
        "\n",
        "  all_files = os.listdir(path_dir)\n",
        "\n",
        "  for filename in all_files:\n",
        "    if filename.endswith((\".jpg\", \".png\")):\n",
        "      img_path=os.path.join(path_dir, filename)\n",
        "      try:\n",
        "        img=Image.open(img_path)\n",
        "        img = img.convert('RGB')  # 이미지를 RGB로 변환\n",
        "        img=img.resize((224, 224)) #224*224\n",
        "        transform = transforms.Compose([\n",
        "                    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
        "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 이미지 정규화\n",
        "                ])\n",
        "        img = transform(img)\n",
        "        images.append(img)\n",
        "\n",
        "        if 'o' in filename:\n",
        "          labels.append(0) # o는 0\n",
        "        elif 'x' in filename:\n",
        "          labels.append(1) # x는 1\n",
        "      except PIL.UnidentifiedImageError:\n",
        "        print(f\"failed to load image: {filename}\")\n",
        "  #labels = tf.convert_to_tensor(labels)  # 레이블 리스트를 텐서로 변환\n",
        "\n",
        "\n",
        "  images = torch.stack(images)  # 이미지 리스트를 텐서로 변환\n",
        "  labels = torch.tensor(labels)  # 레이블 리스트를 텐서로 변환\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "images, labels= preprocess_image(path_dir)\n",
        "print('Images shape:', images.size())\n",
        "print('Labels shape:', labels.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe6heZF1ftXN",
        "outputId": "57b1daf9-ed69-4e18-c8c3-edb09c08e030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images shape: torch.Size([280, 3, 224, 224])\n",
            "Labels shape: torch.Size([280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ox 전체 이미지 280\n",
        "- 224*224 픽셀\n",
        "- RGB 이므로 3채널\n",
        "- label 총 280개, o->0, x->1"
      ],
      "metadata": {
        "id": "5A8naesnlDPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training-data 랑 test-data로 나누기\n",
        "# train_ratio 8:2로 나눔\n",
        "def split_dataset(images, labels, train_ratio=0.8):\n",
        " dataset= TensorDataset(images, labels) #텐서로 이미지랑 레이블을 하나로 결합\n",
        " train_size = int(train_ratio * len(dataset)) #train data 크기 계산\n",
        " test_size = len(dataset) - train_size #test data 크기 계산\n",
        " train_dataset, test_dataset = random_split(dataset, [train_size, test_size]) #train data와 test data로 random split\n",
        " return train_dataset, test_dataset\n",
        "\n",
        "train_dataset, test_dataset = split_dataset(images, labels)\n",
        "print('Train dataset size:', len(train_dataset))\n",
        "print('Test dataset size:', len(test_dataset))\n",
        "\n",
        "#모델에 데이터 전달(데이터 로더)\n",
        "batch_size = 32\n",
        "#학습데이터는 shuffle하고 테스트데이터는 안함\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBMhaMuuk9ix",
        "outputId": "edd49dbf-6092-4387-a618-879b00f665a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 224\n",
            "Test dataset size: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn 모델 정의\n",
        "# conv - pooling - fully conneted layer(linear) - relu\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    #RGB이므로 3채널, out채널은 합성곱 필터의 출력 채널 수\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)#최대 풀링(이미지 인식 분야)\n",
        "    #입력 특성의 수와 출력 특성의 수 정의\n",
        "    self.fc1 = nn.Linear(32 * 56 * 56, 512) # 이전 합성곱 레이어의 출력 특성 수 이용해서 입력 특성수 정의\n",
        "    self.fc2 = nn.Linear(512, 2) #최종적으로 분류할 클래스 수 맞춰서 출력 특성 정의\n",
        "    self.relu1 = nn.ReLU() #활성화 함수(비선형성 추가해서 복잡한 패턴 학습)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    #self.dropout = nn.Dropout(p=0.5) 혹시 모를 과적합 방지\n",
        "\n",
        "#순전파 연산 - 차례대로 변수 계산하고 저장\n",
        "  def forward(self, x):\n",
        "    x=self.maxpool(torch.relu(self.conv1(x))) #conv1 합성곱 풀링 계산 후 저장\n",
        "    x=self.maxpool(torch.relu(self.conv2(x))) #conv2 합성곱 풀링 계산 후 저장\n",
        "    x = x.view(-1, 32 * 56 * 56) # 텐서를 1차원으로 변환\n",
        "    x = torch.relu(self.fc1(x)) #fc1 계산 후 저장\n",
        "    x = self.fc2(x) #fc2 통과해서 최종 출력\n",
        "    return x\n",
        "\n",
        "#모델 요약\n",
        "model = CNN()\n",
        "summary(model, (3, 224, 224))\n",
        "\n",
        "#모델 초기화\n",
        "model = CNN()\n",
        "#손실함수 - 출력과 실제 사이의 엔트로피 손실 계산\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#옵티마이저 - 최적화 알고리즘을 사용하여 모델의 파라미터를 업데이트, lr은 학습률(가중치 업데이트 속도와 방향 결정)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cvCSJnXNMUN",
        "outputId": "1064f783-d141-4728-d739-81256228a785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             448\n",
            "         MaxPool2d-2         [-1, 16, 112, 112]               0\n",
            "            Conv2d-3         [-1, 32, 112, 112]           4,640\n",
            "         MaxPool2d-4           [-1, 32, 56, 56]               0\n",
            "            Linear-5                  [-1, 512]      51,380,736\n",
            "            Linear-6                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 51,386,850\n",
            "Trainable params: 51,386,850\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 11.49\n",
            "Params size (MB): 196.03\n",
            "Estimated Total Size (MB): 208.09\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 훈련\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs): #10번 epoch 반복\n",
        "    running_loss = 0.0 #epoch 내에 러닝 손실 초기화\n",
        "    for inputs, labels in train_loader:\n",
        "      optimizer.zero_grad() #기울기 초기화\n",
        "      outputs = model(inputs) #입력 데이터 전달해서 출력 계산\n",
        "      loss = criterion(outputs, labels) # loss 계산(출력 - 실제)\n",
        "      loss.backward() #역전파 - 파라미터에 대한 loss기울기 계산\n",
        "      optimizer.step() #파라미터 업데이트\n",
        "      #epoch 내에 러닝 손실 계산, 출력\n",
        "      running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "#모델 평가\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad(): #평가시 기울기 계산 안함\n",
        "    for inputs, labels in test_loader:\n",
        "      outputs = model(inputs)\n",
        "      _, predicted = torch.max(outputs.data, 1) #최대값과 최대값의 인덱스 반환\n",
        "      total += labels.size(0) #배치 크기만큼 더함\n",
        "      correct += (predicted == labels).sum().item() #예측값과 실제값이 같은지 확인\n",
        "    accuracy = 100 * correct / total #정확도 계산\n",
        "    print(f\"Accuracy: {accuracy}%\")\n",
        "\n",
        "#모델 훈련 , 평가\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
        "evaluate_model(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw7vnI6IVULX",
        "outputId": "e8fbde4b-349c-4dae-8da2-774ff7b9fc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 15.731369503906794\n",
            "Epoch 2/10, Loss: 0.908461834703173\n",
            "Epoch 3/10, Loss: 0.555486900465829\n",
            "Epoch 4/10, Loss: 0.43910699657031466\n",
            "Epoch 5/10, Loss: 0.27624434658459257\n",
            "Epoch 6/10, Loss: 0.27045609269823345\n",
            "Epoch 7/10, Loss: 0.2053407153912953\n",
            "Epoch 8/10, Loss: 0.1854294618325574\n",
            "Epoch 9/10, Loss: 0.13482524773904256\n",
            "Epoch 10/10, Loss: 0.09688379083360944\n",
            "Accuracy: 83.92857142857143%\n"
          ]
        }
      ]
    }
  ]
}